2022-08-18 14:15:58,618 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr/local/cuda
NVCC: Build cuda_11.3.r11.3/compiler.29745058_0
GCC: gcc (GCC) 5.4.0
PyTorch: 1.11.0
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0
OpenCV: 4.5.5
MMCV: 1.4.8
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMDetection: 2.23.0+3e26931
------------------------------------------------------------

2022-08-18 14:15:59,792 - mmdet - INFO - Distributed training: False
2022-08-18 14:16:00,974 - mmdet - INFO - Config:
model = dict(
    type='CascadeRCNN',
    backbone=dict(
        type='SwinTransformer',
        embed_dims=96,
        depths=[2, 2, 6, 2],
        num_heads=[3, 6, 12, 24],
        window_size=7,
        mlp_ratio=4,
        qkv_bias=True,
        qk_scale=None,
        drop_rate=0.0,
        attn_drop_rate=0.0,
        drop_path_rate=0.2,
        patch_norm=True,
        out_indices=(0, 1, 2, 3),
        with_cp=False,
        convert_weights=True,
        init_cfg=dict(
            type='Pretrained',
            checkpoint=
            'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth'
        )),
    neck=dict(
        type='FPN',
        in_channels=[96, 192, 384, 768],
        out_channels=256,
        num_outs=5),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        reg_decoded_bbox=True,
        loss_bbox=dict(type='CIoULoss', loss_weight=3.0)),
    roi_head=dict(
        type='CascadeRoIHead',
        num_stages=3,
        stage_loss_weights=[1, 0.5, 0.25],
        bbox_roi_extractor=dict(
            type='GenericRoIExtractor',
            aggregation='sum',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=2),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32],
            pre_cfg=dict(
                type='ConvModule',
                in_channels=256,
                out_channels=256,
                kernel_size=5,
                padding=2,
                inplace=False),
            post_cfg=dict(
                type='GeneralizedAttention',
                in_channels=256,
                spatial_range=-1,
                num_heads=6,
                attention_type='0100',
                kv_stride=2)),
        bbox_head=[
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=15,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.1, 0.1, 0.2, 0.2]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                reg_decoded_bbox=True,
                loss_bbox=dict(type='CIoULoss', loss_weight=3.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=15,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.05, 0.05, 0.1, 0.1]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                reg_decoded_bbox=True,
                loss_bbox=dict(type='CIoULoss', loss_weight=3.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=15,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.033, 0.033, 0.067, 0.067]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                reg_decoded_bbox=True,
                loss_bbox=dict(type='CIoULoss', loss_weight=3.0))
        ],
        mask_roi_extractor=dict(
            type='GenericRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=2),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32],
            pre_cfg=dict(
                type='ConvModule',
                in_channels=256,
                out_channels=256,
                kernel_size=5,
                padding=2,
                inplace=False),
            post_cfg=dict(
                type='GeneralizedAttention',
                in_channels=256,
                spatial_range=-1,
                num_heads=6,
                attention_type='0100',
                kv_stride=2)),
        mask_head=dict(
            type='FCNMaskHead',
            num_convs=4,
            in_channels=256,
            conv_out_channels=256,
            num_classes=15,
            loss_mask=[
                dict(type='CrossEntropyLoss', use_mask=True, loss_weight=1.0),
                dict(type='DiceLoss', loss_weight=3.0)
            ])),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=0,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=2000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=[
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.5,
                    neg_iou_thr=0.5,
                    min_pos_iou=0.5,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                mask_size=28,
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.6,
                    neg_iou_thr=0.6,
                    min_pos_iou=0.6,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                mask_size=28,
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.7,
                    neg_iou_thr=0.7,
                    min_pos_iou=0.7,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                mask_size=28,
                pos_weight=-1,
                debug=False)
        ]),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            score_thr=0.05,
            nms=dict(type='soft_nms', iou_threshold=0.6),
            max_per_img=1000,
            mask_thr_binary=0.5)))
dataset_type = 'CocoDataset'
data_root = 'data/coco/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(
        type='Resize',
        img_scale=[(1200, 800), (1000, 800), (800, 800), (800, 600),
                   (800, 400)],
        multiscale_mode='value',
        keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=[(1200, 800), (1000, 800)],
        flip=True,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=2,
    train=dict(
        type='CocoDataset',
        ann_file='data/coco/annotations/instances_train2017.json',
        img_prefix='data/coco/train2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
            dict(
                type='Resize',
                img_scale=[(1200, 800), (1000, 800), (800, 800), (800, 600),
                           (800, 400)],
                multiscale_mode='value',
                keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(
                type='Collect',
                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])
        ]),
    val=dict(
        type='CocoDataset',
        ann_file='data/coco/annotations/instances_val2017.json',
        img_prefix='data/coco/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=[(1200, 800), (1000, 800)],
                flip=True,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        ann_file='data/coco/annotations/instances_val2017.json',
        img_prefix='data/coco/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=[(1200, 800), (1000, 800)],
                flip=True,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(metric=['bbox', 'segm'])
optimizer = dict(
    type='AdamW',
    lr=0.0001,
    betas=(0.9, 0.999),
    weight_decay=0.05,
    paramwise_cfg=dict(
        custom_keys=dict(
            absolute_pos_embed=dict(decay_mult=0.0),
            relative_position_bias_table=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0))))
optimizer_config = dict(grad_clip=None)
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=1000,
    warmup_ratio=0.001,
    step=[8])
runner = dict(type='EpochBasedRunner', max_epochs=12)
checkpoint_config = dict(interval=1)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = './work_dirs/cascade-mask-rcnn-SWIN-right-lable-maskhead-add-ciou-softnms-groie-diceloss-tta-multiscaletrain-sample1000/epoch_11.pth'
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
pretrained = 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth'
work_dir = './work_dirs/cascade-mask-rcnn-SWIN-right-lable-maskhead-add-ciou-softnms-groie-diceloss-tta-multiscaletrain-sample1000'
auto_resume = False
gpu_ids = [0]

2022-08-18 14:16:00,975 - mmdet - INFO - Set random seed to 310380332, deterministic: False
2022-08-18 14:16:01,648 - mmdet - INFO - load checkpoint from http path: https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth
2022-08-18 14:16:01,805 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2022-08-18 14:16:01,829 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
2022-08-18 14:16:01,866 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2022-08-18 14:16:01,947 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2022-08-18 14:16:02,018 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
Name of parameter - Initialization information

backbone.patch_embed.projection.weight - torch.Size([96, 3, 4, 4]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.projection.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.norm.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.norm.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm1.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm2.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.0.0.weight - torch.Size([384, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.0.0.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.1.weight - torch.Size([96, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm1.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm2.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.0.0.weight - torch.Size([384, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.0.0.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.1.weight - torch.Size([96, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.norm.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.norm.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.reduction.weight - torch.Size([192, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm1.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm2.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm2.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm1.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm2.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm2.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.norm.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.norm.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.reduction.weight - torch.Size([384, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.norm.weight - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.norm.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.reduction.weight - torch.Size([768, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.norm0.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm0.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.0.catten.fc1.weight - torch.Size([16, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.catten.fc2.weight - torch.Size([256, 16, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.satten.conv1.weight - torch.Size([1, 2, 7, 7]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.fc1.weight - torch.Size([256, 96, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.catten.fc1.weight - torch.Size([16, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.catten.fc2.weight - torch.Size([256, 16, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.satten.conv1.weight - torch.Size([1, 2, 7, 7]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.fc1.weight - torch.Size([256, 192, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.catten.fc1.weight - torch.Size([16, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.catten.fc2.weight - torch.Size([256, 16, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.satten.conv1.weight - torch.Size([1, 2, 7, 7]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.fc1.weight - torch.Size([256, 384, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.3.catten.fc1.weight - torch.Size([16, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.3.catten.fc2.weight - torch.Size([256, 16, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.3.satten.conv1.weight - torch.Size([1, 2, 7, 7]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.3.fc1.weight - torch.Size([256, 768, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv1.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv2.0.weight - torch.Size([64, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv2.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv2.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv2.2.weight - torch.Size([64, 1, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv2.3.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv2.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv2.4.weight - torch.Size([256, 64, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv2.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv2.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv3.0.weight - torch.Size([64, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv3.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv3.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv3.2.weight - torch.Size([64, 1, 5, 5]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv3.3.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv3.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv3.4.weight - torch.Size([256, 64, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv3.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv3.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv4.0.weight - torch.Size([64, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv4.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv4.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv4.2.weight - torch.Size([64, 1, 7, 7]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv4.3.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv4.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv4.4.weight - torch.Size([256, 64, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv4.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv4.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv_1_1.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv_1_2.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv_1_3.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.bn1_1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.bn1_1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.bn1_2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.bn1_2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.bn1_3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.bn1_3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.project.0.weight - torch.Size([256, 1024, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.project.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.project.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv1.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv2.0.weight - torch.Size([64, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv2.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv2.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv2.2.weight - torch.Size([64, 1, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv2.3.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv2.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv2.4.weight - torch.Size([256, 64, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv2.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv2.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv3.0.weight - torch.Size([64, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv3.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv3.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv3.2.weight - torch.Size([64, 1, 5, 5]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv3.3.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv3.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv3.4.weight - torch.Size([256, 64, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv3.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv3.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv4.0.weight - torch.Size([64, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv4.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv4.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv4.2.weight - torch.Size([64, 1, 7, 7]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv4.3.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv4.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv4.4.weight - torch.Size([256, 64, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv4.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv4.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv_1_1.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv_1_2.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv_1_3.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.bn1_1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.bn1_1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.bn1_2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.bn1_2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.bn1_3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.bn1_3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.project.0.weight - torch.Size([256, 1024, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.project.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.project.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv1.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv2.0.weight - torch.Size([64, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv2.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv2.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv2.2.weight - torch.Size([64, 1, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv2.3.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv2.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv2.4.weight - torch.Size([256, 64, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv2.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv2.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv3.0.weight - torch.Size([64, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv3.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv3.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv3.2.weight - torch.Size([64, 1, 5, 5]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv3.3.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv3.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv3.4.weight - torch.Size([256, 64, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv3.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv3.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv4.0.weight - torch.Size([64, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv4.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv4.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv4.2.weight - torch.Size([64, 1, 7, 7]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv4.3.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv4.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv4.4.weight - torch.Size([256, 64, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv4.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv4.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv_1_1.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv_1_2.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv_1_3.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.bn1_1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.bn1_1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.bn1_2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.bn1_2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.bn1_3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.bn1_3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.project.0.weight - torch.Size([256, 1024, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.project.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.project.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv1.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv2.0.weight - torch.Size([64, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv2.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv2.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv2.2.weight - torch.Size([64, 1, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv2.3.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv2.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv2.4.weight - torch.Size([256, 64, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv2.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv2.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv3.0.weight - torch.Size([64, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv3.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv3.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv3.2.weight - torch.Size([64, 1, 5, 5]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv3.3.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv3.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv3.4.weight - torch.Size([256, 64, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv3.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv3.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv4.0.weight - torch.Size([64, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv4.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv4.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv4.2.weight - torch.Size([64, 1, 7, 7]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv4.3.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv4.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv4.4.weight - torch.Size([256, 64, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv4.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv4.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv_1_1.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv_1_2.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv_1_3.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.bn1_1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.bn1_1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.bn1_2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.bn1_2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.bn1_3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.bn1_3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.project.0.weight - torch.Size([256, 1024, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.project.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.project.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_conv.bias - torch.Size([256]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.bias - torch.Size([3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.bias - torch.Size([12]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_roi_extractor.0.post_module.gamma - torch.Size([1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_roi_extractor.0.post_module.query_conv.weight - torch.Size([252, 256, 1, 1]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.bbox_roi_extractor.0.post_module.value_conv.weight - torch.Size([252, 256, 1, 1]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.bbox_roi_extractor.0.post_module.appr_geom_fc_x.weight - torch.Size([252, 128]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.bbox_roi_extractor.0.post_module.appr_geom_fc_y.weight - torch.Size([252, 128]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.bbox_roi_extractor.0.post_module.proj_conv.weight - torch.Size([256, 252, 1, 1]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.bbox_roi_extractor.0.post_module.proj_conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_roi_extractor.0.pre_module.conv.weight - torch.Size([256, 256, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.bbox_roi_extractor.0.pre_module.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_roi_extractor.1.post_module.gamma - torch.Size([1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_roi_extractor.1.post_module.query_conv.weight - torch.Size([252, 256, 1, 1]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.bbox_roi_extractor.1.post_module.value_conv.weight - torch.Size([252, 256, 1, 1]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.bbox_roi_extractor.1.post_module.appr_geom_fc_x.weight - torch.Size([252, 128]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.bbox_roi_extractor.1.post_module.appr_geom_fc_y.weight - torch.Size([252, 128]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.bbox_roi_extractor.1.post_module.proj_conv.weight - torch.Size([256, 252, 1, 1]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.bbox_roi_extractor.1.post_module.proj_conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_roi_extractor.1.pre_module.conv.weight - torch.Size([256, 256, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.bbox_roi_extractor.1.pre_module.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_roi_extractor.2.post_module.gamma - torch.Size([1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_roi_extractor.2.post_module.query_conv.weight - torch.Size([252, 256, 1, 1]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.bbox_roi_extractor.2.post_module.value_conv.weight - torch.Size([252, 256, 1, 1]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.bbox_roi_extractor.2.post_module.appr_geom_fc_x.weight - torch.Size([252, 128]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.bbox_roi_extractor.2.post_module.appr_geom_fc_y.weight - torch.Size([252, 128]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.bbox_roi_extractor.2.post_module.proj_conv.weight - torch.Size([256, 252, 1, 1]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.bbox_roi_extractor.2.post_module.proj_conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_roi_extractor.2.pre_module.conv.weight - torch.Size([256, 256, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.bbox_roi_extractor.2.pre_module.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.fc_cls.weight - torch.Size([16, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_cls.bias - torch.Size([16]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_reg.weight - torch.Size([4, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.0.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.0.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.0.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.0.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.0.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.fc_cls.weight - torch.Size([16, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.1.fc_cls.bias - torch.Size([16]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.1.fc_reg.weight - torch.Size([4, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.1.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.1.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.fc_cls.weight - torch.Size([16, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.2.fc_cls.bias - torch.Size([16]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.2.fc_reg.weight - torch.Size([4, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.2.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.2.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.mask_head.0.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.upsample.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.upsample.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.conv_logits.weight - torch.Size([15, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.conv_logits.bias - torch.Size([15]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.conv_down_t.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.bn_down_t.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.bn_down_t.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.conv_up_t.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.bn_up_t.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.bn_up_t.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.conv_down_c.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.bn_down_c.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.bn_down_c.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.conv_up_c.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.bn_up_c.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.bn_up_c.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.trans.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.trans.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.trans.attn.q.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.trans.attn.kv.weight - torch.Size([128, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.trans.attn.proj.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.trans.attn.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.trans.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.trans.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.trans.mlp.fc1.weight - torch.Size([256, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.trans.mlp.fc1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.trans.mlp.dwconv.dwconv.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.trans.mlp.dwconv.dwconv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.trans.mlp.fc2.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.trans.mlp.fc2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.trans.patch_embed.proj.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.trans.patch_embed.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.trans.patch_embed.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.trans.patch_embed.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.conv0.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans1.conv1.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.conv_down_t.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.bn_down_t.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.bn_down_t.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.conv_up_t.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.bn_up_t.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.bn_up_t.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.conv_down_c.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.bn_down_c.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.bn_down_c.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.conv_up_c.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.bn_up_c.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.bn_up_c.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.trans.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.trans.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.trans.attn.q.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.trans.attn.kv.weight - torch.Size([128, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.trans.attn.proj.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.trans.attn.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.trans.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.trans.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.trans.mlp.fc1.weight - torch.Size([256, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.trans.mlp.fc1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.trans.mlp.dwconv.dwconv.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.trans.mlp.dwconv.dwconv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.trans.mlp.fc2.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.trans.mlp.fc2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.trans.patch_embed.proj.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.trans.patch_embed.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.trans.patch_embed.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.trans.patch_embed.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.conv0.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans2.conv1.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.conv_down_t.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.bn_down_t.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.bn_down_t.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.conv_up_t.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.bn_up_t.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.bn_up_t.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.conv_down_c.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.bn_down_c.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.bn_down_c.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.conv_up_c.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.bn_up_c.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.bn_up_c.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.trans.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.trans.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.trans.attn.q.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.trans.attn.kv.weight - torch.Size([128, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.trans.attn.proj.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.trans.attn.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.trans.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.trans.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.trans.mlp.fc1.weight - torch.Size([256, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.trans.mlp.fc1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.trans.mlp.dwconv.dwconv.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.trans.mlp.dwconv.dwconv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.trans.mlp.fc2.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.trans.mlp.fc2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.trans.patch_embed.proj.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.trans.patch_embed.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.trans.patch_embed.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.trans.patch_embed.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.conv0.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans3.conv1.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.conv_down_t.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.bn_down_t.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.bn_down_t.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.conv_up_t.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.bn_up_t.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.bn_up_t.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.conv_down_c.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.bn_down_c.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.bn_down_c.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.conv_up_c.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.bn_up_c.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.bn_up_c.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.trans.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.trans.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.trans.attn.q.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.trans.attn.kv.weight - torch.Size([128, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.trans.attn.proj.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.trans.attn.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.trans.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.trans.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.trans.mlp.fc1.weight - torch.Size([256, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.trans.mlp.fc1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.trans.mlp.dwconv.dwconv.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.trans.mlp.dwconv.dwconv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.trans.mlp.fc2.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.trans.mlp.fc2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.trans.patch_embed.proj.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.trans.patch_embed.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.trans.patch_embed.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.trans.patch_embed.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.conv0.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.trans4.conv1.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.upsample.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.upsample.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.conv_logits.weight - torch.Size([15, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.conv_logits.bias - torch.Size([15]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.conv_down_t.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.bn_down_t.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.bn_down_t.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.conv_up_t.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.bn_up_t.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.bn_up_t.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.conv_down_c.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.bn_down_c.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.bn_down_c.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.conv_up_c.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.bn_up_c.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.bn_up_c.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.trans.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.trans.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.trans.attn.q.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.trans.attn.kv.weight - torch.Size([128, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.trans.attn.proj.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.trans.attn.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.trans.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.trans.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.trans.mlp.fc1.weight - torch.Size([256, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.trans.mlp.fc1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.trans.mlp.dwconv.dwconv.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.trans.mlp.dwconv.dwconv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.trans.mlp.fc2.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.trans.mlp.fc2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.trans.patch_embed.proj.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.trans.patch_embed.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.trans.patch_embed.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.trans.patch_embed.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.conv0.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans1.conv1.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.conv_down_t.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.bn_down_t.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.bn_down_t.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.conv_up_t.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.bn_up_t.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.bn_up_t.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.conv_down_c.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.bn_down_c.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.bn_down_c.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.conv_up_c.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.bn_up_c.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.bn_up_c.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.trans.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.trans.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.trans.attn.q.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.trans.attn.kv.weight - torch.Size([128, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.trans.attn.proj.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.trans.attn.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.trans.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.trans.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.trans.mlp.fc1.weight - torch.Size([256, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.trans.mlp.fc1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.trans.mlp.dwconv.dwconv.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.trans.mlp.dwconv.dwconv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.trans.mlp.fc2.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.trans.mlp.fc2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.trans.patch_embed.proj.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.trans.patch_embed.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.trans.patch_embed.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.trans.patch_embed.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.conv0.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans2.conv1.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.conv_down_t.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.bn_down_t.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.bn_down_t.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.conv_up_t.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.bn_up_t.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.bn_up_t.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.conv_down_c.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.bn_down_c.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.bn_down_c.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.conv_up_c.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.bn_up_c.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.bn_up_c.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.trans.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.trans.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.trans.attn.q.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.trans.attn.kv.weight - torch.Size([128, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.trans.attn.proj.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.trans.attn.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.trans.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.trans.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.trans.mlp.fc1.weight - torch.Size([256, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.trans.mlp.fc1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.trans.mlp.dwconv.dwconv.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.trans.mlp.dwconv.dwconv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.trans.mlp.fc2.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.trans.mlp.fc2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.trans.patch_embed.proj.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.trans.patch_embed.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.trans.patch_embed.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.trans.patch_embed.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.conv0.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans3.conv1.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.conv_down_t.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.bn_down_t.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.bn_down_t.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.conv_up_t.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.bn_up_t.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.bn_up_t.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.conv_down_c.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.bn_down_c.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.bn_down_c.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.conv_up_c.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.bn_up_c.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.bn_up_c.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.trans.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.trans.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.trans.attn.q.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.trans.attn.kv.weight - torch.Size([128, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.trans.attn.proj.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.trans.attn.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.trans.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.trans.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.trans.mlp.fc1.weight - torch.Size([256, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.trans.mlp.fc1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.trans.mlp.dwconv.dwconv.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.trans.mlp.dwconv.dwconv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.trans.mlp.fc2.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.trans.mlp.fc2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.trans.patch_embed.proj.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.trans.patch_embed.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.trans.patch_embed.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.trans.patch_embed.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.conv0.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.trans4.conv1.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.upsample.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.upsample.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.conv_logits.weight - torch.Size([15, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.conv_logits.bias - torch.Size([15]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.conv_down_t.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.bn_down_t.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.bn_down_t.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.conv_up_t.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.bn_up_t.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.bn_up_t.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.conv_down_c.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.bn_down_c.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.bn_down_c.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.conv_up_c.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.bn_up_c.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.bn_up_c.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.trans.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.trans.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.trans.attn.q.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.trans.attn.kv.weight - torch.Size([128, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.trans.attn.proj.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.trans.attn.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.trans.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.trans.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.trans.mlp.fc1.weight - torch.Size([256, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.trans.mlp.fc1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.trans.mlp.dwconv.dwconv.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.trans.mlp.dwconv.dwconv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.trans.mlp.fc2.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.trans.mlp.fc2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.trans.patch_embed.proj.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.trans.patch_embed.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.trans.patch_embed.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.trans.patch_embed.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.conv0.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans1.conv1.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.conv_down_t.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.bn_down_t.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.bn_down_t.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.conv_up_t.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.bn_up_t.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.bn_up_t.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.conv_down_c.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.bn_down_c.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.bn_down_c.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.conv_up_c.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.bn_up_c.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.bn_up_c.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.trans.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.trans.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.trans.attn.q.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.trans.attn.kv.weight - torch.Size([128, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.trans.attn.proj.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.trans.attn.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.trans.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.trans.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.trans.mlp.fc1.weight - torch.Size([256, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.trans.mlp.fc1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.trans.mlp.dwconv.dwconv.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.trans.mlp.dwconv.dwconv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.trans.mlp.fc2.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.trans.mlp.fc2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.trans.patch_embed.proj.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.trans.patch_embed.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.trans.patch_embed.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.trans.patch_embed.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.conv0.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans2.conv1.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.conv_down_t.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.bn_down_t.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.bn_down_t.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.conv_up_t.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.bn_up_t.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.bn_up_t.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.conv_down_c.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.bn_down_c.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.bn_down_c.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.conv_up_c.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.bn_up_c.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.bn_up_c.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.trans.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.trans.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.trans.attn.q.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.trans.attn.kv.weight - torch.Size([128, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.trans.attn.proj.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.trans.attn.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.trans.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.trans.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.trans.mlp.fc1.weight - torch.Size([256, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.trans.mlp.fc1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.trans.mlp.dwconv.dwconv.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.trans.mlp.dwconv.dwconv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.trans.mlp.fc2.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.trans.mlp.fc2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.trans.patch_embed.proj.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.trans.patch_embed.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.trans.patch_embed.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.trans.patch_embed.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.conv0.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans3.conv1.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.conv_down_t.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.bn_down_t.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.bn_down_t.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.conv_up_t.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.bn_up_t.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.bn_up_t.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.conv_down_c.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.bn_down_c.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.bn_down_c.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.conv_up_c.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.bn_up_c.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.bn_up_c.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.trans.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.trans.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.trans.attn.q.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.trans.attn.kv.weight - torch.Size([128, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.trans.attn.proj.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.trans.attn.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.trans.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.trans.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.trans.mlp.fc1.weight - torch.Size([256, 64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.trans.mlp.fc1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.trans.mlp.dwconv.dwconv.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.trans.mlp.dwconv.dwconv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.trans.mlp.fc2.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.trans.mlp.fc2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.trans.patch_embed.proj.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.trans.patch_embed.proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.trans.patch_embed.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.trans.patch_embed.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.conv0.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.trans4.conv1.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_roi_extractor.0.post_module.gamma - torch.Size([1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_roi_extractor.0.post_module.query_conv.weight - torch.Size([252, 256, 1, 1]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.mask_roi_extractor.0.post_module.value_conv.weight - torch.Size([252, 256, 1, 1]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.mask_roi_extractor.0.post_module.appr_geom_fc_x.weight - torch.Size([252, 128]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.mask_roi_extractor.0.post_module.appr_geom_fc_y.weight - torch.Size([252, 128]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.mask_roi_extractor.0.post_module.proj_conv.weight - torch.Size([256, 252, 1, 1]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.mask_roi_extractor.0.post_module.proj_conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_roi_extractor.0.pre_module.conv.weight - torch.Size([256, 256, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.mask_roi_extractor.0.pre_module.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_roi_extractor.1.post_module.gamma - torch.Size([1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_roi_extractor.1.post_module.query_conv.weight - torch.Size([252, 256, 1, 1]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.mask_roi_extractor.1.post_module.value_conv.weight - torch.Size([252, 256, 1, 1]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.mask_roi_extractor.1.post_module.appr_geom_fc_x.weight - torch.Size([252, 128]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.mask_roi_extractor.1.post_module.appr_geom_fc_y.weight - torch.Size([252, 128]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.mask_roi_extractor.1.post_module.proj_conv.weight - torch.Size([256, 252, 1, 1]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.mask_roi_extractor.1.post_module.proj_conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_roi_extractor.1.pre_module.conv.weight - torch.Size([256, 256, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.mask_roi_extractor.1.pre_module.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_roi_extractor.2.post_module.gamma - torch.Size([1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_roi_extractor.2.post_module.query_conv.weight - torch.Size([252, 256, 1, 1]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.mask_roi_extractor.2.post_module.value_conv.weight - torch.Size([252, 256, 1, 1]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.mask_roi_extractor.2.post_module.appr_geom_fc_x.weight - torch.Size([252, 128]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.mask_roi_extractor.2.post_module.appr_geom_fc_y.weight - torch.Size([252, 128]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.mask_roi_extractor.2.post_module.proj_conv.weight - torch.Size([256, 252, 1, 1]): 
Initialized by user-defined `init_weights` in GeneralizedAttention  

roi_head.mask_roi_extractor.2.post_module.proj_conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_roi_extractor.2.pre_module.conv.weight - torch.Size([256, 256, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.mask_roi_extractor.2.pre_module.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  
2022-08-18 14:16:26,007 - mmdet - INFO - load checkpoint from local path: ./work_dirs/cascade-mask-rcnn-SWIN-right-lable-maskhead-add-ciou-softnms-groie-diceloss-tta-multiscaletrain-sample1000/epoch_11.pth
2022-08-18 14:16:27,016 - mmdet - INFO - resumed epoch 11, iter 206019
2022-08-18 14:16:27,018 - mmdet - INFO - Start running, host: zwc@localhost.localdomain, work_dir: /home/zwc/Documents/mmdetection/work_dirs/cascade-mask-rcnn-SWIN-right-lable-maskhead-add-ciou-softnms-groie-diceloss-tta-multiscaletrain-sample1000
2022-08-18 14:16:27,018 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2022-08-18 14:16:27,019 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs
2022-08-18 14:16:27,019 - mmdet - INFO - Checkpoints will be saved to /home/zwc/Documents/mmdetection/work_dirs/cascade-mask-rcnn-SWIN-right-lable-maskhead-add-ciou-softnms-groie-diceloss-tta-multiscaletrain-sample1000 by HardDiskBackend.
2022-08-18 14:16:57,944 - mmdet - INFO - Epoch [12][50/18729]	lr: 1.000e-05, eta: 3:12:30, time: 0.618, data_time: 0.072, memory: 10975, loss_rpn_cls: 0.0218, loss_rpn_bbox: 0.0759, s0.loss_cls: 0.0705, s0.acc: 97.3086, s0.loss_bbox: 0.0502, s0.loss_mask: 0.4142, s1.loss_cls: 0.0330, s1.acc: 97.6877, s1.loss_bbox: 0.0252, s1.loss_mask: 0.2158, s2.loss_cls: 0.0174, s2.acc: 97.3600, s2.loss_bbox: 0.0111, s2.loss_mask: 0.1055, loss: 1.0406
2022-08-18 14:17:26,147 - mmdet - INFO - Epoch [12][100/18729]	lr: 1.000e-05, eta: 3:03:33, time: 0.564, data_time: 0.023, memory: 10975, loss_rpn_cls: 0.0218, loss_rpn_bbox: 0.1000, s0.loss_cls: 0.0812, s0.acc: 96.8672, s0.loss_bbox: 0.0609, s0.loss_mask: 0.4562, s1.loss_cls: 0.0342, s1.acc: 97.3282, s1.loss_bbox: 0.0296, s1.loss_mask: 0.2310, s2.loss_cls: 0.0181, s2.acc: 97.1987, s2.loss_bbox: 0.0130, s2.loss_mask: 0.1108, loss: 1.1568
2022-08-18 14:17:54,718 - mmdet - INFO - Epoch [12][150/18729]	lr: 1.000e-05, eta: 3:01:01, time: 0.571, data_time: 0.026, memory: 10989, loss_rpn_cls: 0.0196, loss_rpn_bbox: 0.0845, s0.loss_cls: 0.0711, s0.acc: 97.1641, s0.loss_bbox: 0.0521, s0.loss_mask: 0.5042, s1.loss_cls: 0.0299, s1.acc: 97.6713, s1.loss_bbox: 0.0257, s1.loss_mask: 0.2565, s2.loss_cls: 0.0157, s2.acc: 97.3183, s2.loss_bbox: 0.0115, s2.loss_mask: 0.1258, loss: 1.1966
2022-08-18 14:18:22,419 - mmdet - INFO - Epoch [12][200/18729]	lr: 1.000e-05, eta: 2:58:10, time: 0.554, data_time: 0.033, memory: 10989, loss_rpn_cls: 0.0205, loss_rpn_bbox: 0.0835, s0.loss_cls: 0.0574, s0.acc: 97.8281, s0.loss_bbox: 0.0468, s0.loss_mask: 0.6114, s1.loss_cls: 0.0278, s1.acc: 97.9421, s1.loss_bbox: 0.0222, s1.loss_mask: 0.3068, s2.loss_cls: 0.0163, s2.acc: 97.5076, s2.loss_bbox: 0.0095, s2.loss_mask: 0.1497, loss: 1.3520
2022-08-18 14:18:50,814 - mmdet - INFO - Epoch [12][250/18729]	lr: 1.000e-05, eta: 2:57:07, time: 0.568, data_time: 0.023, memory: 10989, loss_rpn_cls: 0.0154, loss_rpn_bbox: 0.0866, s0.loss_cls: 0.0688, s0.acc: 97.2930, s0.loss_bbox: 0.0583, s0.loss_mask: 0.4138, s1.loss_cls: 0.0293, s1.acc: 97.8824, s1.loss_bbox: 0.0290, s1.loss_mask: 0.2186, s2.loss_cls: 0.0173, s2.acc: 97.2936, s2.loss_bbox: 0.0129, s2.loss_mask: 0.1061, loss: 1.0561
2022-08-18 14:19:18,637 - mmdet - INFO - Epoch [12][300/18729]	lr: 1.000e-05, eta: 2:55:41, time: 0.556, data_time: 0.023, memory: 10989, loss_rpn_cls: 0.0189, loss_rpn_bbox: 0.0727, s0.loss_cls: 0.0689, s0.acc: 97.3477, s0.loss_bbox: 0.0484, s0.loss_mask: 0.4665, s1.loss_cls: 0.0308, s1.acc: 97.6312, s1.loss_bbox: 0.0242, s1.loss_mask: 0.2371, s2.loss_cls: 0.0162, s2.acc: 97.5037, s2.loss_bbox: 0.0109, s2.loss_mask: 0.1162, loss: 1.1109
2022-08-18 14:19:49,739 - mmdet - INFO - Epoch [12][350/18729]	lr: 1.000e-05, eta: 2:57:24, time: 0.622, data_time: 0.055, memory: 11785, loss_rpn_cls: 0.0224, loss_rpn_bbox: 0.1169, s0.loss_cls: 0.0804, s0.acc: 96.7188, s0.loss_bbox: 0.0630, s0.loss_mask: 0.5281, s1.loss_cls: 0.0362, s1.acc: 97.1302, s1.loss_bbox: 0.0289, s1.loss_mask: 0.2727, s2.loss_cls: 0.0200, s2.acc: 96.8009, s2.loss_bbox: 0.0122, s2.loss_mask: 0.1311, loss: 1.3120
2022-08-18 14:20:17,725 - mmdet - INFO - Epoch [12][400/18729]	lr: 1.000e-05, eta: 2:56:10, time: 0.560, data_time: 0.026, memory: 11785, loss_rpn_cls: 0.0195, loss_rpn_bbox: 0.0907, s0.loss_cls: 0.0804, s0.acc: 96.9258, s0.loss_bbox: 0.0558, s0.loss_mask: 0.4654, s1.loss_cls: 0.0333, s1.acc: 97.5327, s1.loss_bbox: 0.0263, s1.loss_mask: 0.2345, s2.loss_cls: 0.0176, s2.acc: 97.4259, s2.loss_bbox: 0.0112, s2.loss_mask: 0.1118, loss: 1.1465
2022-08-18 14:20:45,828 - mmdet - INFO - Epoch [12][450/18729]	lr: 1.000e-05, eta: 2:55:12, time: 0.562, data_time: 0.036, memory: 11785, loss_rpn_cls: 0.0197, loss_rpn_bbox: 0.0925, s0.loss_cls: 0.0646, s0.acc: 97.2812, s0.loss_bbox: 0.0488, s0.loss_mask: 0.4561, s1.loss_cls: 0.0277, s1.acc: 97.8862, s1.loss_bbox: 0.0235, s1.loss_mask: 0.2336, s2.loss_cls: 0.0159, s2.acc: 97.5782, s2.loss_bbox: 0.0100, s2.loss_mask: 0.1133, loss: 1.1059
2022-08-18 14:21:13,455 - mmdet - INFO - Epoch [12][500/18729]	lr: 1.000e-05, eta: 2:54:02, time: 0.553, data_time: 0.022, memory: 11785, loss_rpn_cls: 0.0302, loss_rpn_bbox: 0.1085, s0.loss_cls: 0.0692, s0.acc: 97.1953, s0.loss_bbox: 0.0574, s0.loss_mask: 0.3944, s1.loss_cls: 0.0291, s1.acc: 97.7764, s1.loss_bbox: 0.0260, s1.loss_mask: 0.2019, s2.loss_cls: 0.0151, s2.acc: 97.6650, s2.loss_bbox: 0.0110, s2.loss_mask: 0.0967, loss: 1.0396
2022-08-18 14:21:48,461 - mmdet - INFO - Epoch [12][550/18729]	lr: 1.000e-05, eta: 2:57:04, time: 0.700, data_time: 0.145, memory: 12528, loss_rpn_cls: 0.0258, loss_rpn_bbox: 0.0913, s0.loss_cls: 0.0832, s0.acc: 96.6914, s0.loss_bbox: 0.0597, s0.loss_mask: 0.4715, s1.loss_cls: 0.0369, s1.acc: 97.0466, s1.loss_bbox: 0.0273, s1.loss_mask: 0.2371, s2.loss_cls: 0.0187, s2.acc: 97.0174, s2.loss_bbox: 0.0119, s2.loss_mask: 0.1157, loss: 1.1790
2022-08-18 14:22:15,935 - mmdet - INFO - Epoch [12][600/18729]	lr: 1.000e-05, eta: 2:55:42, time: 0.549, data_time: 0.036, memory: 12528, loss_rpn_cls: 0.0191, loss_rpn_bbox: 0.0554, s0.loss_cls: 0.0597, s0.acc: 97.6914, s0.loss_bbox: 0.0390, s0.loss_mask: 0.5249, s1.loss_cls: 0.0262, s1.acc: 98.0531, s1.loss_bbox: 0.0180, s1.loss_mask: 0.2789, s2.loss_cls: 0.0140, s2.acc: 97.7540, s2.loss_bbox: 0.0075, s2.loss_mask: 0.1381, loss: 1.1807
2022-08-18 14:22:44,793 - mmdet - INFO - Epoch [12][650/18729]	lr: 1.000e-05, eta: 2:55:06, time: 0.577, data_time: 0.037, memory: 12528, loss_rpn_cls: 0.0228, loss_rpn_bbox: 0.0886, s0.loss_cls: 0.0758, s0.acc: 97.1914, s0.loss_bbox: 0.0530, s0.loss_mask: 0.4608, s1.loss_cls: 0.0359, s1.acc: 97.3928, s1.loss_bbox: 0.0257, s1.loss_mask: 0.2327, s2.loss_cls: 0.0180, s2.acc: 97.1643, s2.loss_bbox: 0.0110, s2.loss_mask: 0.1125, loss: 1.1368
2022-08-18 14:23:12,605 - mmdet - INFO - Epoch [12][700/18729]	lr: 1.000e-05, eta: 2:54:05, time: 0.556, data_time: 0.024, memory: 12528, loss_rpn_cls: 0.0152, loss_rpn_bbox: 0.1025, s0.loss_cls: 0.0829, s0.acc: 96.7422, s0.loss_bbox: 0.0632, s0.loss_mask: 0.4740, s1.loss_cls: 0.0340, s1.acc: 97.4555, s1.loss_bbox: 0.0300, s1.loss_mask: 0.2347, s2.loss_cls: 0.0187, s2.acc: 97.1849, s2.loss_bbox: 0.0129, s2.loss_mask: 0.1108, loss: 1.1790
2022-08-18 14:23:42,954 - mmdet - INFO - Epoch [12][750/18729]	lr: 1.000e-05, eta: 2:54:09, time: 0.607, data_time: 0.063, memory: 12528, loss_rpn_cls: 0.0207, loss_rpn_bbox: 0.0973, s0.loss_cls: 0.0950, s0.acc: 96.3203, s0.loss_bbox: 0.0582, s0.loss_mask: 0.4598, s1.loss_cls: 0.0428, s1.acc: 96.7759, s1.loss_bbox: 0.0280, s1.loss_mask: 0.2378, s2.loss_cls: 0.0224, s2.acc: 96.6309, s2.loss_bbox: 0.0123, s2.loss_mask: 0.1169, loss: 1.1914
2022-08-18 14:24:10,215 - mmdet - INFO - Epoch [12][800/18729]	lr: 1.000e-05, eta: 2:53:00, time: 0.545, data_time: 0.023, memory: 12528, loss_rpn_cls: 0.0219, loss_rpn_bbox: 0.0970, s0.loss_cls: 0.0701, s0.acc: 97.2852, s0.loss_bbox: 0.0552, s0.loss_mask: 0.4803, s1.loss_cls: 0.0305, s1.acc: 97.6455, s1.loss_bbox: 0.0265, s1.loss_mask: 0.2401, s2.loss_cls: 0.0169, s2.acc: 97.4084, s2.loss_bbox: 0.0114, s2.loss_mask: 0.1156, loss: 1.1654
2022-08-18 14:24:37,562 - mmdet - INFO - Epoch [12][850/18729]	lr: 1.000e-05, eta: 2:51:57, time: 0.547, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0196, loss_rpn_bbox: 0.0792, s0.loss_cls: 0.0765, s0.acc: 96.9297, s0.loss_bbox: 0.0540, s0.loss_mask: 0.4565, s1.loss_cls: 0.0338, s1.acc: 97.4585, s1.loss_bbox: 0.0266, s1.loss_mask: 0.2314, s2.loss_cls: 0.0189, s2.acc: 96.9912, s2.loss_bbox: 0.0118, s2.loss_mask: 0.1125, loss: 1.1207
2022-08-18 14:25:05,250 - mmdet - INFO - Epoch [12][900/18729]	lr: 1.000e-05, eta: 2:51:05, time: 0.554, data_time: 0.027, memory: 12528, loss_rpn_cls: 0.0226, loss_rpn_bbox: 0.1021, s0.loss_cls: 0.0672, s0.acc: 97.3789, s0.loss_bbox: 0.0549, s0.loss_mask: 0.5236, s1.loss_cls: 0.0293, s1.acc: 97.8677, s1.loss_bbox: 0.0260, s1.loss_mask: 0.2680, s2.loss_cls: 0.0163, s2.acc: 97.4373, s2.loss_bbox: 0.0113, s2.loss_mask: 0.1312, loss: 1.2524
2022-08-18 14:25:33,062 - mmdet - INFO - Epoch [12][950/18729]	lr: 1.000e-05, eta: 2:50:18, time: 0.556, data_time: 0.027, memory: 12528, loss_rpn_cls: 0.0173, loss_rpn_bbox: 0.0855, s0.loss_cls: 0.0757, s0.acc: 96.9570, s0.loss_bbox: 0.0602, s0.loss_mask: 0.4354, s1.loss_cls: 0.0300, s1.acc: 97.5872, s1.loss_bbox: 0.0284, s1.loss_mask: 0.2234, s2.loss_cls: 0.0171, s2.acc: 97.1471, s2.loss_bbox: 0.0127, s2.loss_mask: 0.1087, loss: 1.0944
2022-08-18 14:26:01,336 - mmdet - INFO - Epoch [12][1000/18729]	lr: 1.000e-05, eta: 2:49:41, time: 0.565, data_time: 0.036, memory: 12528, loss_rpn_cls: 0.0146, loss_rpn_bbox: 0.0791, s0.loss_cls: 0.0709, s0.acc: 97.1211, s0.loss_bbox: 0.0528, s0.loss_mask: 0.5197, s1.loss_cls: 0.0300, s1.acc: 97.5458, s1.loss_bbox: 0.0251, s1.loss_mask: 0.2580, s2.loss_cls: 0.0167, s2.acc: 97.2278, s2.loss_bbox: 0.0113, s2.loss_mask: 0.1209, loss: 1.1989
2022-08-18 14:26:28,687 - mmdet - INFO - Epoch [12][1050/18729]	lr: 1.000e-05, eta: 2:48:50, time: 0.547, data_time: 0.027, memory: 12528, loss_rpn_cls: 0.0228, loss_rpn_bbox: 0.0845, s0.loss_cls: 0.0677, s0.acc: 97.3594, s0.loss_bbox: 0.0493, s0.loss_mask: 0.5108, s1.loss_cls: 0.0287, s1.acc: 97.8822, s1.loss_bbox: 0.0230, s1.loss_mask: 0.2563, s2.loss_cls: 0.0153, s2.acc: 97.7249, s2.loss_bbox: 0.0094, s2.loss_mask: 0.1252, loss: 1.1930
2022-08-18 14:26:56,177 - mmdet - INFO - Epoch [12][1100/18729]	lr: 1.000e-05, eta: 2:48:02, time: 0.550, data_time: 0.030, memory: 12528, loss_rpn_cls: 0.0174, loss_rpn_bbox: 0.0699, s0.loss_cls: 0.0632, s0.acc: 97.6758, s0.loss_bbox: 0.0462, s0.loss_mask: 0.4615, s1.loss_cls: 0.0295, s1.acc: 97.8850, s1.loss_bbox: 0.0223, s1.loss_mask: 0.2357, s2.loss_cls: 0.0179, s2.acc: 97.3698, s2.loss_bbox: 0.0095, s2.loss_mask: 0.1130, loss: 1.0860
2022-08-18 14:27:24,365 - mmdet - INFO - Epoch [12][1150/18729]	lr: 1.000e-05, eta: 2:47:27, time: 0.564, data_time: 0.021, memory: 12528, loss_rpn_cls: 0.0214, loss_rpn_bbox: 0.1125, s0.loss_cls: 0.0872, s0.acc: 96.5977, s0.loss_bbox: 0.0642, s0.loss_mask: 0.3786, s1.loss_cls: 0.0361, s1.acc: 97.3662, s1.loss_bbox: 0.0305, s1.loss_mask: 0.2008, s2.loss_cls: 0.0187, s2.acc: 97.2393, s2.loss_bbox: 0.0136, s2.loss_mask: 0.0973, loss: 1.0610
2022-08-18 14:27:52,389 - mmdet - INFO - Epoch [12][1200/18729]	lr: 1.000e-05, eta: 2:46:51, time: 0.560, data_time: 0.019, memory: 12528, loss_rpn_cls: 0.0259, loss_rpn_bbox: 0.0987, s0.loss_cls: 0.0782, s0.acc: 96.9062, s0.loss_bbox: 0.0591, s0.loss_mask: 0.4831, s1.loss_cls: 0.0327, s1.acc: 97.4930, s1.loss_bbox: 0.0287, s1.loss_mask: 0.2499, s2.loss_cls: 0.0174, s2.acc: 97.3452, s2.loss_bbox: 0.0125, s2.loss_mask: 0.1223, loss: 1.2085
2022-08-18 14:28:19,582 - mmdet - INFO - Epoch [12][1250/18729]	lr: 1.000e-05, eta: 2:46:03, time: 0.544, data_time: 0.025, memory: 12528, loss_rpn_cls: 0.0196, loss_rpn_bbox: 0.0681, s0.loss_cls: 0.0682, s0.acc: 97.2266, s0.loss_bbox: 0.0466, s0.loss_mask: 0.4526, s1.loss_cls: 0.0318, s1.acc: 97.5692, s1.loss_bbox: 0.0235, s1.loss_mask: 0.2312, s2.loss_cls: 0.0164, s2.acc: 97.3616, s2.loss_bbox: 0.0106, s2.loss_mask: 0.1137, loss: 1.0823
2022-08-18 14:28:47,106 - mmdet - INFO - Epoch [12][1300/18729]	lr: 1.000e-05, eta: 2:45:22, time: 0.550, data_time: 0.015, memory: 12528, loss_rpn_cls: 0.0155, loss_rpn_bbox: 0.0693, s0.loss_cls: 0.0664, s0.acc: 97.3633, s0.loss_bbox: 0.0551, s0.loss_mask: 0.4420, s1.loss_cls: 0.0277, s1.acc: 97.8841, s1.loss_bbox: 0.0277, s1.loss_mask: 0.2230, s2.loss_cls: 0.0146, s2.acc: 97.7242, s2.loss_bbox: 0.0128, s2.loss_mask: 0.1096, loss: 1.0636
2022-08-18 14:29:13,691 - mmdet - INFO - Epoch [12][1350/18729]	lr: 1.000e-05, eta: 2:44:29, time: 0.532, data_time: 0.021, memory: 12528, loss_rpn_cls: 0.0265, loss_rpn_bbox: 0.0689, s0.loss_cls: 0.0659, s0.acc: 97.4141, s0.loss_bbox: 0.0431, s0.loss_mask: 0.4776, s1.loss_cls: 0.0298, s1.acc: 97.8869, s1.loss_bbox: 0.0214, s1.loss_mask: 0.2419, s2.loss_cls: 0.0164, s2.acc: 97.5764, s2.loss_bbox: 0.0090, s2.loss_mask: 0.1174, loss: 1.1179
2022-08-18 14:29:42,103 - mmdet - INFO - Epoch [12][1400/18729]	lr: 1.000e-05, eta: 2:44:01, time: 0.568, data_time: 0.037, memory: 12528, loss_rpn_cls: 0.0201, loss_rpn_bbox: 0.0871, s0.loss_cls: 0.0756, s0.acc: 97.1250, s0.loss_bbox: 0.0519, s0.loss_mask: 0.5012, s1.loss_cls: 0.0365, s1.acc: 97.1991, s1.loss_bbox: 0.0236, s1.loss_mask: 0.2534, s2.loss_cls: 0.0189, s2.acc: 97.1069, s2.loss_bbox: 0.0100, s2.loss_mask: 0.1207, loss: 1.1990
2022-08-18 14:30:09,033 - mmdet - INFO - Epoch [12][1450/18729]	lr: 1.000e-05, eta: 2:43:15, time: 0.539, data_time: 0.023, memory: 12528, loss_rpn_cls: 0.0138, loss_rpn_bbox: 0.0736, s0.loss_cls: 0.0663, s0.acc: 97.5273, s0.loss_bbox: 0.0538, s0.loss_mask: 0.4439, s1.loss_cls: 0.0318, s1.acc: 97.6396, s1.loss_bbox: 0.0259, s1.loss_mask: 0.2299, s2.loss_cls: 0.0174, s2.acc: 97.3706, s2.loss_bbox: 0.0109, s2.loss_mask: 0.1115, loss: 1.0787
2022-08-18 14:30:36,092 - mmdet - INFO - Epoch [12][1500/18729]	lr: 1.000e-05, eta: 2:42:32, time: 0.541, data_time: 0.026, memory: 12528, loss_rpn_cls: 0.0237, loss_rpn_bbox: 0.0948, s0.loss_cls: 0.0658, s0.acc: 97.3945, s0.loss_bbox: 0.0519, s0.loss_mask: 0.5176, s1.loss_cls: 0.0260, s1.acc: 98.0515, s1.loss_bbox: 0.0249, s1.loss_mask: 0.2764, s2.loss_cls: 0.0161, s2.acc: 97.5370, s2.loss_bbox: 0.0106, s2.loss_mask: 0.1331, loss: 1.2411
2022-08-18 14:31:10,227 - mmdet - INFO - Epoch [12][1550/18729]	lr: 1.000e-05, eta: 2:43:08, time: 0.683, data_time: 0.128, memory: 12528, loss_rpn_cls: 0.0220, loss_rpn_bbox: 0.0843, s0.loss_cls: 0.0782, s0.acc: 96.8906, s0.loss_bbox: 0.0567, s0.loss_mask: 0.4282, s1.loss_cls: 0.0307, s1.acc: 97.6150, s1.loss_bbox: 0.0263, s1.loss_mask: 0.2246, s2.loss_cls: 0.0159, s2.acc: 97.5444, s2.loss_bbox: 0.0117, s2.loss_mask: 0.1092, loss: 1.0880
2022-08-18 14:31:36,703 - mmdet - INFO - Epoch [12][1600/18729]	lr: 1.000e-05, eta: 2:42:18, time: 0.530, data_time: 0.019, memory: 12528, loss_rpn_cls: 0.0205, loss_rpn_bbox: 0.0714, s0.loss_cls: 0.0703, s0.acc: 97.1992, s0.loss_bbox: 0.0528, s0.loss_mask: 0.4105, s1.loss_cls: 0.0294, s1.acc: 97.8508, s1.loss_bbox: 0.0259, s1.loss_mask: 0.2084, s2.loss_cls: 0.0146, s2.acc: 97.8076, s2.loss_bbox: 0.0116, s2.loss_mask: 0.1031, loss: 1.0185
2022-08-18 14:32:03,447 - mmdet - INFO - Epoch [12][1650/18729]	lr: 1.000e-05, eta: 2:41:32, time: 0.535, data_time: 0.018, memory: 12528, loss_rpn_cls: 0.0205, loss_rpn_bbox: 0.0843, s0.loss_cls: 0.0687, s0.acc: 97.4180, s0.loss_bbox: 0.0507, s0.loss_mask: 0.4050, s1.loss_cls: 0.0315, s1.acc: 97.5814, s1.loss_bbox: 0.0249, s1.loss_mask: 0.2055, s2.loss_cls: 0.0183, s2.acc: 97.0921, s2.loss_bbox: 0.0109, s2.loss_mask: 0.0991, loss: 1.0193
2022-08-18 14:32:30,406 - mmdet - INFO - Epoch [12][1700/18729]	lr: 1.000e-05, eta: 2:40:50, time: 0.539, data_time: 0.030, memory: 12528, loss_rpn_cls: 0.0204, loss_rpn_bbox: 0.0680, s0.loss_cls: 0.0584, s0.acc: 97.6680, s0.loss_bbox: 0.0446, s0.loss_mask: 0.4510, s1.loss_cls: 0.0244, s1.acc: 98.1142, s1.loss_bbox: 0.0214, s1.loss_mask: 0.2318, s2.loss_cls: 0.0144, s2.acc: 97.7968, s2.loss_bbox: 0.0092, s2.loss_mask: 0.1138, loss: 1.0574
2022-08-18 14:32:58,698 - mmdet - INFO - Epoch [12][1750/18729]	lr: 1.000e-05, eta: 2:40:21, time: 0.566, data_time: 0.031, memory: 12528, loss_rpn_cls: 0.0232, loss_rpn_bbox: 0.0983, s0.loss_cls: 0.0747, s0.acc: 97.0703, s0.loss_bbox: 0.0534, s0.loss_mask: 0.4619, s1.loss_cls: 0.0321, s1.acc: 97.8160, s1.loss_bbox: 0.0268, s1.loss_mask: 0.2347, s2.loss_cls: 0.0173, s2.acc: 97.6520, s2.loss_bbox: 0.0115, s2.loss_mask: 0.1142, loss: 1.1481
2022-08-18 14:33:26,776 - mmdet - INFO - Epoch [12][1800/18729]	lr: 1.000e-05, eta: 2:39:50, time: 0.562, data_time: 0.022, memory: 12528, loss_rpn_cls: 0.0167, loss_rpn_bbox: 0.0983, s0.loss_cls: 0.0766, s0.acc: 96.9648, s0.loss_bbox: 0.0615, s0.loss_mask: 0.4212, s1.loss_cls: 0.0317, s1.acc: 97.6621, s1.loss_bbox: 0.0298, s1.loss_mask: 0.2156, s2.loss_cls: 0.0181, s2.acc: 97.2817, s2.loss_bbox: 0.0132, s2.loss_mask: 0.1048, loss: 1.0876
2022-08-18 14:33:56,027 - mmdet - INFO - Epoch [12][1850/18729]	lr: 1.000e-05, eta: 2:39:30, time: 0.585, data_time: 0.035, memory: 12528, loss_rpn_cls: 0.0270, loss_rpn_bbox: 0.1159, s0.loss_cls: 0.0835, s0.acc: 96.8750, s0.loss_bbox: 0.0658, s0.loss_mask: 0.4610, s1.loss_cls: 0.0334, s1.acc: 97.5564, s1.loss_bbox: 0.0297, s1.loss_mask: 0.2368, s2.loss_cls: 0.0197, s2.acc: 97.0295, s2.loss_bbox: 0.0126, s2.loss_mask: 0.1133, loss: 1.1987
2022-08-18 14:34:23,999 - mmdet - INFO - Epoch [12][1900/18729]	lr: 1.000e-05, eta: 2:38:58, time: 0.559, data_time: 0.027, memory: 12528, loss_rpn_cls: 0.0201, loss_rpn_bbox: 0.1036, s0.loss_cls: 0.0742, s0.acc: 97.0703, s0.loss_bbox: 0.0581, s0.loss_mask: 0.4705, s1.loss_cls: 0.0325, s1.acc: 97.6183, s1.loss_bbox: 0.0274, s1.loss_mask: 0.2391, s2.loss_cls: 0.0182, s2.acc: 96.9392, s2.loss_bbox: 0.0117, s2.loss_mask: 0.1167, loss: 1.1719
2022-08-18 14:34:49,698 - mmdet - INFO - Epoch [12][1950/18729]	lr: 1.000e-05, eta: 2:38:07, time: 0.514, data_time: 0.018, memory: 12528, loss_rpn_cls: 0.0215, loss_rpn_bbox: 0.0791, s0.loss_cls: 0.0524, s0.acc: 98.1328, s0.loss_bbox: 0.0460, s0.loss_mask: 0.4472, s1.loss_cls: 0.0237, s1.acc: 98.4029, s1.loss_bbox: 0.0235, s1.loss_mask: 0.2325, s2.loss_cls: 0.0128, s2.acc: 98.1484, s2.loss_bbox: 0.0102, s2.loss_mask: 0.1124, loss: 1.0614
2022-08-18 14:35:19,749 - mmdet - INFO - Epoch [12][2000/18729]	lr: 1.000e-05, eta: 2:37:54, time: 0.601, data_time: 0.063, memory: 12528, loss_rpn_cls: 0.0212, loss_rpn_bbox: 0.0827, s0.loss_cls: 0.0614, s0.acc: 97.6914, s0.loss_bbox: 0.0489, s0.loss_mask: 0.4894, s1.loss_cls: 0.0283, s1.acc: 97.9808, s1.loss_bbox: 0.0230, s1.loss_mask: 0.2528, s2.loss_cls: 0.0148, s2.acc: 97.6880, s2.loss_bbox: 0.0097, s2.loss_mask: 0.1219, loss: 1.1540
2022-08-18 14:35:46,772 - mmdet - INFO - Epoch [12][2050/18729]	lr: 1.000e-05, eta: 2:37:15, time: 0.540, data_time: 0.032, memory: 12528, loss_rpn_cls: 0.0200, loss_rpn_bbox: 0.0797, s0.loss_cls: 0.0623, s0.acc: 97.5859, s0.loss_bbox: 0.0456, s0.loss_mask: 0.4909, s1.loss_cls: 0.0277, s1.acc: 98.0140, s1.loss_bbox: 0.0225, s1.loss_mask: 0.2540, s2.loss_cls: 0.0156, s2.acc: 97.7142, s2.loss_bbox: 0.0101, s2.loss_mask: 0.1226, loss: 1.1508
2022-08-18 14:36:15,563 - mmdet - INFO - Epoch [12][2100/18729]	lr: 1.000e-05, eta: 2:36:51, time: 0.576, data_time: 0.033, memory: 12528, loss_rpn_cls: 0.0173, loss_rpn_bbox: 0.0976, s0.loss_cls: 0.0803, s0.acc: 96.8086, s0.loss_bbox: 0.0581, s0.loss_mask: 0.4570, s1.loss_cls: 0.0356, s1.acc: 97.1695, s1.loss_bbox: 0.0274, s1.loss_mask: 0.2348, s2.loss_cls: 0.0194, s2.acc: 96.9334, s2.loss_bbox: 0.0120, s2.loss_mask: 0.1122, loss: 1.1519
2022-08-18 14:36:41,590 - mmdet - INFO - Epoch [12][2150/18729]	lr: 1.000e-05, eta: 2:36:05, time: 0.521, data_time: 0.014, memory: 12528, loss_rpn_cls: 0.0180, loss_rpn_bbox: 0.1073, s0.loss_cls: 0.0747, s0.acc: 97.0430, s0.loss_bbox: 0.0567, s0.loss_mask: 0.4163, s1.loss_cls: 0.0315, s1.acc: 97.5970, s1.loss_bbox: 0.0262, s1.loss_mask: 0.2125, s2.loss_cls: 0.0166, s2.acc: 97.4967, s2.loss_bbox: 0.0114, s2.loss_mask: 0.1035, loss: 1.0748
2022-08-18 14:37:11,663 - mmdet - INFO - Epoch [12][2200/18729]	lr: 1.000e-05, eta: 2:35:51, time: 0.601, data_time: 0.053, memory: 12528, loss_rpn_cls: 0.0225, loss_rpn_bbox: 0.0947, s0.loss_cls: 0.0746, s0.acc: 97.1172, s0.loss_bbox: 0.0535, s0.loss_mask: 0.4837, s1.loss_cls: 0.0343, s1.acc: 97.4233, s1.loss_bbox: 0.0251, s1.loss_mask: 0.2478, s2.loss_cls: 0.0186, s2.acc: 97.1804, s2.loss_bbox: 0.0106, s2.loss_mask: 0.1215, loss: 1.1870
2022-08-18 14:37:37,579 - mmdet - INFO - Epoch [12][2250/18729]	lr: 1.000e-05, eta: 2:35:05, time: 0.518, data_time: 0.017, memory: 12528, loss_rpn_cls: 0.0159, loss_rpn_bbox: 0.0626, s0.loss_cls: 0.0545, s0.acc: 97.7812, s0.loss_bbox: 0.0434, s0.loss_mask: 0.4309, s1.loss_cls: 0.0227, s1.acc: 98.3355, s1.loss_bbox: 0.0225, s1.loss_mask: 0.2195, s2.loss_cls: 0.0130, s2.acc: 97.9792, s2.loss_bbox: 0.0098, s2.loss_mask: 0.1068, loss: 1.0016
2022-08-18 14:38:06,442 - mmdet - INFO - Epoch [12][2300/18729]	lr: 1.000e-05, eta: 2:34:41, time: 0.577, data_time: 0.035, memory: 12528, loss_rpn_cls: 0.0222, loss_rpn_bbox: 0.1006, s0.loss_cls: 0.0719, s0.acc: 97.1133, s0.loss_bbox: 0.0630, s0.loss_mask: 0.4698, s1.loss_cls: 0.0298, s1.acc: 97.7008, s1.loss_bbox: 0.0297, s1.loss_mask: 0.2376, s2.loss_cls: 0.0162, s2.acc: 97.4593, s2.loss_bbox: 0.0131, s2.loss_mask: 0.1148, loss: 1.1686
2022-08-18 14:38:34,742 - mmdet - INFO - Epoch [12][2350/18729]	lr: 1.000e-05, eta: 2:34:13, time: 0.566, data_time: 0.035, memory: 12528, loss_rpn_cls: 0.0257, loss_rpn_bbox: 0.0875, s0.loss_cls: 0.0728, s0.acc: 97.3711, s0.loss_bbox: 0.0546, s0.loss_mask: 0.4677, s1.loss_cls: 0.0323, s1.acc: 97.6986, s1.loss_bbox: 0.0264, s1.loss_mask: 0.2343, s2.loss_cls: 0.0172, s2.acc: 97.4696, s2.loss_bbox: 0.0117, s2.loss_mask: 0.1152, loss: 1.1454
2022-08-18 14:39:02,930 - mmdet - INFO - Epoch [12][2400/18729]	lr: 1.000e-05, eta: 2:33:45, time: 0.564, data_time: 0.029, memory: 12528, loss_rpn_cls: 0.0245, loss_rpn_bbox: 0.1082, s0.loss_cls: 0.0764, s0.acc: 96.9844, s0.loss_bbox: 0.0650, s0.loss_mask: 0.4620, s1.loss_cls: 0.0351, s1.acc: 97.2670, s1.loss_bbox: 0.0297, s1.loss_mask: 0.2366, s2.loss_cls: 0.0189, s2.acc: 96.9298, s2.loss_bbox: 0.0122, s2.loss_mask: 0.1142, loss: 1.1830
2022-08-18 14:39:30,660 - mmdet - INFO - Epoch [12][2450/18729]	lr: 1.000e-05, eta: 2:33:13, time: 0.555, data_time: 0.022, memory: 12528, loss_rpn_cls: 0.0186, loss_rpn_bbox: 0.1110, s0.loss_cls: 0.0707, s0.acc: 97.2539, s0.loss_bbox: 0.0604, s0.loss_mask: 0.4398, s1.loss_cls: 0.0321, s1.acc: 97.5908, s1.loss_bbox: 0.0284, s1.loss_mask: 0.2259, s2.loss_cls: 0.0173, s2.acc: 97.2770, s2.loss_bbox: 0.0127, s2.loss_mask: 0.1059, loss: 1.1228
2022-08-18 14:39:57,470 - mmdet - INFO - Epoch [12][2500/18729]	lr: 1.000e-05, eta: 2:32:35, time: 0.536, data_time: 0.021, memory: 12528, loss_rpn_cls: 0.0200, loss_rpn_bbox: 0.0883, s0.loss_cls: 0.0664, s0.acc: 97.4688, s0.loss_bbox: 0.0534, s0.loss_mask: 0.4231, s1.loss_cls: 0.0305, s1.acc: 97.7889, s1.loss_bbox: 0.0256, s1.loss_mask: 0.2178, s2.loss_cls: 0.0185, s2.acc: 97.2078, s2.loss_bbox: 0.0113, s2.loss_mask: 0.1060, loss: 1.0610
2022-08-18 14:40:24,760 - mmdet - INFO - Epoch [12][2550/18729]	lr: 1.000e-05, eta: 2:32:01, time: 0.546, data_time: 0.031, memory: 12528, loss_rpn_cls: 0.0147, loss_rpn_bbox: 0.0863, s0.loss_cls: 0.0649, s0.acc: 97.3008, s0.loss_bbox: 0.0497, s0.loss_mask: 0.4137, s1.loss_cls: 0.0285, s1.acc: 97.7888, s1.loss_bbox: 0.0238, s1.loss_mask: 0.2102, s2.loss_cls: 0.0159, s2.acc: 97.4671, s2.loss_bbox: 0.0103, s2.loss_mask: 0.1006, loss: 1.0185
2022-08-18 14:40:53,126 - mmdet - INFO - Epoch [12][2600/18729]	lr: 1.000e-05, eta: 2:31:34, time: 0.567, data_time: 0.042, memory: 12528, loss_rpn_cls: 0.0304, loss_rpn_bbox: 0.0880, s0.loss_cls: 0.0702, s0.acc: 97.3906, s0.loss_bbox: 0.0541, s0.loss_mask: 0.5065, s1.loss_cls: 0.0297, s1.acc: 97.8754, s1.loss_bbox: 0.0260, s1.loss_mask: 0.2570, s2.loss_cls: 0.0172, s2.acc: 97.4182, s2.loss_bbox: 0.0113, s2.loss_mask: 0.1259, loss: 1.2163
2022-08-18 14:41:20,860 - mmdet - INFO - Epoch [12][2650/18729]	lr: 1.000e-05, eta: 2:31:03, time: 0.555, data_time: 0.034, memory: 12528, loss_rpn_cls: 0.0147, loss_rpn_bbox: 0.0817, s0.loss_cls: 0.0640, s0.acc: 97.5781, s0.loss_bbox: 0.0524, s0.loss_mask: 0.5064, s1.loss_cls: 0.0270, s1.acc: 97.9229, s1.loss_bbox: 0.0243, s1.loss_mask: 0.2552, s2.loss_cls: 0.0147, s2.acc: 97.8723, s2.loss_bbox: 0.0104, s2.loss_mask: 0.1223, loss: 1.1731
2022-08-18 14:41:50,533 - mmdet - INFO - Epoch [12][2700/18729]	lr: 1.000e-05, eta: 2:30:44, time: 0.593, data_time: 0.036, memory: 12528, loss_rpn_cls: 0.0325, loss_rpn_bbox: 0.1185, s0.loss_cls: 0.1013, s0.acc: 96.0898, s0.loss_bbox: 0.0677, s0.loss_mask: 0.4801, s1.loss_cls: 0.0425, s1.acc: 96.8354, s1.loss_bbox: 0.0311, s1.loss_mask: 0.2458, s2.loss_cls: 0.0232, s2.acc: 96.5254, s2.loss_bbox: 0.0130, s2.loss_mask: 0.1176, loss: 1.2731
2022-08-18 14:42:18,318 - mmdet - INFO - Epoch [12][2750/18729]	lr: 1.000e-05, eta: 2:30:13, time: 0.556, data_time: 0.026, memory: 12528, loss_rpn_cls: 0.0222, loss_rpn_bbox: 0.1023, s0.loss_cls: 0.0711, s0.acc: 97.1992, s0.loss_bbox: 0.0553, s0.loss_mask: 0.4490, s1.loss_cls: 0.0290, s1.acc: 97.7945, s1.loss_bbox: 0.0266, s1.loss_mask: 0.2238, s2.loss_cls: 0.0161, s2.acc: 97.5849, s2.loss_bbox: 0.0120, s2.loss_mask: 0.1075, loss: 1.1148
2022-08-18 14:42:46,259 - mmdet - INFO - Epoch [12][2800/18729]	lr: 1.000e-05, eta: 2:29:44, time: 0.559, data_time: 0.022, memory: 12528, loss_rpn_cls: 0.0192, loss_rpn_bbox: 0.0871, s0.loss_cls: 0.0746, s0.acc: 97.0156, s0.loss_bbox: 0.0573, s0.loss_mask: 0.3963, s1.loss_cls: 0.0304, s1.acc: 97.5050, s1.loss_bbox: 0.0277, s1.loss_mask: 0.2035, s2.loss_cls: 0.0162, s2.acc: 97.5547, s2.loss_bbox: 0.0129, s2.loss_mask: 0.1004, loss: 1.0256
2022-08-18 14:43:14,187 - mmdet - INFO - Epoch [12][2850/18729]	lr: 1.000e-05, eta: 2:29:14, time: 0.559, data_time: 0.039, memory: 12528, loss_rpn_cls: 0.0181, loss_rpn_bbox: 0.0603, s0.loss_cls: 0.0613, s0.acc: 97.5547, s0.loss_bbox: 0.0451, s0.loss_mask: 0.4386, s1.loss_cls: 0.0272, s1.acc: 97.9315, s1.loss_bbox: 0.0221, s1.loss_mask: 0.2222, s2.loss_cls: 0.0140, s2.acc: 97.8760, s2.loss_bbox: 0.0098, s2.loss_mask: 0.1085, loss: 1.0274
2022-08-18 14:43:42,151 - mmdet - INFO - Epoch [12][2900/18729]	lr: 1.000e-05, eta: 2:28:44, time: 0.559, data_time: 0.029, memory: 12528, loss_rpn_cls: 0.0246, loss_rpn_bbox: 0.1140, s0.loss_cls: 0.0729, s0.acc: 97.1562, s0.loss_bbox: 0.0580, s0.loss_mask: 0.4835, s1.loss_cls: 0.0337, s1.acc: 97.5246, s1.loss_bbox: 0.0275, s1.loss_mask: 0.2523, s2.loss_cls: 0.0173, s2.acc: 97.3924, s2.loss_bbox: 0.0115, s2.loss_mask: 0.1215, loss: 1.2168
2022-08-18 14:44:09,712 - mmdet - INFO - Epoch [12][2950/18729]	lr: 1.000e-05, eta: 2:28:13, time: 0.551, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0177, loss_rpn_bbox: 0.0757, s0.loss_cls: 0.0690, s0.acc: 97.2656, s0.loss_bbox: 0.0522, s0.loss_mask: 0.4140, s1.loss_cls: 0.0280, s1.acc: 97.8712, s1.loss_bbox: 0.0245, s1.loss_mask: 0.2131, s2.loss_cls: 0.0146, s2.acc: 97.7056, s2.loss_bbox: 0.0108, s2.loss_mask: 0.1030, loss: 1.0226
2022-08-18 14:44:37,331 - mmdet - INFO - Epoch [12][3000/18729]	lr: 1.000e-05, eta: 2:27:42, time: 0.552, data_time: 0.026, memory: 12528, loss_rpn_cls: 0.0284, loss_rpn_bbox: 0.1018, s0.loss_cls: 0.0689, s0.acc: 97.2617, s0.loss_bbox: 0.0545, s0.loss_mask: 0.4111, s1.loss_cls: 0.0293, s1.acc: 97.7162, s1.loss_bbox: 0.0251, s1.loss_mask: 0.2116, s2.loss_cls: 0.0159, s2.acc: 97.6483, s2.loss_bbox: 0.0110, s2.loss_mask: 0.1021, loss: 1.0598
2022-08-18 14:45:05,268 - mmdet - INFO - Epoch [12][3050/18729]	lr: 1.000e-05, eta: 2:27:12, time: 0.559, data_time: 0.025, memory: 12528, loss_rpn_cls: 0.0222, loss_rpn_bbox: 0.0928, s0.loss_cls: 0.0754, s0.acc: 97.0664, s0.loss_bbox: 0.0607, s0.loss_mask: 0.4440, s1.loss_cls: 0.0312, s1.acc: 97.5633, s1.loss_bbox: 0.0290, s1.loss_mask: 0.2281, s2.loss_cls: 0.0162, s2.acc: 97.4718, s2.loss_bbox: 0.0127, s2.loss_mask: 0.1110, loss: 1.1231
2022-08-18 14:45:33,093 - mmdet - INFO - Epoch [12][3100/18729]	lr: 1.000e-05, eta: 2:26:42, time: 0.556, data_time: 0.024, memory: 12528, loss_rpn_cls: 0.0245, loss_rpn_bbox: 0.0741, s0.loss_cls: 0.0747, s0.acc: 97.0352, s0.loss_bbox: 0.0562, s0.loss_mask: 0.4757, s1.loss_cls: 0.0304, s1.acc: 97.6657, s1.loss_bbox: 0.0274, s1.loss_mask: 0.2405, s2.loss_cls: 0.0168, s2.acc: 97.5139, s2.loss_bbox: 0.0120, s2.loss_mask: 0.1146, loss: 1.1470
2022-08-18 14:46:00,265 - mmdet - INFO - Epoch [12][3150/18729]	lr: 1.000e-05, eta: 2:26:09, time: 0.543, data_time: 0.022, memory: 12528, loss_rpn_cls: 0.0124, loss_rpn_bbox: 0.0776, s0.loss_cls: 0.0561, s0.acc: 97.8008, s0.loss_bbox: 0.0494, s0.loss_mask: 0.4267, s1.loss_cls: 0.0269, s1.acc: 97.9295, s1.loss_bbox: 0.0248, s1.loss_mask: 0.2210, s2.loss_cls: 0.0142, s2.acc: 97.8051, s2.loss_bbox: 0.0111, s2.loss_mask: 0.1105, loss: 1.0306
2022-08-18 14:46:27,396 - mmdet - INFO - Epoch [12][3200/18729]	lr: 1.000e-05, eta: 2:25:36, time: 0.543, data_time: 0.023, memory: 12528, loss_rpn_cls: 0.0251, loss_rpn_bbox: 0.0652, s0.loss_cls: 0.0765, s0.acc: 96.8867, s0.loss_bbox: 0.0510, s0.loss_mask: 0.4734, s1.loss_cls: 0.0354, s1.acc: 97.2344, s1.loss_bbox: 0.0247, s1.loss_mask: 0.2428, s2.loss_cls: 0.0165, s2.acc: 97.1648, s2.loss_bbox: 0.0108, s2.loss_mask: 0.1169, loss: 1.1383
2022-08-18 14:46:56,844 - mmdet - INFO - Epoch [12][3250/18729]	lr: 1.000e-05, eta: 2:25:14, time: 0.589, data_time: 0.037, memory: 12528, loss_rpn_cls: 0.0234, loss_rpn_bbox: 0.0941, s0.loss_cls: 0.0733, s0.acc: 97.1992, s0.loss_bbox: 0.0603, s0.loss_mask: 0.4674, s1.loss_cls: 0.0321, s1.acc: 97.7162, s1.loss_bbox: 0.0288, s1.loss_mask: 0.2325, s2.loss_cls: 0.0175, s2.acc: 97.4710, s2.loss_bbox: 0.0124, s2.loss_mask: 0.1115, loss: 1.1532
2022-08-18 14:47:25,627 - mmdet - INFO - Epoch [12][3300/18729]	lr: 1.000e-05, eta: 2:24:49, time: 0.576, data_time: 0.033, memory: 12528, loss_rpn_cls: 0.0159, loss_rpn_bbox: 0.1112, s0.loss_cls: 0.0654, s0.acc: 97.5703, s0.loss_bbox: 0.0544, s0.loss_mask: 0.3938, s1.loss_cls: 0.0271, s1.acc: 97.8967, s1.loss_bbox: 0.0258, s1.loss_mask: 0.2046, s2.loss_cls: 0.0147, s2.acc: 97.6243, s2.loss_bbox: 0.0114, s2.loss_mask: 0.1010, loss: 1.0254
2022-08-18 14:47:52,698 - mmdet - INFO - Epoch [12][3350/18729]	lr: 1.000e-05, eta: 2:24:16, time: 0.541, data_time: 0.025, memory: 12528, loss_rpn_cls: 0.0192, loss_rpn_bbox: 0.0779, s0.loss_cls: 0.0613, s0.acc: 97.5742, s0.loss_bbox: 0.0469, s0.loss_mask: 0.4729, s1.loss_cls: 0.0273, s1.acc: 97.8514, s1.loss_bbox: 0.0224, s1.loss_mask: 0.2442, s2.loss_cls: 0.0149, s2.acc: 97.7223, s2.loss_bbox: 0.0098, s2.loss_mask: 0.1174, loss: 1.1141
2022-08-18 14:48:20,654 - mmdet - INFO - Epoch [12][3400/18729]	lr: 1.000e-05, eta: 2:23:47, time: 0.559, data_time: 0.029, memory: 12528, loss_rpn_cls: 0.0148, loss_rpn_bbox: 0.1102, s0.loss_cls: 0.0783, s0.acc: 97.0703, s0.loss_bbox: 0.0572, s0.loss_mask: 0.4378, s1.loss_cls: 0.0320, s1.acc: 97.5454, s1.loss_bbox: 0.0262, s1.loss_mask: 0.2242, s2.loss_cls: 0.0181, s2.acc: 97.3678, s2.loss_bbox: 0.0115, s2.loss_mask: 0.1097, loss: 1.1201
2022-08-18 14:48:54,585 - mmdet - INFO - Epoch [12][3450/18729]	lr: 1.000e-05, eta: 2:23:45, time: 0.679, data_time: 0.128, memory: 12528, loss_rpn_cls: 0.0331, loss_rpn_bbox: 0.1314, s0.loss_cls: 0.0825, s0.acc: 96.6875, s0.loss_bbox: 0.0595, s0.loss_mask: 0.5241, s1.loss_cls: 0.0368, s1.acc: 97.0219, s1.loss_bbox: 0.0269, s1.loss_mask: 0.2592, s2.loss_cls: 0.0198, s2.acc: 96.7182, s2.loss_bbox: 0.0109, s2.loss_mask: 0.1254, loss: 1.3098
2022-08-18 14:49:24,547 - mmdet - INFO - Epoch [12][3500/18729]	lr: 1.000e-05, eta: 2:23:24, time: 0.599, data_time: 0.044, memory: 12528, loss_rpn_cls: 0.0223, loss_rpn_bbox: 0.0970, s0.loss_cls: 0.0725, s0.acc: 97.1211, s0.loss_bbox: 0.0571, s0.loss_mask: 0.5352, s1.loss_cls: 0.0323, s1.acc: 97.5153, s1.loss_bbox: 0.0253, s1.loss_mask: 0.2627, s2.loss_cls: 0.0172, s2.acc: 97.3942, s2.loss_bbox: 0.0106, s2.loss_mask: 0.1270, loss: 1.2594
2022-08-18 14:49:52,867 - mmdet - INFO - Epoch [12][3550/18729]	lr: 1.000e-05, eta: 2:22:56, time: 0.566, data_time: 0.029, memory: 12528, loss_rpn_cls: 0.0262, loss_rpn_bbox: 0.0897, s0.loss_cls: 0.0831, s0.acc: 96.8008, s0.loss_bbox: 0.0553, s0.loss_mask: 0.4631, s1.loss_cls: 0.0377, s1.acc: 97.2622, s1.loss_bbox: 0.0265, s1.loss_mask: 0.2356, s2.loss_cls: 0.0202, s2.acc: 97.1147, s2.loss_bbox: 0.0115, s2.loss_mask: 0.1146, loss: 1.1637
2022-08-18 14:50:19,972 - mmdet - INFO - Epoch [12][3600/18729]	lr: 1.000e-05, eta: 2:22:23, time: 0.542, data_time: 0.021, memory: 12528, loss_rpn_cls: 0.0202, loss_rpn_bbox: 0.0828, s0.loss_cls: 0.0711, s0.acc: 97.4180, s0.loss_bbox: 0.0540, s0.loss_mask: 0.4332, s1.loss_cls: 0.0307, s1.acc: 97.7639, s1.loss_bbox: 0.0266, s1.loss_mask: 0.2248, s2.loss_cls: 0.0162, s2.acc: 97.5642, s2.loss_bbox: 0.0115, s2.loss_mask: 0.1095, loss: 1.0805
2022-08-18 14:50:48,770 - mmdet - INFO - Epoch [12][3650/18729]	lr: 1.000e-05, eta: 2:21:57, time: 0.576, data_time: 0.031, memory: 12528, loss_rpn_cls: 0.0216, loss_rpn_bbox: 0.1194, s0.loss_cls: 0.0756, s0.acc: 97.1211, s0.loss_bbox: 0.0626, s0.loss_mask: 0.4620, s1.loss_cls: 0.0312, s1.acc: 97.7554, s1.loss_bbox: 0.0288, s1.loss_mask: 0.2408, s2.loss_cls: 0.0166, s2.acc: 97.6426, s2.loss_bbox: 0.0124, s2.loss_mask: 0.1149, loss: 1.1859
2022-08-18 14:51:16,228 - mmdet - INFO - Epoch [12][3700/18729]	lr: 1.000e-05, eta: 2:21:25, time: 0.549, data_time: 0.027, memory: 12528, loss_rpn_cls: 0.0271, loss_rpn_bbox: 0.0910, s0.loss_cls: 0.0670, s0.acc: 97.3047, s0.loss_bbox: 0.0529, s0.loss_mask: 0.4804, s1.loss_cls: 0.0274, s1.acc: 97.9689, s1.loss_bbox: 0.0254, s1.loss_mask: 0.2456, s2.loss_cls: 0.0151, s2.acc: 97.7598, s2.loss_bbox: 0.0111, s2.loss_mask: 0.1189, loss: 1.1619
2022-08-18 14:51:45,804 - mmdet - INFO - Epoch [12][3750/18729]	lr: 1.000e-05, eta: 2:21:03, time: 0.592, data_time: 0.038, memory: 12528, loss_rpn_cls: 0.0216, loss_rpn_bbox: 0.0940, s0.loss_cls: 0.0864, s0.acc: 96.5625, s0.loss_bbox: 0.0619, s0.loss_mask: 0.4531, s1.loss_cls: 0.0368, s1.acc: 97.0504, s1.loss_bbox: 0.0296, s1.loss_mask: 0.2328, s2.loss_cls: 0.0198, s2.acc: 96.7430, s2.loss_bbox: 0.0125, s2.loss_mask: 0.1141, loss: 1.1626
2022-08-18 14:52:13,580 - mmdet - INFO - Epoch [12][3800/18729]	lr: 1.000e-05, eta: 2:20:33, time: 0.556, data_time: 0.019, memory: 12528, loss_rpn_cls: 0.0141, loss_rpn_bbox: 0.0932, s0.loss_cls: 0.0797, s0.acc: 96.8906, s0.loss_bbox: 0.0623, s0.loss_mask: 0.4245, s1.loss_cls: 0.0337, s1.acc: 97.5054, s1.loss_bbox: 0.0302, s1.loss_mask: 0.2196, s2.loss_cls: 0.0184, s2.acc: 97.1134, s2.loss_bbox: 0.0135, s2.loss_mask: 0.1075, loss: 1.0967
2022-08-18 14:52:41,436 - mmdet - INFO - Epoch [12][3850/18729]	lr: 1.000e-05, eta: 2:20:03, time: 0.557, data_time: 0.025, memory: 12528, loss_rpn_cls: 0.0198, loss_rpn_bbox: 0.0896, s0.loss_cls: 0.0812, s0.acc: 96.7188, s0.loss_bbox: 0.0563, s0.loss_mask: 0.4978, s1.loss_cls: 0.0367, s1.acc: 97.1906, s1.loss_bbox: 0.0271, s1.loss_mask: 0.2521, s2.loss_cls: 0.0190, s2.acc: 96.8777, s2.loss_bbox: 0.0118, s2.loss_mask: 0.1242, loss: 1.2156
2022-08-18 14:53:09,001 - mmdet - INFO - Epoch [12][3900/18729]	lr: 1.000e-05, eta: 2:19:32, time: 0.551, data_time: 0.020, memory: 12528, loss_rpn_cls: 0.0168, loss_rpn_bbox: 0.0978, s0.loss_cls: 0.0772, s0.acc: 97.0039, s0.loss_bbox: 0.0584, s0.loss_mask: 0.3755, s1.loss_cls: 0.0319, s1.acc: 97.5425, s1.loss_bbox: 0.0286, s1.loss_mask: 0.1908, s2.loss_cls: 0.0172, s2.acc: 97.3920, s2.loss_bbox: 0.0129, s2.loss_mask: 0.0929, loss: 1.0000
2022-08-18 14:53:35,638 - mmdet - INFO - Epoch [12][3950/18729]	lr: 1.000e-05, eta: 2:18:58, time: 0.533, data_time: 0.012, memory: 12528, loss_rpn_cls: 0.0184, loss_rpn_bbox: 0.1072, s0.loss_cls: 0.0770, s0.acc: 96.9453, s0.loss_bbox: 0.0631, s0.loss_mask: 0.4071, s1.loss_cls: 0.0331, s1.acc: 97.4827, s1.loss_bbox: 0.0300, s1.loss_mask: 0.2141, s2.loss_cls: 0.0180, s2.acc: 97.2050, s2.loss_bbox: 0.0134, s2.loss_mask: 0.1040, loss: 1.0853
2022-08-18 14:54:02,683 - mmdet - INFO - Epoch [12][4000/18729]	lr: 1.000e-05, eta: 2:18:25, time: 0.541, data_time: 0.027, memory: 12528, loss_rpn_cls: 0.0213, loss_rpn_bbox: 0.0997, s0.loss_cls: 0.0619, s0.acc: 97.4922, s0.loss_bbox: 0.0521, s0.loss_mask: 0.4655, s1.loss_cls: 0.0299, s1.acc: 97.5797, s1.loss_bbox: 0.0253, s1.loss_mask: 0.2316, s2.loss_cls: 0.0165, s2.acc: 97.4371, s2.loss_bbox: 0.0110, s2.loss_mask: 0.1143, loss: 1.1291
2022-08-18 14:54:30,337 - mmdet - INFO - Epoch [12][4050/18729]	lr: 1.000e-05, eta: 2:17:55, time: 0.553, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0198, loss_rpn_bbox: 0.0712, s0.loss_cls: 0.0836, s0.acc: 96.8516, s0.loss_bbox: 0.0516, s0.loss_mask: 0.4725, s1.loss_cls: 0.0387, s1.acc: 97.1126, s1.loss_bbox: 0.0253, s1.loss_mask: 0.2461, s2.loss_cls: 0.0209, s2.acc: 96.8643, s2.loss_bbox: 0.0108, s2.loss_mask: 0.1179, loss: 1.1583
2022-08-18 14:55:00,706 - mmdet - INFO - Epoch [12][4100/18729]	lr: 1.000e-05, eta: 2:17:35, time: 0.607, data_time: 0.046, memory: 12528, loss_rpn_cls: 0.0319, loss_rpn_bbox: 0.1134, s0.loss_cls: 0.0985, s0.acc: 96.3945, s0.loss_bbox: 0.0645, s0.loss_mask: 0.4600, s1.loss_cls: 0.0455, s1.acc: 96.6145, s1.loss_bbox: 0.0307, s1.loss_mask: 0.2363, s2.loss_cls: 0.0225, s2.acc: 96.5088, s2.loss_bbox: 0.0131, s2.loss_mask: 0.1169, loss: 1.2332
2022-08-18 14:55:29,169 - mmdet - INFO - Epoch [12][4150/18729]	lr: 1.000e-05, eta: 2:17:07, time: 0.569, data_time: 0.048, memory: 12528, loss_rpn_cls: 0.0215, loss_rpn_bbox: 0.0737, s0.loss_cls: 0.0763, s0.acc: 97.0820, s0.loss_bbox: 0.0553, s0.loss_mask: 0.4699, s1.loss_cls: 0.0341, s1.acc: 97.3584, s1.loss_bbox: 0.0273, s1.loss_mask: 0.2470, s2.loss_cls: 0.0181, s2.acc: 97.1007, s2.loss_bbox: 0.0118, s2.loss_mask: 0.1194, loss: 1.1544
2022-08-18 14:55:55,660 - mmdet - INFO - Epoch [12][4200/18729]	lr: 1.000e-05, eta: 2:16:33, time: 0.530, data_time: 0.012, memory: 12528, loss_rpn_cls: 0.0169, loss_rpn_bbox: 0.0719, s0.loss_cls: 0.0678, s0.acc: 97.4062, s0.loss_bbox: 0.0561, s0.loss_mask: 0.4578, s1.loss_cls: 0.0306, s1.acc: 97.7629, s1.loss_bbox: 0.0282, s1.loss_mask: 0.2376, s2.loss_cls: 0.0161, s2.acc: 97.4543, s2.loss_bbox: 0.0122, s2.loss_mask: 0.1142, loss: 1.1094
2022-08-18 14:56:22,426 - mmdet - INFO - Epoch [12][4250/18729]	lr: 1.000e-05, eta: 2:16:00, time: 0.535, data_time: 0.019, memory: 12528, loss_rpn_cls: 0.0161, loss_rpn_bbox: 0.0720, s0.loss_cls: 0.0613, s0.acc: 97.5352, s0.loss_bbox: 0.0502, s0.loss_mask: 0.4271, s1.loss_cls: 0.0266, s1.acc: 98.1530, s1.loss_bbox: 0.0243, s1.loss_mask: 0.2181, s2.loss_cls: 0.0153, s2.acc: 97.7217, s2.loss_bbox: 0.0106, s2.loss_mask: 0.1077, loss: 1.0293
2022-08-18 14:56:49,532 - mmdet - INFO - Epoch [12][4300/18729]	lr: 1.000e-05, eta: 2:15:28, time: 0.542, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0128, loss_rpn_bbox: 0.0722, s0.loss_cls: 0.0602, s0.acc: 97.6172, s0.loss_bbox: 0.0442, s0.loss_mask: 0.4414, s1.loss_cls: 0.0261, s1.acc: 98.0692, s1.loss_bbox: 0.0216, s1.loss_mask: 0.2276, s2.loss_cls: 0.0133, s2.acc: 98.0757, s2.loss_bbox: 0.0095, s2.loss_mask: 0.1119, loss: 1.0410
2022-08-18 14:57:18,653 - mmdet - INFO - Epoch [12][4350/18729]	lr: 1.000e-05, eta: 2:15:03, time: 0.582, data_time: 0.049, memory: 12528, loss_rpn_cls: 0.0218, loss_rpn_bbox: 0.0954, s0.loss_cls: 0.0731, s0.acc: 97.0625, s0.loss_bbox: 0.0621, s0.loss_mask: 0.4230, s1.loss_cls: 0.0325, s1.acc: 97.5053, s1.loss_bbox: 0.0299, s1.loss_mask: 0.2112, s2.loss_cls: 0.0174, s2.acc: 97.4134, s2.loss_bbox: 0.0130, s2.loss_mask: 0.1034, loss: 1.0830
2022-08-18 14:57:45,313 - mmdet - INFO - Epoch [12][4400/18729]	lr: 1.000e-05, eta: 2:14:30, time: 0.533, data_time: 0.025, memory: 12528, loss_rpn_cls: 0.0152, loss_rpn_bbox: 0.0564, s0.loss_cls: 0.0567, s0.acc: 97.7812, s0.loss_bbox: 0.0431, s0.loss_mask: 0.4527, s1.loss_cls: 0.0235, s1.acc: 98.1810, s1.loss_bbox: 0.0215, s1.loss_mask: 0.2385, s2.loss_cls: 0.0135, s2.acc: 97.8316, s2.loss_bbox: 0.0098, s2.loss_mask: 0.1155, loss: 1.0464
2022-08-18 14:58:11,869 - mmdet - INFO - Epoch [12][4450/18729]	lr: 1.000e-05, eta: 2:13:57, time: 0.531, data_time: 0.013, memory: 12528, loss_rpn_cls: 0.0222, loss_rpn_bbox: 0.0960, s0.loss_cls: 0.0791, s0.acc: 96.8281, s0.loss_bbox: 0.0607, s0.loss_mask: 0.4513, s1.loss_cls: 0.0342, s1.acc: 97.4820, s1.loss_bbox: 0.0293, s1.loss_mask: 0.2316, s2.loss_cls: 0.0184, s2.acc: 97.0555, s2.loss_bbox: 0.0134, s2.loss_mask: 0.1125, loss: 1.1488
2022-08-18 14:58:40,272 - mmdet - INFO - Epoch [12][4500/18729]	lr: 1.000e-05, eta: 2:13:30, time: 0.568, data_time: 0.032, memory: 12528, loss_rpn_cls: 0.0256, loss_rpn_bbox: 0.1037, s0.loss_cls: 0.0811, s0.acc: 96.7422, s0.loss_bbox: 0.0558, s0.loss_mask: 0.5882, s1.loss_cls: 0.0365, s1.acc: 97.2223, s1.loss_bbox: 0.0261, s1.loss_mask: 0.2888, s2.loss_cls: 0.0186, s2.acc: 97.1769, s2.loss_bbox: 0.0114, s2.loss_mask: 0.1401, loss: 1.3760
2022-08-18 14:59:08,442 - mmdet - INFO - Epoch [12][4550/18729]	lr: 1.000e-05, eta: 2:13:01, time: 0.563, data_time: 0.025, memory: 12528, loss_rpn_cls: 0.0213, loss_rpn_bbox: 0.0920, s0.loss_cls: 0.0769, s0.acc: 97.2070, s0.loss_bbox: 0.0575, s0.loss_mask: 0.4161, s1.loss_cls: 0.0312, s1.acc: 97.8237, s1.loss_bbox: 0.0274, s1.loss_mask: 0.2129, s2.loss_cls: 0.0171, s2.acc: 97.4699, s2.loss_bbox: 0.0122, s2.loss_mask: 0.1008, loss: 1.0653
2022-08-18 14:59:36,211 - mmdet - INFO - Epoch [12][4600/18729]	lr: 1.000e-05, eta: 2:12:32, time: 0.555, data_time: 0.021, memory: 12528, loss_rpn_cls: 0.0183, loss_rpn_bbox: 0.0975, s0.loss_cls: 0.0713, s0.acc: 97.2539, s0.loss_bbox: 0.0650, s0.loss_mask: 0.4323, s1.loss_cls: 0.0302, s1.acc: 97.6580, s1.loss_bbox: 0.0312, s1.loss_mask: 0.2165, s2.loss_cls: 0.0177, s2.acc: 97.0864, s2.loss_bbox: 0.0138, s2.loss_mask: 0.1048, loss: 1.0986
2022-08-18 15:00:03,309 - mmdet - INFO - Epoch [12][4650/18729]	lr: 1.000e-05, eta: 2:12:01, time: 0.542, data_time: 0.026, memory: 12528, loss_rpn_cls: 0.0172, loss_rpn_bbox: 0.0721, s0.loss_cls: 0.0717, s0.acc: 97.2812, s0.loss_bbox: 0.0519, s0.loss_mask: 0.4928, s1.loss_cls: 0.0306, s1.acc: 97.7491, s1.loss_bbox: 0.0248, s1.loss_mask: 0.2481, s2.loss_cls: 0.0162, s2.acc: 97.4565, s2.loss_bbox: 0.0112, s2.loss_mask: 0.1210, loss: 1.1575
2022-08-18 15:00:36,069 - mmdet - INFO - Epoch [12][4700/18729]	lr: 1.000e-05, eta: 2:11:47, time: 0.655, data_time: 0.111, memory: 12528, loss_rpn_cls: 0.0182, loss_rpn_bbox: 0.0876, s0.loss_cls: 0.0788, s0.acc: 96.8281, s0.loss_bbox: 0.0578, s0.loss_mask: 0.4232, s1.loss_cls: 0.0327, s1.acc: 97.4793, s1.loss_bbox: 0.0290, s1.loss_mask: 0.2193, s2.loss_cls: 0.0192, s2.acc: 97.1718, s2.loss_bbox: 0.0125, s2.loss_mask: 0.1078, loss: 1.0860
2022-08-18 15:01:03,637 - mmdet - INFO - Epoch [12][4750/18729]	lr: 1.000e-05, eta: 2:11:17, time: 0.551, data_time: 0.026, memory: 12528, loss_rpn_cls: 0.0255, loss_rpn_bbox: 0.0953, s0.loss_cls: 0.0682, s0.acc: 97.2617, s0.loss_bbox: 0.0562, s0.loss_mask: 0.4570, s1.loss_cls: 0.0309, s1.acc: 97.7186, s1.loss_bbox: 0.0264, s1.loss_mask: 0.2349, s2.loss_cls: 0.0167, s2.acc: 97.2855, s2.loss_bbox: 0.0113, s2.loss_mask: 0.1116, loss: 1.1339
2022-08-18 15:01:29,942 - mmdet - INFO - Epoch [12][4800/18729]	lr: 1.000e-05, eta: 2:10:43, time: 0.526, data_time: 0.013, memory: 12528, loss_rpn_cls: 0.0189, loss_rpn_bbox: 0.0885, s0.loss_cls: 0.0741, s0.acc: 97.2617, s0.loss_bbox: 0.0545, s0.loss_mask: 0.4495, s1.loss_cls: 0.0312, s1.acc: 97.5863, s1.loss_bbox: 0.0265, s1.loss_mask: 0.2320, s2.loss_cls: 0.0171, s2.acc: 97.2966, s2.loss_bbox: 0.0114, s2.loss_mask: 0.1123, loss: 1.1159
2022-08-18 15:01:58,275 - mmdet - INFO - Epoch [12][4850/18729]	lr: 1.000e-05, eta: 2:10:15, time: 0.567, data_time: 0.027, memory: 12528, loss_rpn_cls: 0.0196, loss_rpn_bbox: 0.0924, s0.loss_cls: 0.0670, s0.acc: 97.2656, s0.loss_bbox: 0.0573, s0.loss_mask: 0.4367, s1.loss_cls: 0.0268, s1.acc: 98.0736, s1.loss_bbox: 0.0267, s1.loss_mask: 0.2201, s2.loss_cls: 0.0148, s2.acc: 97.8165, s2.loss_bbox: 0.0124, s2.loss_mask: 0.1080, loss: 1.0818
2022-08-18 15:02:25,001 - mmdet - INFO - Epoch [12][4900/18729]	lr: 1.000e-05, eta: 2:09:43, time: 0.535, data_time: 0.022, memory: 12528, loss_rpn_cls: 0.0248, loss_rpn_bbox: 0.0962, s0.loss_cls: 0.0717, s0.acc: 97.1602, s0.loss_bbox: 0.0509, s0.loss_mask: 0.4897, s1.loss_cls: 0.0331, s1.acc: 97.5717, s1.loss_bbox: 0.0240, s1.loss_mask: 0.2515, s2.loss_cls: 0.0176, s2.acc: 97.2329, s2.loss_bbox: 0.0105, s2.loss_mask: 0.1217, loss: 1.1916
2022-08-18 15:02:54,412 - mmdet - INFO - Epoch [12][4950/18729]	lr: 1.000e-05, eta: 2:09:18, time: 0.588, data_time: 0.055, memory: 12528, loss_rpn_cls: 0.0165, loss_rpn_bbox: 0.0670, s0.loss_cls: 0.0510, s0.acc: 98.0039, s0.loss_bbox: 0.0427, s0.loss_mask: 0.4856, s1.loss_cls: 0.0223, s1.acc: 98.3630, s1.loss_bbox: 0.0200, s1.loss_mask: 0.2487, s2.loss_cls: 0.0119, s2.acc: 98.3376, s2.loss_bbox: 0.0088, s2.loss_mask: 0.1218, loss: 1.0962
2022-08-18 15:03:23,157 - mmdet - INFO - Epoch [12][5000/18729]	lr: 1.000e-05, eta: 2:08:52, time: 0.575, data_time: 0.045, memory: 12528, loss_rpn_cls: 0.0253, loss_rpn_bbox: 0.0889, s0.loss_cls: 0.0633, s0.acc: 97.5000, s0.loss_bbox: 0.0501, s0.loss_mask: 0.4891, s1.loss_cls: 0.0262, s1.acc: 97.8981, s1.loss_bbox: 0.0235, s1.loss_mask: 0.2481, s2.loss_cls: 0.0162, s2.acc: 97.5656, s2.loss_bbox: 0.0102, s2.loss_mask: 0.1198, loss: 1.1607
2022-08-18 15:03:52,965 - mmdet - INFO - Epoch [12][5050/18729]	lr: 1.000e-05, eta: 2:08:28, time: 0.596, data_time: 0.043, memory: 12528, loss_rpn_cls: 0.0270, loss_rpn_bbox: 0.0926, s0.loss_cls: 0.0790, s0.acc: 96.8711, s0.loss_bbox: 0.0542, s0.loss_mask: 0.5020, s1.loss_cls: 0.0340, s1.acc: 97.6231, s1.loss_bbox: 0.0259, s1.loss_mask: 0.2554, s2.loss_cls: 0.0197, s2.acc: 97.0782, s2.loss_bbox: 0.0108, s2.loss_mask: 0.1242, loss: 1.2249
2022-08-18 15:04:20,906 - mmdet - INFO - Epoch [12][5100/18729]	lr: 1.000e-05, eta: 2:07:59, time: 0.559, data_time: 0.026, memory: 12528, loss_rpn_cls: 0.0206, loss_rpn_bbox: 0.0810, s0.loss_cls: 0.0751, s0.acc: 97.1055, s0.loss_bbox: 0.0537, s0.loss_mask: 0.4721, s1.loss_cls: 0.0307, s1.acc: 97.6396, s1.loss_bbox: 0.0261, s1.loss_mask: 0.2406, s2.loss_cls: 0.0159, s2.acc: 97.6214, s2.loss_bbox: 0.0116, s2.loss_mask: 0.1194, loss: 1.1469
2022-08-18 15:04:49,546 - mmdet - INFO - Epoch [12][5150/18729]	lr: 1.000e-05, eta: 2:07:32, time: 0.573, data_time: 0.037, memory: 12528, loss_rpn_cls: 0.0208, loss_rpn_bbox: 0.0917, s0.loss_cls: 0.0671, s0.acc: 97.3398, s0.loss_bbox: 0.0529, s0.loss_mask: 0.4486, s1.loss_cls: 0.0294, s1.acc: 97.6118, s1.loss_bbox: 0.0255, s1.loss_mask: 0.2267, s2.loss_cls: 0.0159, s2.acc: 97.5594, s2.loss_bbox: 0.0113, s2.loss_mask: 0.1104, loss: 1.1002
2022-08-18 15:05:21,016 - mmdet - INFO - Epoch [12][5200/18729]	lr: 1.000e-05, eta: 2:07:13, time: 0.629, data_time: 0.069, memory: 12528, loss_rpn_cls: 0.0235, loss_rpn_bbox: 0.1068, s0.loss_cls: 0.0742, s0.acc: 97.1328, s0.loss_bbox: 0.0607, s0.loss_mask: 0.4551, s1.loss_cls: 0.0338, s1.acc: 97.3608, s1.loss_bbox: 0.0292, s1.loss_mask: 0.2348, s2.loss_cls: 0.0177, s2.acc: 97.1343, s2.loss_bbox: 0.0129, s2.loss_mask: 0.1138, loss: 1.1626
2022-08-18 15:05:49,815 - mmdet - INFO - Epoch [12][5250/18729]	lr: 1.000e-05, eta: 2:06:46, time: 0.576, data_time: 0.030, memory: 12528, loss_rpn_cls: 0.0149, loss_rpn_bbox: 0.1000, s0.loss_cls: 0.0689, s0.acc: 97.3320, s0.loss_bbox: 0.0540, s0.loss_mask: 0.4689, s1.loss_cls: 0.0273, s1.acc: 97.9488, s1.loss_bbox: 0.0250, s1.loss_mask: 0.2372, s2.loss_cls: 0.0143, s2.acc: 97.7603, s2.loss_bbox: 0.0112, s2.loss_mask: 0.1181, loss: 1.1400
2022-08-18 15:06:16,800 - mmdet - INFO - Epoch [12][5300/18729]	lr: 1.000e-05, eta: 2:06:15, time: 0.540, data_time: 0.017, memory: 12528, loss_rpn_cls: 0.0225, loss_rpn_bbox: 0.0922, s0.loss_cls: 0.0796, s0.acc: 96.8789, s0.loss_bbox: 0.0597, s0.loss_mask: 0.4604, s1.loss_cls: 0.0346, s1.acc: 97.3180, s1.loss_bbox: 0.0290, s1.loss_mask: 0.2355, s2.loss_cls: 0.0190, s2.acc: 96.9829, s2.loss_bbox: 0.0121, s2.loss_mask: 0.1135, loss: 1.1580
2022-08-18 15:06:44,453 - mmdet - INFO - Epoch [12][5350/18729]	lr: 1.000e-05, eta: 2:05:45, time: 0.553, data_time: 0.029, memory: 12528, loss_rpn_cls: 0.0196, loss_rpn_bbox: 0.0816, s0.loss_cls: 0.0738, s0.acc: 97.2539, s0.loss_bbox: 0.0524, s0.loss_mask: 0.4598, s1.loss_cls: 0.0320, s1.acc: 97.6774, s1.loss_bbox: 0.0262, s1.loss_mask: 0.2322, s2.loss_cls: 0.0182, s2.acc: 97.3616, s2.loss_bbox: 0.0113, s2.loss_mask: 0.1128, loss: 1.1199
2022-08-18 15:07:14,791 - mmdet - INFO - Epoch [12][5400/18729]	lr: 1.000e-05, eta: 2:05:22, time: 0.607, data_time: 0.055, memory: 12528, loss_rpn_cls: 0.0207, loss_rpn_bbox: 0.1164, s0.loss_cls: 0.0862, s0.acc: 96.7891, s0.loss_bbox: 0.0631, s0.loss_mask: 0.5031, s1.loss_cls: 0.0364, s1.acc: 97.3333, s1.loss_bbox: 0.0294, s1.loss_mask: 0.2580, s2.loss_cls: 0.0202, s2.acc: 96.8246, s2.loss_bbox: 0.0126, s2.loss_mask: 0.1242, loss: 1.2704
2022-08-18 15:07:42,410 - mmdet - INFO - Epoch [12][5450/18729]	lr: 1.000e-05, eta: 2:04:53, time: 0.552, data_time: 0.030, memory: 12528, loss_rpn_cls: 0.0227, loss_rpn_bbox: 0.0775, s0.loss_cls: 0.0651, s0.acc: 97.4375, s0.loss_bbox: 0.0486, s0.loss_mask: 0.4020, s1.loss_cls: 0.0279, s1.acc: 97.7598, s1.loss_bbox: 0.0241, s1.loss_mask: 0.2096, s2.loss_cls: 0.0150, s2.acc: 97.5843, s2.loss_bbox: 0.0109, s2.loss_mask: 0.1011, loss: 1.0044
2022-08-18 15:08:11,103 - mmdet - INFO - Epoch [12][5500/18729]	lr: 1.000e-05, eta: 2:04:26, time: 0.574, data_time: 0.035, memory: 12528, loss_rpn_cls: 0.0222, loss_rpn_bbox: 0.0876, s0.loss_cls: 0.0713, s0.acc: 97.3516, s0.loss_bbox: 0.0526, s0.loss_mask: 0.4467, s1.loss_cls: 0.0331, s1.acc: 97.6526, s1.loss_bbox: 0.0253, s1.loss_mask: 0.2285, s2.loss_cls: 0.0178, s2.acc: 97.3559, s2.loss_bbox: 0.0111, s2.loss_mask: 0.1094, loss: 1.1055
2022-08-18 15:08:38,818 - mmdet - INFO - Epoch [12][5550/18729]	lr: 1.000e-05, eta: 2:03:56, time: 0.554, data_time: 0.025, memory: 12528, loss_rpn_cls: 0.0184, loss_rpn_bbox: 0.0818, s0.loss_cls: 0.0604, s0.acc: 97.6562, s0.loss_bbox: 0.0488, s0.loss_mask: 0.4192, s1.loss_cls: 0.0273, s1.acc: 97.8974, s1.loss_bbox: 0.0227, s1.loss_mask: 0.2150, s2.loss_cls: 0.0147, s2.acc: 97.8482, s2.loss_bbox: 0.0102, s2.loss_mask: 0.1056, loss: 1.0241
2022-08-18 15:09:05,882 - mmdet - INFO - Epoch [12][5600/18729]	lr: 1.000e-05, eta: 2:03:25, time: 0.541, data_time: 0.016, memory: 12528, loss_rpn_cls: 0.0188, loss_rpn_bbox: 0.1103, s0.loss_cls: 0.0764, s0.acc: 96.8555, s0.loss_bbox: 0.0650, s0.loss_mask: 0.4650, s1.loss_cls: 0.0316, s1.acc: 97.5287, s1.loss_bbox: 0.0297, s1.loss_mask: 0.2387, s2.loss_cls: 0.0174, s2.acc: 97.2680, s2.loss_bbox: 0.0127, s2.loss_mask: 0.1147, loss: 1.1802
2022-08-18 15:09:35,252 - mmdet - INFO - Epoch [12][5650/18729]	lr: 1.000e-05, eta: 2:03:00, time: 0.587, data_time: 0.027, memory: 12528, loss_rpn_cls: 0.0266, loss_rpn_bbox: 0.1290, s0.loss_cls: 0.0812, s0.acc: 96.7812, s0.loss_bbox: 0.0686, s0.loss_mask: 0.4681, s1.loss_cls: 0.0302, s1.acc: 97.7919, s1.loss_bbox: 0.0325, s1.loss_mask: 0.2370, s2.loss_cls: 0.0175, s2.acc: 97.3071, s2.loss_bbox: 0.0145, s2.loss_mask: 0.1157, loss: 1.2211
2022-08-18 15:10:02,992 - mmdet - INFO - Epoch [12][5700/18729]	lr: 1.000e-05, eta: 2:02:30, time: 0.555, data_time: 0.029, memory: 12528, loss_rpn_cls: 0.0162, loss_rpn_bbox: 0.0865, s0.loss_cls: 0.0690, s0.acc: 97.1992, s0.loss_bbox: 0.0590, s0.loss_mask: 0.4510, s1.loss_cls: 0.0327, s1.acc: 97.6029, s1.loss_bbox: 0.0279, s1.loss_mask: 0.2271, s2.loss_cls: 0.0178, s2.acc: 97.2030, s2.loss_bbox: 0.0117, s2.loss_mask: 0.1095, loss: 1.1082
2022-08-18 15:10:29,949 - mmdet - INFO - Epoch [12][5750/18729]	lr: 1.000e-05, eta: 2:01:59, time: 0.539, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0131, loss_rpn_bbox: 0.0541, s0.loss_cls: 0.0456, s0.acc: 98.1641, s0.loss_bbox: 0.0419, s0.loss_mask: 0.4608, s1.loss_cls: 0.0183, s1.acc: 98.7598, s1.loss_bbox: 0.0204, s1.loss_mask: 0.2380, s2.loss_cls: 0.0104, s2.acc: 98.5506, s2.loss_bbox: 0.0091, s2.loss_mask: 0.1170, loss: 1.0287
2022-08-18 15:10:58,300 - mmdet - INFO - Epoch [12][5800/18729]	lr: 1.000e-05, eta: 2:01:32, time: 0.567, data_time: 0.022, memory: 12528, loss_rpn_cls: 0.0167, loss_rpn_bbox: 0.0965, s0.loss_cls: 0.0748, s0.acc: 97.0820, s0.loss_bbox: 0.0595, s0.loss_mask: 0.4198, s1.loss_cls: 0.0297, s1.acc: 97.6687, s1.loss_bbox: 0.0285, s1.loss_mask: 0.2187, s2.loss_cls: 0.0162, s2.acc: 97.4272, s2.loss_bbox: 0.0132, s2.loss_mask: 0.1072, loss: 1.0808
2022-08-18 15:11:25,430 - mmdet - INFO - Epoch [12][5850/18729]	lr: 1.000e-05, eta: 2:01:01, time: 0.543, data_time: 0.026, memory: 12528, loss_rpn_cls: 0.0241, loss_rpn_bbox: 0.1029, s0.loss_cls: 0.0712, s0.acc: 97.1758, s0.loss_bbox: 0.0569, s0.loss_mask: 0.4293, s1.loss_cls: 0.0315, s1.acc: 97.7886, s1.loss_bbox: 0.0262, s1.loss_mask: 0.2189, s2.loss_cls: 0.0172, s2.acc: 97.2266, s2.loss_bbox: 0.0112, s2.loss_mask: 0.1067, loss: 1.0961
2022-08-18 15:11:54,461 - mmdet - INFO - Epoch [12][5900/18729]	lr: 1.000e-05, eta: 2:00:35, time: 0.581, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0237, loss_rpn_bbox: 0.1173, s0.loss_cls: 0.0879, s0.acc: 96.4922, s0.loss_bbox: 0.0724, s0.loss_mask: 0.4626, s1.loss_cls: 0.0372, s1.acc: 97.0469, s1.loss_bbox: 0.0319, s1.loss_mask: 0.2252, s2.loss_cls: 0.0203, s2.acc: 96.7704, s2.loss_bbox: 0.0138, s2.loss_mask: 0.1093, loss: 1.2016
2022-08-18 15:12:24,275 - mmdet - INFO - Epoch [12][5950/18729]	lr: 1.000e-05, eta: 2:00:10, time: 0.596, data_time: 0.056, memory: 12528, loss_rpn_cls: 0.0227, loss_rpn_bbox: 0.1284, s0.loss_cls: 0.0713, s0.acc: 97.0117, s0.loss_bbox: 0.0579, s0.loss_mask: 0.4564, s1.loss_cls: 0.0305, s1.acc: 97.5114, s1.loss_bbox: 0.0262, s1.loss_mask: 0.2349, s2.loss_cls: 0.0171, s2.acc: 97.2511, s2.loss_bbox: 0.0113, s2.loss_mask: 0.1162, loss: 1.1729
2022-08-18 15:12:54,266 - mmdet - INFO - Epoch [12][6000/18729]	lr: 1.000e-05, eta: 1:59:45, time: 0.600, data_time: 0.047, memory: 12528, loss_rpn_cls: 0.0259, loss_rpn_bbox: 0.1174, s0.loss_cls: 0.0981, s0.acc: 96.3828, s0.loss_bbox: 0.0590, s0.loss_mask: 0.4555, s1.loss_cls: 0.0434, s1.acc: 96.6999, s1.loss_bbox: 0.0268, s1.loss_mask: 0.2287, s2.loss_cls: 0.0226, s2.acc: 96.4293, s2.loss_bbox: 0.0114, s2.loss_mask: 0.1111, loss: 1.1999
2022-08-18 15:13:24,128 - mmdet - INFO - Epoch [12][6050/18729]	lr: 1.000e-05, eta: 1:59:21, time: 0.597, data_time: 0.044, memory: 12528, loss_rpn_cls: 0.0241, loss_rpn_bbox: 0.0998, s0.loss_cls: 0.0727, s0.acc: 97.2188, s0.loss_bbox: 0.0584, s0.loss_mask: 0.5147, s1.loss_cls: 0.0311, s1.acc: 97.7325, s1.loss_bbox: 0.0271, s1.loss_mask: 0.2664, s2.loss_cls: 0.0189, s2.acc: 97.2157, s2.loss_bbox: 0.0115, s2.loss_mask: 0.1282, loss: 1.2529
2022-08-18 15:13:51,438 - mmdet - INFO - Epoch [12][6100/18729]	lr: 1.000e-05, eta: 1:58:50, time: 0.546, data_time: 0.019, memory: 12528, loss_rpn_cls: 0.0160, loss_rpn_bbox: 0.0848, s0.loss_cls: 0.0628, s0.acc: 97.4570, s0.loss_bbox: 0.0519, s0.loss_mask: 0.3835, s1.loss_cls: 0.0273, s1.acc: 97.9109, s1.loss_bbox: 0.0249, s1.loss_mask: 0.1931, s2.loss_cls: 0.0135, s2.acc: 97.8734, s2.loss_bbox: 0.0119, s2.loss_mask: 0.0945, loss: 0.9641
2022-08-18 15:14:19,907 - mmdet - INFO - Epoch [12][6150/18729]	lr: 1.000e-05, eta: 1:58:23, time: 0.569, data_time: 0.031, memory: 12528, loss_rpn_cls: 0.0233, loss_rpn_bbox: 0.0939, s0.loss_cls: 0.0920, s0.acc: 96.5352, s0.loss_bbox: 0.0611, s0.loss_mask: 0.4126, s1.loss_cls: 0.0384, s1.acc: 97.2032, s1.loss_bbox: 0.0299, s1.loss_mask: 0.2108, s2.loss_cls: 0.0198, s2.acc: 96.8365, s2.loss_bbox: 0.0132, s2.loss_mask: 0.1016, loss: 1.0965
2022-08-18 15:14:50,626 - mmdet - INFO - Epoch [12][6200/18729]	lr: 1.000e-05, eta: 1:58:00, time: 0.614, data_time: 0.057, memory: 12528, loss_rpn_cls: 0.0218, loss_rpn_bbox: 0.1153, s0.loss_cls: 0.0780, s0.acc: 96.9805, s0.loss_bbox: 0.0604, s0.loss_mask: 0.4537, s1.loss_cls: 0.0343, s1.acc: 97.4864, s1.loss_bbox: 0.0286, s1.loss_mask: 0.2300, s2.loss_cls: 0.0190, s2.acc: 97.2871, s2.loss_bbox: 0.0123, s2.loss_mask: 0.1119, loss: 1.1653
2022-08-18 15:15:20,984 - mmdet - INFO - Epoch [12][6250/18729]	lr: 1.000e-05, eta: 1:57:35, time: 0.607, data_time: 0.067, memory: 12528, loss_rpn_cls: 0.0167, loss_rpn_bbox: 0.0747, s0.loss_cls: 0.0604, s0.acc: 97.8867, s0.loss_bbox: 0.0471, s0.loss_mask: 0.4470, s1.loss_cls: 0.0268, s1.acc: 98.2254, s1.loss_bbox: 0.0219, s1.loss_mask: 0.2296, s2.loss_cls: 0.0141, s2.acc: 98.0971, s2.loss_bbox: 0.0099, s2.loss_mask: 0.1137, loss: 1.0620
2022-08-18 15:15:48,599 - mmdet - INFO - Epoch [12][6300/18729]	lr: 1.000e-05, eta: 1:57:06, time: 0.552, data_time: 0.027, memory: 12528, loss_rpn_cls: 0.0231, loss_rpn_bbox: 0.0968, s0.loss_cls: 0.0790, s0.acc: 97.0352, s0.loss_bbox: 0.0539, s0.loss_mask: 0.4507, s1.loss_cls: 0.0302, s1.acc: 97.9333, s1.loss_bbox: 0.0244, s1.loss_mask: 0.2262, s2.loss_cls: 0.0171, s2.acc: 97.3698, s2.loss_bbox: 0.0098, s2.loss_mask: 0.1059, loss: 1.1171
2022-08-18 15:16:15,963 - mmdet - INFO - Epoch [12][6350/18729]	lr: 1.000e-05, eta: 1:56:36, time: 0.547, data_time: 0.024, memory: 12528, loss_rpn_cls: 0.0259, loss_rpn_bbox: 0.1114, s0.loss_cls: 0.0849, s0.acc: 96.7930, s0.loss_bbox: 0.0599, s0.loss_mask: 0.4741, s1.loss_cls: 0.0395, s1.acc: 97.0766, s1.loss_bbox: 0.0280, s1.loss_mask: 0.2453, s2.loss_cls: 0.0232, s2.acc: 96.5933, s2.loss_bbox: 0.0118, s2.loss_mask: 0.1183, loss: 1.2224
2022-08-18 15:16:44,465 - mmdet - INFO - Epoch [12][6400/18729]	lr: 1.000e-05, eta: 1:56:08, time: 0.570, data_time: 0.033, memory: 12528, loss_rpn_cls: 0.0245, loss_rpn_bbox: 0.0990, s0.loss_cls: 0.0656, s0.acc: 97.4297, s0.loss_bbox: 0.0538, s0.loss_mask: 0.4684, s1.loss_cls: 0.0292, s1.acc: 97.8410, s1.loss_bbox: 0.0246, s1.loss_mask: 0.2359, s2.loss_cls: 0.0155, s2.acc: 97.6869, s2.loss_bbox: 0.0104, s2.loss_mask: 0.1134, loss: 1.1404
2022-08-18 15:17:11,937 - mmdet - INFO - Epoch [12][6450/18729]	lr: 1.000e-05, eta: 1:55:38, time: 0.549, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0309, loss_rpn_bbox: 0.1066, s0.loss_cls: 0.0711, s0.acc: 97.2148, s0.loss_bbox: 0.0559, s0.loss_mask: 0.4971, s1.loss_cls: 0.0302, s1.acc: 97.6394, s1.loss_bbox: 0.0255, s1.loss_mask: 0.2402, s2.loss_cls: 0.0165, s2.acc: 97.5350, s2.loss_bbox: 0.0110, s2.loss_mask: 0.1140, loss: 1.1990
2022-08-18 15:17:39,235 - mmdet - INFO - Epoch [12][6500/18729]	lr: 1.000e-05, eta: 1:55:08, time: 0.546, data_time: 0.025, memory: 12528, loss_rpn_cls: 0.0218, loss_rpn_bbox: 0.0914, s0.loss_cls: 0.0722, s0.acc: 97.0859, s0.loss_bbox: 0.0516, s0.loss_mask: 0.4594, s1.loss_cls: 0.0295, s1.acc: 97.8841, s1.loss_bbox: 0.0255, s1.loss_mask: 0.2384, s2.loss_cls: 0.0165, s2.acc: 97.4520, s2.loss_bbox: 0.0112, s2.loss_mask: 0.1130, loss: 1.1303
2022-08-18 15:18:06,627 - mmdet - INFO - Epoch [12][6550/18729]	lr: 1.000e-05, eta: 1:54:38, time: 0.548, data_time: 0.024, memory: 12528, loss_rpn_cls: 0.0223, loss_rpn_bbox: 0.0891, s0.loss_cls: 0.0703, s0.acc: 97.2852, s0.loss_bbox: 0.0560, s0.loss_mask: 0.5124, s1.loss_cls: 0.0313, s1.acc: 97.6341, s1.loss_bbox: 0.0255, s1.loss_mask: 0.2644, s2.loss_cls: 0.0166, s2.acc: 97.4150, s2.loss_bbox: 0.0109, s2.loss_mask: 0.1273, loss: 1.2261
2022-08-18 15:18:34,412 - mmdet - INFO - Epoch [12][6600/18729]	lr: 1.000e-05, eta: 1:54:09, time: 0.556, data_time: 0.023, memory: 12528, loss_rpn_cls: 0.0141, loss_rpn_bbox: 0.0704, s0.loss_cls: 0.0619, s0.acc: 97.5469, s0.loss_bbox: 0.0506, s0.loss_mask: 0.4162, s1.loss_cls: 0.0233, s1.acc: 98.3051, s1.loss_bbox: 0.0247, s1.loss_mask: 0.2141, s2.loss_cls: 0.0124, s2.acc: 98.1701, s2.loss_bbox: 0.0110, s2.loss_mask: 0.1043, loss: 1.0031
2022-08-18 15:19:02,935 - mmdet - INFO - Epoch [12][6650/18729]	lr: 1.000e-05, eta: 1:53:42, time: 0.570, data_time: 0.029, memory: 12528, loss_rpn_cls: 0.0311, loss_rpn_bbox: 0.1030, s0.loss_cls: 0.0770, s0.acc: 96.9609, s0.loss_bbox: 0.0604, s0.loss_mask: 0.4222, s1.loss_cls: 0.0336, s1.acc: 97.5161, s1.loss_bbox: 0.0298, s1.loss_mask: 0.2221, s2.loss_cls: 0.0187, s2.acc: 97.1642, s2.loss_bbox: 0.0126, s2.loss_mask: 0.1041, loss: 1.1145
2022-08-18 15:19:30,757 - mmdet - INFO - Epoch [12][6700/18729]	lr: 1.000e-05, eta: 1:53:13, time: 0.556, data_time: 0.025, memory: 12528, loss_rpn_cls: 0.0352, loss_rpn_bbox: 0.1184, s0.loss_cls: 0.0925, s0.acc: 96.4453, s0.loss_bbox: 0.0600, s0.loss_mask: 0.5221, s1.loss_cls: 0.0417, s1.acc: 97.0436, s1.loss_bbox: 0.0286, s1.loss_mask: 0.2620, s2.loss_cls: 0.0226, s2.acc: 96.7562, s2.loss_bbox: 0.0119, s2.loss_mask: 0.1288, loss: 1.3237
2022-08-18 15:19:58,933 - mmdet - INFO - Epoch [12][6750/18729]	lr: 1.000e-05, eta: 1:52:44, time: 0.564, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0262, loss_rpn_bbox: 0.1063, s0.loss_cls: 0.0865, s0.acc: 96.6133, s0.loss_bbox: 0.0636, s0.loss_mask: 0.4591, s1.loss_cls: 0.0356, s1.acc: 97.2925, s1.loss_bbox: 0.0310, s1.loss_mask: 0.2344, s2.loss_cls: 0.0197, s2.acc: 96.9622, s2.loss_bbox: 0.0136, s2.loss_mask: 0.1116, loss: 1.1875
2022-08-18 15:20:25,785 - mmdet - INFO - Epoch [12][6800/18729]	lr: 1.000e-05, eta: 1:52:14, time: 0.537, data_time: 0.018, memory: 12528, loss_rpn_cls: 0.0212, loss_rpn_bbox: 0.1073, s0.loss_cls: 0.0769, s0.acc: 97.1016, s0.loss_bbox: 0.0615, s0.loss_mask: 0.4646, s1.loss_cls: 0.0350, s1.acc: 97.2865, s1.loss_bbox: 0.0286, s1.loss_mask: 0.2348, s2.loss_cls: 0.0193, s2.acc: 97.0190, s2.loss_bbox: 0.0121, s2.loss_mask: 0.1125, loss: 1.1737
2022-08-18 15:20:53,772 - mmdet - INFO - Epoch [12][6850/18729]	lr: 1.000e-05, eta: 1:51:45, time: 0.560, data_time: 0.031, memory: 12528, loss_rpn_cls: 0.0123, loss_rpn_bbox: 0.0680, s0.loss_cls: 0.0693, s0.acc: 97.2539, s0.loss_bbox: 0.0430, s0.loss_mask: 0.4193, s1.loss_cls: 0.0281, s1.acc: 97.8248, s1.loss_bbox: 0.0205, s1.loss_mask: 0.2115, s2.loss_cls: 0.0141, s2.acc: 97.5858, s2.loss_bbox: 0.0092, s2.loss_mask: 0.1035, loss: 0.9987
2022-08-18 15:21:22,366 - mmdet - INFO - Epoch [12][6900/18729]	lr: 1.000e-05, eta: 1:51:17, time: 0.572, data_time: 0.044, memory: 12528, loss_rpn_cls: 0.0210, loss_rpn_bbox: 0.0998, s0.loss_cls: 0.0820, s0.acc: 96.8438, s0.loss_bbox: 0.0566, s0.loss_mask: 0.5066, s1.loss_cls: 0.0358, s1.acc: 97.2312, s1.loss_bbox: 0.0267, s1.loss_mask: 0.2585, s2.loss_cls: 0.0181, s2.acc: 97.2472, s2.loss_bbox: 0.0111, s2.loss_mask: 0.1230, loss: 1.2393
2022-08-18 15:21:50,620 - mmdet - INFO - Epoch [12][6950/18729]	lr: 1.000e-05, eta: 1:50:49, time: 0.565, data_time: 0.038, memory: 12528, loss_rpn_cls: 0.0162, loss_rpn_bbox: 0.0853, s0.loss_cls: 0.0582, s0.acc: 97.6250, s0.loss_bbox: 0.0470, s0.loss_mask: 0.4526, s1.loss_cls: 0.0265, s1.acc: 98.0335, s1.loss_bbox: 0.0230, s1.loss_mask: 0.2288, s2.loss_cls: 0.0142, s2.acc: 97.8692, s2.loss_bbox: 0.0102, s2.loss_mask: 0.1110, loss: 1.0730
2022-08-18 15:22:19,129 - mmdet - INFO - Epoch [12][7000/18729]	lr: 1.000e-05, eta: 1:50:21, time: 0.570, data_time: 0.029, memory: 12528, loss_rpn_cls: 0.0168, loss_rpn_bbox: 0.0994, s0.loss_cls: 0.0644, s0.acc: 97.4727, s0.loss_bbox: 0.0575, s0.loss_mask: 0.4183, s1.loss_cls: 0.0269, s1.acc: 97.9734, s1.loss_bbox: 0.0268, s1.loss_mask: 0.2163, s2.loss_cls: 0.0150, s2.acc: 97.7582, s2.loss_bbox: 0.0115, s2.loss_mask: 0.1045, loss: 1.0574
2022-08-18 15:22:47,298 - mmdet - INFO - Epoch [12][7050/18729]	lr: 1.000e-05, eta: 1:49:53, time: 0.563, data_time: 0.035, memory: 12528, loss_rpn_cls: 0.0245, loss_rpn_bbox: 0.0991, s0.loss_cls: 0.0695, s0.acc: 97.2109, s0.loss_bbox: 0.0553, s0.loss_mask: 0.4392, s1.loss_cls: 0.0293, s1.acc: 97.8596, s1.loss_bbox: 0.0256, s1.loss_mask: 0.2207, s2.loss_cls: 0.0167, s2.acc: 97.4979, s2.loss_bbox: 0.0115, s2.loss_mask: 0.1086, loss: 1.1000
2022-08-18 15:23:13,802 - mmdet - INFO - Epoch [12][7100/18729]	lr: 1.000e-05, eta: 1:49:22, time: 0.530, data_time: 0.021, memory: 12528, loss_rpn_cls: 0.0209, loss_rpn_bbox: 0.0600, s0.loss_cls: 0.0514, s0.acc: 98.0859, s0.loss_bbox: 0.0400, s0.loss_mask: 0.4765, s1.loss_cls: 0.0234, s1.acc: 98.1819, s1.loss_bbox: 0.0192, s1.loss_mask: 0.2420, s2.loss_cls: 0.0121, s2.acc: 97.9939, s2.loss_bbox: 0.0088, s2.loss_mask: 0.1179, loss: 1.0721
2022-08-18 15:23:41,571 - mmdet - INFO - Epoch [12][7150/18729]	lr: 1.000e-05, eta: 1:48:53, time: 0.555, data_time: 0.020, memory: 12528, loss_rpn_cls: 0.0159, loss_rpn_bbox: 0.0953, s0.loss_cls: 0.0739, s0.acc: 97.0352, s0.loss_bbox: 0.0629, s0.loss_mask: 0.4420, s1.loss_cls: 0.0354, s1.acc: 97.1227, s1.loss_bbox: 0.0286, s1.loss_mask: 0.2227, s2.loss_cls: 0.0189, s2.acc: 96.8588, s2.loss_bbox: 0.0123, s2.loss_mask: 0.1078, loss: 1.1156
2022-08-18 15:24:09,851 - mmdet - INFO - Epoch [12][7200/18729]	lr: 1.000e-05, eta: 1:48:25, time: 0.566, data_time: 0.030, memory: 12528, loss_rpn_cls: 0.0172, loss_rpn_bbox: 0.0866, s0.loss_cls: 0.0723, s0.acc: 97.3281, s0.loss_bbox: 0.0560, s0.loss_mask: 0.4910, s1.loss_cls: 0.0327, s1.acc: 97.6507, s1.loss_bbox: 0.0260, s1.loss_mask: 0.2529, s2.loss_cls: 0.0181, s2.acc: 97.2097, s2.loss_bbox: 0.0114, s2.loss_mask: 0.1251, loss: 1.1892
2022-08-18 15:24:39,709 - mmdet - INFO - Epoch [12][7250/18729]	lr: 1.000e-05, eta: 1:47:59, time: 0.597, data_time: 0.049, memory: 12528, loss_rpn_cls: 0.0204, loss_rpn_bbox: 0.1059, s0.loss_cls: 0.0635, s0.acc: 97.5938, s0.loss_bbox: 0.0519, s0.loss_mask: 0.4639, s1.loss_cls: 0.0252, s1.acc: 98.0999, s1.loss_bbox: 0.0238, s1.loss_mask: 0.2396, s2.loss_cls: 0.0144, s2.acc: 97.8896, s2.loss_bbox: 0.0103, s2.loss_mask: 0.1180, loss: 1.1368
2022-08-18 15:25:05,900 - mmdet - INFO - Epoch [12][7300/18729]	lr: 1.000e-05, eta: 1:47:28, time: 0.524, data_time: 0.016, memory: 12528, loss_rpn_cls: 0.0177, loss_rpn_bbox: 0.0838, s0.loss_cls: 0.0635, s0.acc: 97.6250, s0.loss_bbox: 0.0519, s0.loss_mask: 0.4046, s1.loss_cls: 0.0260, s1.acc: 98.0119, s1.loss_bbox: 0.0255, s1.loss_mask: 0.2096, s2.loss_cls: 0.0147, s2.acc: 97.6878, s2.loss_bbox: 0.0112, s2.loss_mask: 0.1003, loss: 1.0088
2022-08-18 15:25:35,007 - mmdet - INFO - Epoch [12][7350/18729]	lr: 1.000e-05, eta: 1:47:01, time: 0.582, data_time: 0.036, memory: 12528, loss_rpn_cls: 0.0355, loss_rpn_bbox: 0.1344, s0.loss_cls: 0.0924, s0.acc: 96.3164, s0.loss_bbox: 0.0661, s0.loss_mask: 0.4778, s1.loss_cls: 0.0373, s1.acc: 97.0931, s1.loss_bbox: 0.0304, s1.loss_mask: 0.2379, s2.loss_cls: 0.0206, s2.acc: 96.6774, s2.loss_bbox: 0.0125, s2.loss_mask: 0.1156, loss: 1.2603
2022-08-18 15:26:02,613 - mmdet - INFO - Epoch [12][7400/18729]	lr: 1.000e-05, eta: 1:46:32, time: 0.552, data_time: 0.029, memory: 12528, loss_rpn_cls: 0.0227, loss_rpn_bbox: 0.0865, s0.loss_cls: 0.0768, s0.acc: 97.1133, s0.loss_bbox: 0.0518, s0.loss_mask: 0.4276, s1.loss_cls: 0.0316, s1.acc: 97.7291, s1.loss_bbox: 0.0242, s1.loss_mask: 0.2200, s2.loss_cls: 0.0161, s2.acc: 97.7195, s2.loss_bbox: 0.0110, s2.loss_mask: 0.1083, loss: 1.0766
2022-08-18 15:26:29,361 - mmdet - INFO - Epoch [12][7450/18729]	lr: 1.000e-05, eta: 1:46:02, time: 0.535, data_time: 0.024, memory: 12528, loss_rpn_cls: 0.0214, loss_rpn_bbox: 0.0888, s0.loss_cls: 0.0678, s0.acc: 97.3477, s0.loss_bbox: 0.0511, s0.loss_mask: 0.4455, s1.loss_cls: 0.0284, s1.acc: 97.9299, s1.loss_bbox: 0.0242, s1.loss_mask: 0.2211, s2.loss_cls: 0.0152, s2.acc: 97.9507, s2.loss_bbox: 0.0107, s2.loss_mask: 0.1083, loss: 1.0826
2022-08-18 15:27:02,152 - mmdet - INFO - Epoch [12][7500/18729]	lr: 1.000e-05, eta: 1:45:40, time: 0.656, data_time: 0.095, memory: 12528, loss_rpn_cls: 0.0195, loss_rpn_bbox: 0.0980, s0.loss_cls: 0.0735, s0.acc: 97.1875, s0.loss_bbox: 0.0605, s0.loss_mask: 0.4660, s1.loss_cls: 0.0313, s1.acc: 97.6327, s1.loss_bbox: 0.0281, s1.loss_mask: 0.2394, s2.loss_cls: 0.0177, s2.acc: 97.2442, s2.loss_bbox: 0.0118, s2.loss_mask: 0.1165, loss: 1.1624
2022-08-18 15:27:31,224 - mmdet - INFO - Epoch [12][7550/18729]	lr: 1.000e-05, eta: 1:45:13, time: 0.581, data_time: 0.035, memory: 12528, loss_rpn_cls: 0.0277, loss_rpn_bbox: 0.1082, s0.loss_cls: 0.0831, s0.acc: 96.8984, s0.loss_bbox: 0.0605, s0.loss_mask: 0.4516, s1.loss_cls: 0.0365, s1.acc: 97.4073, s1.loss_bbox: 0.0287, s1.loss_mask: 0.2383, s2.loss_cls: 0.0199, s2.acc: 97.1100, s2.loss_bbox: 0.0122, s2.loss_mask: 0.1144, loss: 1.1811
2022-08-18 15:27:57,294 - mmdet - INFO - Epoch [12][7600/18729]	lr: 1.000e-05, eta: 1:44:42, time: 0.521, data_time: 0.020, memory: 12528, loss_rpn_cls: 0.0165, loss_rpn_bbox: 0.0731, s0.loss_cls: 0.0731, s0.acc: 97.1133, s0.loss_bbox: 0.0465, s0.loss_mask: 0.4748, s1.loss_cls: 0.0336, s1.acc: 97.2837, s1.loss_bbox: 0.0235, s1.loss_mask: 0.2323, s2.loss_cls: 0.0186, s2.acc: 96.9690, s2.loss_bbox: 0.0099, s2.loss_mask: 0.1140, loss: 1.1157
2022-08-18 15:28:22,941 - mmdet - INFO - Epoch [12][7650/18729]	lr: 1.000e-05, eta: 1:44:10, time: 0.513, data_time: 0.022, memory: 12528, loss_rpn_cls: 0.0250, loss_rpn_bbox: 0.0514, s0.loss_cls: 0.0625, s0.acc: 97.6719, s0.loss_bbox: 0.0442, s0.loss_mask: 0.4774, s1.loss_cls: 0.0275, s1.acc: 97.8908, s1.loss_bbox: 0.0222, s1.loss_mask: 0.2476, s2.loss_cls: 0.0150, s2.acc: 97.5573, s2.loss_bbox: 0.0095, s2.loss_mask: 0.1189, loss: 1.1011
2022-08-18 15:28:49,251 - mmdet - INFO - Epoch [12][7700/18729]	lr: 1.000e-05, eta: 1:43:39, time: 0.526, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0319, loss_rpn_bbox: 0.0689, s0.loss_cls: 0.0626, s0.acc: 97.5938, s0.loss_bbox: 0.0375, s0.loss_mask: 0.4900, s1.loss_cls: 0.0284, s1.acc: 97.9679, s1.loss_bbox: 0.0184, s1.loss_mask: 0.2503, s2.loss_cls: 0.0142, s2.acc: 97.9454, s2.loss_bbox: 0.0080, s2.loss_mask: 0.1231, loss: 1.1333
2022-08-18 15:29:16,592 - mmdet - INFO - Epoch [12][7750/18729]	lr: 1.000e-05, eta: 1:43:10, time: 0.547, data_time: 0.018, memory: 12528, loss_rpn_cls: 0.0156, loss_rpn_bbox: 0.0805, s0.loss_cls: 0.0775, s0.acc: 97.1055, s0.loss_bbox: 0.0588, s0.loss_mask: 0.4364, s1.loss_cls: 0.0310, s1.acc: 97.8964, s1.loss_bbox: 0.0288, s1.loss_mask: 0.2246, s2.loss_cls: 0.0166, s2.acc: 97.7566, s2.loss_bbox: 0.0128, s2.loss_mask: 0.1092, loss: 1.0918
2022-08-18 15:29:44,442 - mmdet - INFO - Epoch [12][7800/18729]	lr: 1.000e-05, eta: 1:42:41, time: 0.557, data_time: 0.023, memory: 12528, loss_rpn_cls: 0.0184, loss_rpn_bbox: 0.0976, s0.loss_cls: 0.0725, s0.acc: 97.1758, s0.loss_bbox: 0.0619, s0.loss_mask: 0.4605, s1.loss_cls: 0.0323, s1.acc: 97.5769, s1.loss_bbox: 0.0301, s1.loss_mask: 0.2333, s2.loss_cls: 0.0187, s2.acc: 97.0886, s2.loss_bbox: 0.0133, s2.loss_mask: 0.1136, loss: 1.1522
2022-08-18 15:30:12,508 - mmdet - INFO - Epoch [12][7850/18729]	lr: 1.000e-05, eta: 1:42:13, time: 0.561, data_time: 0.026, memory: 12528, loss_rpn_cls: 0.0197, loss_rpn_bbox: 0.0947, s0.loss_cls: 0.0727, s0.acc: 97.1641, s0.loss_bbox: 0.0553, s0.loss_mask: 0.4304, s1.loss_cls: 0.0331, s1.acc: 97.4327, s1.loss_bbox: 0.0266, s1.loss_mask: 0.2173, s2.loss_cls: 0.0174, s2.acc: 97.1179, s2.loss_bbox: 0.0117, s2.loss_mask: 0.1045, loss: 1.0832
2022-08-18 15:30:40,697 - mmdet - INFO - Epoch [12][7900/18729]	lr: 1.000e-05, eta: 1:41:44, time: 0.564, data_time: 0.029, memory: 12528, loss_rpn_cls: 0.0224, loss_rpn_bbox: 0.0806, s0.loss_cls: 0.0738, s0.acc: 97.1992, s0.loss_bbox: 0.0552, s0.loss_mask: 0.4809, s1.loss_cls: 0.0313, s1.acc: 97.6330, s1.loss_bbox: 0.0275, s1.loss_mask: 0.2482, s2.loss_cls: 0.0163, s2.acc: 97.5812, s2.loss_bbox: 0.0127, s2.loss_mask: 0.1219, loss: 1.1708
2022-08-18 15:31:09,880 - mmdet - INFO - Epoch [12][7950/18729]	lr: 1.000e-05, eta: 1:41:18, time: 0.584, data_time: 0.045, memory: 12528, loss_rpn_cls: 0.0127, loss_rpn_bbox: 0.0866, s0.loss_cls: 0.0719, s0.acc: 97.2617, s0.loss_bbox: 0.0516, s0.loss_mask: 0.5105, s1.loss_cls: 0.0310, s1.acc: 97.6708, s1.loss_bbox: 0.0237, s1.loss_mask: 0.2637, s2.loss_cls: 0.0168, s2.acc: 97.5398, s2.loss_bbox: 0.0101, s2.loss_mask: 0.1301, loss: 1.2088
2022-08-18 15:31:38,107 - mmdet - INFO - Epoch [12][8000/18729]	lr: 1.000e-05, eta: 1:40:49, time: 0.565, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0266, loss_rpn_bbox: 0.0920, s0.loss_cls: 0.0746, s0.acc: 97.3242, s0.loss_bbox: 0.0566, s0.loss_mask: 0.4563, s1.loss_cls: 0.0303, s1.acc: 97.8587, s1.loss_bbox: 0.0273, s1.loss_mask: 0.2280, s2.loss_cls: 0.0164, s2.acc: 97.5548, s2.loss_bbox: 0.0121, s2.loss_mask: 0.1114, loss: 1.1316
2022-08-18 15:32:05,879 - mmdet - INFO - Epoch [12][8050/18729]	lr: 1.000e-05, eta: 1:40:21, time: 0.555, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0167, loss_rpn_bbox: 0.0940, s0.loss_cls: 0.0781, s0.acc: 97.0547, s0.loss_bbox: 0.0561, s0.loss_mask: 0.4629, s1.loss_cls: 0.0347, s1.acc: 97.4980, s1.loss_bbox: 0.0274, s1.loss_mask: 0.2357, s2.loss_cls: 0.0186, s2.acc: 97.0763, s2.loss_bbox: 0.0120, s2.loss_mask: 0.1167, loss: 1.1528
2022-08-18 15:32:33,811 - mmdet - INFO - Epoch [12][8100/18729]	lr: 1.000e-05, eta: 1:39:52, time: 0.559, data_time: 0.023, memory: 12528, loss_rpn_cls: 0.0218, loss_rpn_bbox: 0.0913, s0.loss_cls: 0.0749, s0.acc: 97.1836, s0.loss_bbox: 0.0607, s0.loss_mask: 0.3901, s1.loss_cls: 0.0327, s1.acc: 97.6533, s1.loss_bbox: 0.0289, s1.loss_mask: 0.1986, s2.loss_cls: 0.0182, s2.acc: 97.3693, s2.loss_bbox: 0.0127, s2.loss_mask: 0.0973, loss: 1.0273
2022-08-18 15:33:01,866 - mmdet - INFO - Epoch [12][8150/18729]	lr: 1.000e-05, eta: 1:39:24, time: 0.561, data_time: 0.030, memory: 12528, loss_rpn_cls: 0.0260, loss_rpn_bbox: 0.0762, s0.loss_cls: 0.0799, s0.acc: 97.0664, s0.loss_bbox: 0.0542, s0.loss_mask: 0.5004, s1.loss_cls: 0.0311, s1.acc: 97.6417, s1.loss_bbox: 0.0273, s1.loss_mask: 0.2520, s2.loss_cls: 0.0168, s2.acc: 97.5903, s2.loss_bbox: 0.0121, s2.loss_mask: 0.1224, loss: 1.1985
2022-08-18 15:33:28,918 - mmdet - INFO - Epoch [12][8200/18729]	lr: 1.000e-05, eta: 1:38:54, time: 0.541, data_time: 0.022, memory: 12528, loss_rpn_cls: 0.0157, loss_rpn_bbox: 0.0794, s0.loss_cls: 0.0668, s0.acc: 97.4102, s0.loss_bbox: 0.0541, s0.loss_mask: 0.4956, s1.loss_cls: 0.0246, s1.acc: 98.2088, s1.loss_bbox: 0.0257, s1.loss_mask: 0.2537, s2.loss_cls: 0.0134, s2.acc: 98.0540, s2.loss_bbox: 0.0112, s2.loss_mask: 0.1252, loss: 1.1654
2022-08-18 15:33:58,451 - mmdet - INFO - Epoch [12][8250/18729]	lr: 1.000e-05, eta: 1:38:28, time: 0.591, data_time: 0.033, memory: 12528, loss_rpn_cls: 0.0217, loss_rpn_bbox: 0.0992, s0.loss_cls: 0.0875, s0.acc: 96.5312, s0.loss_bbox: 0.0653, s0.loss_mask: 0.4383, s1.loss_cls: 0.0380, s1.acc: 97.0059, s1.loss_bbox: 0.0315, s1.loss_mask: 0.2200, s2.loss_cls: 0.0226, s2.acc: 96.4369, s2.loss_bbox: 0.0136, s2.loss_mask: 0.1071, loss: 1.1450
2022-08-18 15:34:26,135 - mmdet - INFO - Epoch [12][8300/18729]	lr: 1.000e-05, eta: 1:37:59, time: 0.554, data_time: 0.022, memory: 12528, loss_rpn_cls: 0.0244, loss_rpn_bbox: 0.1072, s0.loss_cls: 0.0793, s0.acc: 96.9141, s0.loss_bbox: 0.0631, s0.loss_mask: 0.4490, s1.loss_cls: 0.0356, s1.acc: 97.3620, s1.loss_bbox: 0.0303, s1.loss_mask: 0.2310, s2.loss_cls: 0.0214, s2.acc: 96.8518, s2.loss_bbox: 0.0128, s2.loss_mask: 0.1125, loss: 1.1666
2022-08-18 15:34:54,107 - mmdet - INFO - Epoch [12][8350/18729]	lr: 1.000e-05, eta: 1:37:30, time: 0.559, data_time: 0.024, memory: 12528, loss_rpn_cls: 0.0255, loss_rpn_bbox: 0.1136, s0.loss_cls: 0.0795, s0.acc: 96.9102, s0.loss_bbox: 0.0652, s0.loss_mask: 0.5057, s1.loss_cls: 0.0366, s1.acc: 97.1629, s1.loss_bbox: 0.0313, s1.loss_mask: 0.2533, s2.loss_cls: 0.0199, s2.acc: 96.9611, s2.loss_bbox: 0.0131, s2.loss_mask: 0.1201, loss: 1.2639
2022-08-18 15:35:22,626 - mmdet - INFO - Epoch [12][8400/18729]	lr: 1.000e-05, eta: 1:37:03, time: 0.570, data_time: 0.052, memory: 12528, loss_rpn_cls: 0.0141, loss_rpn_bbox: 0.0579, s0.loss_cls: 0.0610, s0.acc: 97.6367, s0.loss_bbox: 0.0463, s0.loss_mask: 0.4873, s1.loss_cls: 0.0273, s1.acc: 98.0684, s1.loss_bbox: 0.0224, s1.loss_mask: 0.2523, s2.loss_cls: 0.0140, s2.acc: 97.8401, s2.loss_bbox: 0.0099, s2.loss_mask: 0.1213, loss: 1.1138
2022-08-18 15:35:52,736 - mmdet - INFO - Epoch [12][8450/18729]	lr: 1.000e-05, eta: 1:36:37, time: 0.602, data_time: 0.053, memory: 12528, loss_rpn_cls: 0.0190, loss_rpn_bbox: 0.0834, s0.loss_cls: 0.0705, s0.acc: 97.2227, s0.loss_bbox: 0.0578, s0.loss_mask: 0.4707, s1.loss_cls: 0.0299, s1.acc: 97.8302, s1.loss_bbox: 0.0255, s1.loss_mask: 0.2358, s2.loss_cls: 0.0154, s2.acc: 97.6645, s2.loss_bbox: 0.0108, s2.loss_mask: 0.1150, loss: 1.1337
2022-08-18 15:36:21,191 - mmdet - INFO - Epoch [12][8500/18729]	lr: 1.000e-05, eta: 1:36:09, time: 0.569, data_time: 0.044, memory: 12528, loss_rpn_cls: 0.0262, loss_rpn_bbox: 0.0826, s0.loss_cls: 0.0771, s0.acc: 96.9258, s0.loss_bbox: 0.0551, s0.loss_mask: 0.4428, s1.loss_cls: 0.0306, s1.acc: 97.6772, s1.loss_bbox: 0.0261, s1.loss_mask: 0.2255, s2.loss_cls: 0.0168, s2.acc: 97.4326, s2.loss_bbox: 0.0114, s2.loss_mask: 0.1130, loss: 1.1070
2022-08-18 15:36:49,816 - mmdet - INFO - Epoch [12][8550/18729]	lr: 1.000e-05, eta: 1:35:41, time: 0.572, data_time: 0.027, memory: 12528, loss_rpn_cls: 0.0272, loss_rpn_bbox: 0.1026, s0.loss_cls: 0.0810, s0.acc: 96.9570, s0.loss_bbox: 0.0596, s0.loss_mask: 0.4196, s1.loss_cls: 0.0329, s1.acc: 97.3805, s1.loss_bbox: 0.0285, s1.loss_mask: 0.2135, s2.loss_cls: 0.0175, s2.acc: 97.3601, s2.loss_bbox: 0.0127, s2.loss_mask: 0.1045, loss: 1.0996
2022-08-18 15:37:18,698 - mmdet - INFO - Epoch [12][8600/18729]	lr: 1.000e-05, eta: 1:35:14, time: 0.578, data_time: 0.040, memory: 12528, loss_rpn_cls: 0.0205, loss_rpn_bbox: 0.0975, s0.loss_cls: 0.0782, s0.acc: 96.9766, s0.loss_bbox: 0.0566, s0.loss_mask: 0.5245, s1.loss_cls: 0.0341, s1.acc: 97.5661, s1.loss_bbox: 0.0264, s1.loss_mask: 0.2683, s2.loss_cls: 0.0181, s2.acc: 97.3382, s2.loss_bbox: 0.0108, s2.loss_mask: 0.1302, loss: 1.2651
2022-08-18 15:37:47,450 - mmdet - INFO - Epoch [12][8650/18729]	lr: 1.000e-05, eta: 1:34:46, time: 0.575, data_time: 0.040, memory: 12528, loss_rpn_cls: 0.0177, loss_rpn_bbox: 0.0926, s0.loss_cls: 0.0615, s0.acc: 97.7109, s0.loss_bbox: 0.0479, s0.loss_mask: 0.4338, s1.loss_cls: 0.0246, s1.acc: 98.2384, s1.loss_bbox: 0.0218, s1.loss_mask: 0.2209, s2.loss_cls: 0.0134, s2.acc: 97.9803, s2.loss_bbox: 0.0093, s2.loss_mask: 0.1083, loss: 1.0519
2022-08-18 15:38:16,893 - mmdet - INFO - Epoch [12][8700/18729]	lr: 1.000e-05, eta: 1:34:19, time: 0.589, data_time: 0.045, memory: 12528, loss_rpn_cls: 0.0152, loss_rpn_bbox: 0.0938, s0.loss_cls: 0.0643, s0.acc: 97.4805, s0.loss_bbox: 0.0571, s0.loss_mask: 0.4632, s1.loss_cls: 0.0265, s1.acc: 97.9995, s1.loss_bbox: 0.0268, s1.loss_mask: 0.2388, s2.loss_cls: 0.0157, s2.acc: 97.5590, s2.loss_bbox: 0.0115, s2.loss_mask: 0.1161, loss: 1.1289
2022-08-18 15:38:44,975 - mmdet - INFO - Epoch [12][8750/18729]	lr: 1.000e-05, eta: 1:33:51, time: 0.562, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0268, loss_rpn_bbox: 0.0778, s0.loss_cls: 0.0684, s0.acc: 97.1758, s0.loss_bbox: 0.0506, s0.loss_mask: 0.4447, s1.loss_cls: 0.0292, s1.acc: 97.6075, s1.loss_bbox: 0.0242, s1.loss_mask: 0.2277, s2.loss_cls: 0.0155, s2.acc: 97.5446, s2.loss_bbox: 0.0107, s2.loss_mask: 0.1117, loss: 1.0873
2022-08-18 15:39:12,628 - mmdet - INFO - Epoch [12][8800/18729]	lr: 1.000e-05, eta: 1:33:22, time: 0.553, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0218, loss_rpn_bbox: 0.0878, s0.loss_cls: 0.0765, s0.acc: 96.9453, s0.loss_bbox: 0.0541, s0.loss_mask: 0.4182, s1.loss_cls: 0.0329, s1.acc: 97.4363, s1.loss_bbox: 0.0254, s1.loss_mask: 0.2154, s2.loss_cls: 0.0167, s2.acc: 97.4665, s2.loss_bbox: 0.0114, s2.loss_mask: 0.1031, loss: 1.0633
2022-08-18 15:39:39,313 - mmdet - INFO - Epoch [12][8850/18729]	lr: 1.000e-05, eta: 1:32:52, time: 0.534, data_time: 0.022, memory: 12528, loss_rpn_cls: 0.0258, loss_rpn_bbox: 0.0789, s0.loss_cls: 0.0734, s0.acc: 97.3555, s0.loss_bbox: 0.0483, s0.loss_mask: 0.4880, s1.loss_cls: 0.0356, s1.acc: 97.4670, s1.loss_bbox: 0.0236, s1.loss_mask: 0.2345, s2.loss_cls: 0.0189, s2.acc: 97.4246, s2.loss_bbox: 0.0105, s2.loss_mask: 0.1131, loss: 1.1505
2022-08-18 15:40:05,498 - mmdet - INFO - Epoch [12][8900/18729]	lr: 1.000e-05, eta: 1:32:22, time: 0.524, data_time: 0.018, memory: 12528, loss_rpn_cls: 0.0131, loss_rpn_bbox: 0.0756, s0.loss_cls: 0.0562, s0.acc: 97.7930, s0.loss_bbox: 0.0514, s0.loss_mask: 0.4053, s1.loss_cls: 0.0233, s1.acc: 98.2187, s1.loss_bbox: 0.0258, s1.loss_mask: 0.2123, s2.loss_cls: 0.0144, s2.acc: 97.7393, s2.loss_bbox: 0.0114, s2.loss_mask: 0.1041, loss: 0.9930
2022-08-18 15:40:34,121 - mmdet - INFO - Epoch [12][8950/18729]	lr: 1.000e-05, eta: 1:31:54, time: 0.572, data_time: 0.015, memory: 12528, loss_rpn_cls: 0.0201, loss_rpn_bbox: 0.0842, s0.loss_cls: 0.0770, s0.acc: 96.8828, s0.loss_bbox: 0.0558, s0.loss_mask: 0.4250, s1.loss_cls: 0.0345, s1.acc: 97.3208, s1.loss_bbox: 0.0271, s1.loss_mask: 0.2205, s2.loss_cls: 0.0188, s2.acc: 97.0043, s2.loss_bbox: 0.0119, s2.loss_mask: 0.1049, loss: 1.0799
2022-08-18 15:41:01,672 - mmdet - INFO - Epoch [12][9000/18729]	lr: 1.000e-05, eta: 1:31:25, time: 0.551, data_time: 0.026, memory: 12528, loss_rpn_cls: 0.0305, loss_rpn_bbox: 0.1010, s0.loss_cls: 0.0796, s0.acc: 96.9297, s0.loss_bbox: 0.0574, s0.loss_mask: 0.4509, s1.loss_cls: 0.0336, s1.acc: 97.6336, s1.loss_bbox: 0.0266, s1.loss_mask: 0.2292, s2.loss_cls: 0.0178, s2.acc: 97.1436, s2.loss_bbox: 0.0117, s2.loss_mask: 0.1127, loss: 1.1509
2022-08-18 15:41:30,518 - mmdet - INFO - Epoch [12][9050/18729]	lr: 1.000e-05, eta: 1:30:58, time: 0.577, data_time: 0.031, memory: 12528, loss_rpn_cls: 0.0232, loss_rpn_bbox: 0.0971, s0.loss_cls: 0.0982, s0.acc: 96.4727, s0.loss_bbox: 0.0629, s0.loss_mask: 0.4696, s1.loss_cls: 0.0413, s1.acc: 97.1519, s1.loss_bbox: 0.0297, s1.loss_mask: 0.2402, s2.loss_cls: 0.0224, s2.acc: 96.6341, s2.loss_bbox: 0.0128, s2.loss_mask: 0.1182, loss: 1.2156
2022-08-18 15:42:01,221 - mmdet - INFO - Epoch [12][9100/18729]	lr: 1.000e-05, eta: 1:30:32, time: 0.614, data_time: 0.066, memory: 12528, loss_rpn_cls: 0.0306, loss_rpn_bbox: 0.0895, s0.loss_cls: 0.0639, s0.acc: 97.6484, s0.loss_bbox: 0.0495, s0.loss_mask: 0.4782, s1.loss_cls: 0.0271, s1.acc: 98.0617, s1.loss_bbox: 0.0225, s1.loss_mask: 0.2476, s2.loss_cls: 0.0159, s2.acc: 97.5240, s2.loss_bbox: 0.0096, s2.loss_mask: 0.1191, loss: 1.1537
2022-08-18 15:42:28,480 - mmdet - INFO - Epoch [12][9150/18729]	lr: 1.000e-05, eta: 1:30:03, time: 0.545, data_time: 0.027, memory: 12528, loss_rpn_cls: 0.0178, loss_rpn_bbox: 0.0765, s0.loss_cls: 0.0685, s0.acc: 97.3242, s0.loss_bbox: 0.0515, s0.loss_mask: 0.4467, s1.loss_cls: 0.0290, s1.acc: 97.9660, s1.loss_bbox: 0.0258, s1.loss_mask: 0.2260, s2.loss_cls: 0.0171, s2.acc: 97.3470, s2.loss_bbox: 0.0119, s2.loss_mask: 0.1080, loss: 1.0788
2022-08-18 15:42:55,861 - mmdet - INFO - Epoch [12][9200/18729]	lr: 1.000e-05, eta: 1:29:34, time: 0.548, data_time: 0.024, memory: 12528, loss_rpn_cls: 0.0184, loss_rpn_bbox: 0.0940, s0.loss_cls: 0.0712, s0.acc: 97.1172, s0.loss_bbox: 0.0518, s0.loss_mask: 0.4461, s1.loss_cls: 0.0298, s1.acc: 97.7952, s1.loss_bbox: 0.0242, s1.loss_mask: 0.2292, s2.loss_cls: 0.0166, s2.acc: 97.5412, s2.loss_bbox: 0.0107, s2.loss_mask: 0.1109, loss: 1.1027
2022-08-18 15:43:22,638 - mmdet - INFO - Epoch [12][9250/18729]	lr: 1.000e-05, eta: 1:29:04, time: 0.536, data_time: 0.022, memory: 12528, loss_rpn_cls: 0.0223, loss_rpn_bbox: 0.0748, s0.loss_cls: 0.0823, s0.acc: 96.8633, s0.loss_bbox: 0.0497, s0.loss_mask: 0.4645, s1.loss_cls: 0.0355, s1.acc: 97.1606, s1.loss_bbox: 0.0247, s1.loss_mask: 0.2382, s2.loss_cls: 0.0194, s2.acc: 96.7693, s2.loss_bbox: 0.0108, s2.loss_mask: 0.1175, loss: 1.1397
2022-08-18 15:43:50,989 - mmdet - INFO - Epoch [12][9300/18729]	lr: 1.000e-05, eta: 1:28:36, time: 0.567, data_time: 0.031, memory: 12528, loss_rpn_cls: 0.0116, loss_rpn_bbox: 0.0967, s0.loss_cls: 0.0690, s0.acc: 97.3711, s0.loss_bbox: 0.0501, s0.loss_mask: 0.4317, s1.loss_cls: 0.0270, s1.acc: 98.0402, s1.loss_bbox: 0.0245, s1.loss_mask: 0.2260, s2.loss_cls: 0.0158, s2.acc: 97.4730, s2.loss_bbox: 0.0113, s2.loss_mask: 0.1121, loss: 1.0759
2022-08-18 15:44:18,064 - mmdet - INFO - Epoch [12][9350/18729]	lr: 1.000e-05, eta: 1:28:07, time: 0.542, data_time: 0.024, memory: 12528, loss_rpn_cls: 0.0172, loss_rpn_bbox: 0.0747, s0.loss_cls: 0.0585, s0.acc: 97.6641, s0.loss_bbox: 0.0493, s0.loss_mask: 0.4734, s1.loss_cls: 0.0238, s1.acc: 98.1686, s1.loss_bbox: 0.0226, s1.loss_mask: 0.2405, s2.loss_cls: 0.0121, s2.acc: 98.0686, s2.loss_bbox: 0.0101, s2.loss_mask: 0.1177, loss: 1.0999
2022-08-18 15:44:46,415 - mmdet - INFO - Epoch [12][9400/18729]	lr: 1.000e-05, eta: 1:27:39, time: 0.567, data_time: 0.030, memory: 12528, loss_rpn_cls: 0.0226, loss_rpn_bbox: 0.1008, s0.loss_cls: 0.0825, s0.acc: 96.8477, s0.loss_bbox: 0.0616, s0.loss_mask: 0.4006, s1.loss_cls: 0.0370, s1.acc: 97.2324, s1.loss_bbox: 0.0289, s1.loss_mask: 0.2085, s2.loss_cls: 0.0200, s2.acc: 96.8790, s2.loss_bbox: 0.0126, s2.loss_mask: 0.1010, loss: 1.0760
2022-08-18 15:45:14,150 - mmdet - INFO - Epoch [12][9450/18729]	lr: 1.000e-05, eta: 1:27:10, time: 0.555, data_time: 0.027, memory: 12528, loss_rpn_cls: 0.0171, loss_rpn_bbox: 0.0737, s0.loss_cls: 0.0894, s0.acc: 96.5352, s0.loss_bbox: 0.0539, s0.loss_mask: 0.5083, s1.loss_cls: 0.0388, s1.acc: 97.1102, s1.loss_bbox: 0.0246, s1.loss_mask: 0.2432, s2.loss_cls: 0.0200, s2.acc: 96.9788, s2.loss_bbox: 0.0106, s2.loss_mask: 0.1193, loss: 1.1988
2022-08-18 15:45:43,464 - mmdet - INFO - Epoch [12][9500/18729]	lr: 1.000e-05, eta: 1:26:43, time: 0.586, data_time: 0.044, memory: 12528, loss_rpn_cls: 0.0283, loss_rpn_bbox: 0.1172, s0.loss_cls: 0.0799, s0.acc: 97.0938, s0.loss_bbox: 0.0586, s0.loss_mask: 0.4917, s1.loss_cls: 0.0345, s1.acc: 97.5642, s1.loss_bbox: 0.0279, s1.loss_mask: 0.2504, s2.loss_cls: 0.0201, s2.acc: 97.0342, s2.loss_bbox: 0.0118, s2.loss_mask: 0.1219, loss: 1.2423
2022-08-18 15:46:09,641 - mmdet - INFO - Epoch [12][9550/18729]	lr: 1.000e-05, eta: 1:26:13, time: 0.524, data_time: 0.019, memory: 12528, loss_rpn_cls: 0.0104, loss_rpn_bbox: 0.0610, s0.loss_cls: 0.0513, s0.acc: 98.1328, s0.loss_bbox: 0.0418, s0.loss_mask: 0.4559, s1.loss_cls: 0.0235, s1.acc: 98.4805, s1.loss_bbox: 0.0207, s1.loss_mask: 0.2333, s2.loss_cls: 0.0127, s2.acc: 98.2353, s2.loss_bbox: 0.0095, s2.loss_mask: 0.1139, loss: 1.0340
2022-08-18 15:46:35,951 - mmdet - INFO - Epoch [12][9600/18729]	lr: 1.000e-05, eta: 1:25:43, time: 0.526, data_time: 0.015, memory: 12528, loss_rpn_cls: 0.0212, loss_rpn_bbox: 0.0854, s0.loss_cls: 0.0739, s0.acc: 97.2695, s0.loss_bbox: 0.0527, s0.loss_mask: 0.4600, s1.loss_cls: 0.0330, s1.acc: 97.6090, s1.loss_bbox: 0.0256, s1.loss_mask: 0.2400, s2.loss_cls: 0.0178, s2.acc: 97.2351, s2.loss_bbox: 0.0109, s2.loss_mask: 0.1150, loss: 1.1357
2022-08-18 15:47:04,675 - mmdet - INFO - Epoch [12][9650/18729]	lr: 1.000e-05, eta: 1:25:15, time: 0.574, data_time: 0.035, memory: 12528, loss_rpn_cls: 0.0258, loss_rpn_bbox: 0.1120, s0.loss_cls: 0.0932, s0.acc: 96.4531, s0.loss_bbox: 0.0543, s0.loss_mask: 0.4899, s1.loss_cls: 0.0404, s1.acc: 96.8655, s1.loss_bbox: 0.0247, s1.loss_mask: 0.2443, s2.loss_cls: 0.0214, s2.acc: 96.6908, s2.loss_bbox: 0.0104, s2.loss_mask: 0.1192, loss: 1.2358
2022-08-18 15:47:31,990 - mmdet - INFO - Epoch [12][9700/18729]	lr: 1.000e-05, eta: 1:24:46, time: 0.546, data_time: 0.024, memory: 12528, loss_rpn_cls: 0.0192, loss_rpn_bbox: 0.0935, s0.loss_cls: 0.0703, s0.acc: 97.2031, s0.loss_bbox: 0.0562, s0.loss_mask: 0.4804, s1.loss_cls: 0.0309, s1.acc: 97.6486, s1.loss_bbox: 0.0279, s1.loss_mask: 0.2441, s2.loss_cls: 0.0179, s2.acc: 97.1938, s2.loss_bbox: 0.0123, s2.loss_mask: 0.1192, loss: 1.1720
2022-08-18 15:47:59,547 - mmdet - INFO - Epoch [12][9750/18729]	lr: 1.000e-05, eta: 1:24:18, time: 0.551, data_time: 0.030, memory: 12528, loss_rpn_cls: 0.0202, loss_rpn_bbox: 0.1021, s0.loss_cls: 0.0743, s0.acc: 97.1133, s0.loss_bbox: 0.0555, s0.loss_mask: 0.4368, s1.loss_cls: 0.0316, s1.acc: 97.6029, s1.loss_bbox: 0.0265, s1.loss_mask: 0.2249, s2.loss_cls: 0.0181, s2.acc: 97.1442, s2.loss_bbox: 0.0115, s2.loss_mask: 0.1084, loss: 1.1099
2022-08-18 15:48:26,409 - mmdet - INFO - Epoch [12][9800/18729]	lr: 1.000e-05, eta: 1:23:48, time: 0.537, data_time: 0.020, memory: 12528, loss_rpn_cls: 0.0169, loss_rpn_bbox: 0.1015, s0.loss_cls: 0.0808, s0.acc: 96.7773, s0.loss_bbox: 0.0591, s0.loss_mask: 0.4268, s1.loss_cls: 0.0350, s1.acc: 97.2587, s1.loss_bbox: 0.0287, s1.loss_mask: 0.2126, s2.loss_cls: 0.0194, s2.acc: 96.8663, s2.loss_bbox: 0.0130, s2.loss_mask: 0.1028, loss: 1.0967
2022-08-18 15:48:53,730 - mmdet - INFO - Epoch [12][9850/18729]	lr: 1.000e-05, eta: 1:23:19, time: 0.546, data_time: 0.021, memory: 12528, loss_rpn_cls: 0.0126, loss_rpn_bbox: 0.0853, s0.loss_cls: 0.0739, s0.acc: 96.9414, s0.loss_bbox: 0.0548, s0.loss_mask: 0.4267, s1.loss_cls: 0.0278, s1.acc: 97.9132, s1.loss_bbox: 0.0260, s1.loss_mask: 0.2220, s2.loss_cls: 0.0154, s2.acc: 97.7547, s2.loss_bbox: 0.0118, s2.loss_mask: 0.1084, loss: 1.0645
2022-08-18 15:49:21,633 - mmdet - INFO - Epoch [12][9900/18729]	lr: 1.000e-05, eta: 1:22:51, time: 0.558, data_time: 0.025, memory: 12528, loss_rpn_cls: 0.0208, loss_rpn_bbox: 0.0939, s0.loss_cls: 0.0794, s0.acc: 96.8633, s0.loss_bbox: 0.0561, s0.loss_mask: 0.4679, s1.loss_cls: 0.0357, s1.acc: 97.2486, s1.loss_bbox: 0.0277, s1.loss_mask: 0.2404, s2.loss_cls: 0.0194, s2.acc: 96.9770, s2.loss_bbox: 0.0116, s2.loss_mask: 0.1146, loss: 1.1675
2022-08-18 15:49:50,277 - mmdet - INFO - Epoch [12][9950/18729]	lr: 1.000e-05, eta: 1:22:23, time: 0.573, data_time: 0.031, memory: 12528, loss_rpn_cls: 0.0193, loss_rpn_bbox: 0.0941, s0.loss_cls: 0.0696, s0.acc: 97.3867, s0.loss_bbox: 0.0552, s0.loss_mask: 0.4524, s1.loss_cls: 0.0291, s1.acc: 97.8065, s1.loss_bbox: 0.0265, s1.loss_mask: 0.2295, s2.loss_cls: 0.0161, s2.acc: 97.5486, s2.loss_bbox: 0.0115, s2.loss_mask: 0.1109, loss: 1.1142
2022-08-18 15:50:18,367 - mmdet - INFO - Epoch [12][10000/18729]	lr: 1.000e-05, eta: 1:21:55, time: 0.562, data_time: 0.036, memory: 12528, loss_rpn_cls: 0.0228, loss_rpn_bbox: 0.1000, s0.loss_cls: 0.0863, s0.acc: 96.4922, s0.loss_bbox: 0.0570, s0.loss_mask: 0.4531, s1.loss_cls: 0.0382, s1.acc: 97.0466, s1.loss_bbox: 0.0262, s1.loss_mask: 0.2336, s2.loss_cls: 0.0202, s2.acc: 96.7918, s2.loss_bbox: 0.0113, s2.loss_mask: 0.1137, loss: 1.1626
2022-08-18 15:50:45,164 - mmdet - INFO - Epoch [12][10050/18729]	lr: 1.000e-05, eta: 1:21:26, time: 0.536, data_time: 0.025, memory: 12528, loss_rpn_cls: 0.0223, loss_rpn_bbox: 0.0756, s0.loss_cls: 0.0763, s0.acc: 97.0547, s0.loss_bbox: 0.0517, s0.loss_mask: 0.4328, s1.loss_cls: 0.0319, s1.acc: 97.5282, s1.loss_bbox: 0.0250, s1.loss_mask: 0.2275, s2.loss_cls: 0.0165, s2.acc: 97.3012, s2.loss_bbox: 0.0112, s2.loss_mask: 0.1119, loss: 1.0826
2022-08-18 15:51:12,240 - mmdet - INFO - Epoch [12][10100/18729]	lr: 1.000e-05, eta: 1:20:57, time: 0.542, data_time: 0.027, memory: 12528, loss_rpn_cls: 0.0196, loss_rpn_bbox: 0.0667, s0.loss_cls: 0.0705, s0.acc: 97.2930, s0.loss_bbox: 0.0531, s0.loss_mask: 0.4447, s1.loss_cls: 0.0295, s1.acc: 97.8012, s1.loss_bbox: 0.0267, s1.loss_mask: 0.2318, s2.loss_cls: 0.0160, s2.acc: 97.6528, s2.loss_bbox: 0.0112, s2.loss_mask: 0.1126, loss: 1.0824
2022-08-18 15:51:40,325 - mmdet - INFO - Epoch [12][10150/18729]	lr: 1.000e-05, eta: 1:20:28, time: 0.562, data_time: 0.025, memory: 12528, loss_rpn_cls: 0.0214, loss_rpn_bbox: 0.1025, s0.loss_cls: 0.0752, s0.acc: 97.2188, s0.loss_bbox: 0.0592, s0.loss_mask: 0.4722, s1.loss_cls: 0.0312, s1.acc: 97.7592, s1.loss_bbox: 0.0278, s1.loss_mask: 0.2447, s2.loss_cls: 0.0184, s2.acc: 97.2159, s2.loss_bbox: 0.0114, s2.loss_mask: 0.1170, loss: 1.1810
2022-08-18 15:52:06,751 - mmdet - INFO - Epoch [12][10200/18729]	lr: 1.000e-05, eta: 1:19:59, time: 0.529, data_time: 0.025, memory: 12528, loss_rpn_cls: 0.0158, loss_rpn_bbox: 0.0637, s0.loss_cls: 0.0558, s0.acc: 98.0430, s0.loss_bbox: 0.0446, s0.loss_mask: 0.4471, s1.loss_cls: 0.0232, s1.acc: 98.3143, s1.loss_bbox: 0.0214, s1.loss_mask: 0.2281, s2.loss_cls: 0.0127, s2.acc: 98.1876, s2.loss_bbox: 0.0096, s2.loss_mask: 0.1117, loss: 1.0335
2022-08-18 15:52:35,290 - mmdet - INFO - Epoch [12][10250/18729]	lr: 1.000e-05, eta: 1:19:31, time: 0.571, data_time: 0.035, memory: 12528, loss_rpn_cls: 0.0162, loss_rpn_bbox: 0.0809, s0.loss_cls: 0.0694, s0.acc: 97.3633, s0.loss_bbox: 0.0510, s0.loss_mask: 0.4401, s1.loss_cls: 0.0339, s1.acc: 97.4625, s1.loss_bbox: 0.0246, s1.loss_mask: 0.2261, s2.loss_cls: 0.0181, s2.acc: 97.2135, s2.loss_bbox: 0.0105, s2.loss_mask: 0.1089, loss: 1.0798
2022-08-18 15:53:02,361 - mmdet - INFO - Epoch [12][10300/18729]	lr: 1.000e-05, eta: 1:19:02, time: 0.541, data_time: 0.023, memory: 12528, loss_rpn_cls: 0.0220, loss_rpn_bbox: 0.1056, s0.loss_cls: 0.0731, s0.acc: 96.9531, s0.loss_bbox: 0.0627, s0.loss_mask: 0.4907, s1.loss_cls: 0.0317, s1.acc: 97.5914, s1.loss_bbox: 0.0317, s1.loss_mask: 0.2512, s2.loss_cls: 0.0190, s2.acc: 96.8979, s2.loss_bbox: 0.0130, s2.loss_mask: 0.1226, loss: 1.2233
2022-08-18 15:53:28,419 - mmdet - INFO - Epoch [12][10350/18729]	lr: 1.000e-05, eta: 1:18:32, time: 0.521, data_time: 0.015, memory: 12528, loss_rpn_cls: 0.0252, loss_rpn_bbox: 0.0640, s0.loss_cls: 0.0652, s0.acc: 97.3750, s0.loss_bbox: 0.0467, s0.loss_mask: 0.4089, s1.loss_cls: 0.0302, s1.acc: 97.6894, s1.loss_bbox: 0.0231, s1.loss_mask: 0.2103, s2.loss_cls: 0.0159, s2.acc: 97.4357, s2.loss_bbox: 0.0105, s2.loss_mask: 0.1014, loss: 1.0014
2022-08-18 15:53:57,843 - mmdet - INFO - Epoch [12][10400/18729]	lr: 1.000e-05, eta: 1:18:05, time: 0.588, data_time: 0.032, memory: 12528, loss_rpn_cls: 0.0192, loss_rpn_bbox: 0.1014, s0.loss_cls: 0.0873, s0.acc: 96.4805, s0.loss_bbox: 0.0685, s0.loss_mask: 0.4401, s1.loss_cls: 0.0358, s1.acc: 97.3153, s1.loss_bbox: 0.0307, s1.loss_mask: 0.2317, s2.loss_cls: 0.0212, s2.acc: 96.3657, s2.loss_bbox: 0.0129, s2.loss_mask: 0.1066, loss: 1.1554
2022-08-18 15:54:24,897 - mmdet - INFO - Epoch [12][10450/18729]	lr: 1.000e-05, eta: 1:17:36, time: 0.541, data_time: 0.017, memory: 12528, loss_rpn_cls: 0.0164, loss_rpn_bbox: 0.0864, s0.loss_cls: 0.0740, s0.acc: 97.3047, s0.loss_bbox: 0.0530, s0.loss_mask: 0.4778, s1.loss_cls: 0.0300, s1.acc: 97.7721, s1.loss_bbox: 0.0265, s1.loss_mask: 0.2445, s2.loss_cls: 0.0160, s2.acc: 97.7647, s2.loss_bbox: 0.0121, s2.loss_mask: 0.1190, loss: 1.1558
2022-08-18 15:54:53,831 - mmdet - INFO - Epoch [12][10500/18729]	lr: 1.000e-05, eta: 1:17:09, time: 0.579, data_time: 0.034, memory: 12528, loss_rpn_cls: 0.0223, loss_rpn_bbox: 0.1246, s0.loss_cls: 0.0856, s0.acc: 96.7891, s0.loss_bbox: 0.0618, s0.loss_mask: 0.4457, s1.loss_cls: 0.0327, s1.acc: 97.5485, s1.loss_bbox: 0.0278, s1.loss_mask: 0.2243, s2.loss_cls: 0.0179, s2.acc: 97.4160, s2.loss_bbox: 0.0120, s2.loss_mask: 0.1085, loss: 1.1633
2022-08-18 15:55:21,771 - mmdet - INFO - Epoch [12][10550/18729]	lr: 1.000e-05, eta: 1:16:40, time: 0.559, data_time: 0.031, memory: 12528, loss_rpn_cls: 0.0259, loss_rpn_bbox: 0.1124, s0.loss_cls: 0.0777, s0.acc: 96.9766, s0.loss_bbox: 0.0598, s0.loss_mask: 0.4817, s1.loss_cls: 0.0340, s1.acc: 97.5250, s1.loss_bbox: 0.0279, s1.loss_mask: 0.2416, s2.loss_cls: 0.0178, s2.acc: 97.2316, s2.loss_bbox: 0.0121, s2.loss_mask: 0.1176, loss: 1.2085
2022-08-18 15:55:51,314 - mmdet - INFO - Epoch [12][10600/18729]	lr: 1.000e-05, eta: 1:16:13, time: 0.591, data_time: 0.044, memory: 12528, loss_rpn_cls: 0.0216, loss_rpn_bbox: 0.1083, s0.loss_cls: 0.0774, s0.acc: 96.9922, s0.loss_bbox: 0.0610, s0.loss_mask: 0.4379, s1.loss_cls: 0.0341, s1.acc: 97.3131, s1.loss_bbox: 0.0274, s1.loss_mask: 0.2244, s2.loss_cls: 0.0181, s2.acc: 97.0313, s2.loss_bbox: 0.0122, s2.loss_mask: 0.1090, loss: 1.1313
2022-08-18 15:56:18,448 - mmdet - INFO - Epoch [12][10650/18729]	lr: 1.000e-05, eta: 1:15:44, time: 0.543, data_time: 0.018, memory: 12528, loss_rpn_cls: 0.0202, loss_rpn_bbox: 0.0773, s0.loss_cls: 0.0712, s0.acc: 97.1914, s0.loss_bbox: 0.0635, s0.loss_mask: 0.4342, s1.loss_cls: 0.0319, s1.acc: 97.5828, s1.loss_bbox: 0.0306, s1.loss_mask: 0.2208, s2.loss_cls: 0.0170, s2.acc: 97.2271, s2.loss_bbox: 0.0123, s2.loss_mask: 0.1054, loss: 1.0845
2022-08-18 15:56:47,777 - mmdet - INFO - Epoch [12][10700/18729]	lr: 1.000e-05, eta: 1:15:17, time: 0.587, data_time: 0.031, memory: 12528, loss_rpn_cls: 0.0242, loss_rpn_bbox: 0.1175, s0.loss_cls: 0.0892, s0.acc: 96.4609, s0.loss_bbox: 0.0643, s0.loss_mask: 0.4708, s1.loss_cls: 0.0406, s1.acc: 96.8492, s1.loss_bbox: 0.0306, s1.loss_mask: 0.2430, s2.loss_cls: 0.0225, s2.acc: 96.5370, s2.loss_bbox: 0.0136, s2.loss_mask: 0.1208, loss: 1.2371
2022-08-18 15:57:15,168 - mmdet - INFO - Epoch [12][10750/18729]	lr: 1.000e-05, eta: 1:14:49, time: 0.548, data_time: 0.034, memory: 12528, loss_rpn_cls: 0.0115, loss_rpn_bbox: 0.0501, s0.loss_cls: 0.0616, s0.acc: 97.6133, s0.loss_bbox: 0.0447, s0.loss_mask: 0.4909, s1.loss_cls: 0.0273, s1.acc: 97.9417, s1.loss_bbox: 0.0219, s1.loss_mask: 0.2546, s2.loss_cls: 0.0151, s2.acc: 97.4469, s2.loss_bbox: 0.0100, s2.loss_mask: 0.1246, loss: 1.1123
2022-08-18 15:57:45,220 - mmdet - INFO - Epoch [12][10800/18729]	lr: 1.000e-05, eta: 1:14:22, time: 0.601, data_time: 0.050, memory: 12528, loss_rpn_cls: 0.0249, loss_rpn_bbox: 0.0964, s0.loss_cls: 0.0855, s0.acc: 96.8203, s0.loss_bbox: 0.0590, s0.loss_mask: 0.5175, s1.loss_cls: 0.0352, s1.acc: 97.2733, s1.loss_bbox: 0.0274, s1.loss_mask: 0.2648, s2.loss_cls: 0.0199, s2.acc: 96.7967, s2.loss_bbox: 0.0112, s2.loss_mask: 0.1274, loss: 1.2690
2022-08-18 15:58:12,383 - mmdet - INFO - Epoch [12][10850/18729]	lr: 1.000e-05, eta: 1:13:53, time: 0.543, data_time: 0.027, memory: 12528, loss_rpn_cls: 0.0160, loss_rpn_bbox: 0.0532, s0.loss_cls: 0.0608, s0.acc: 97.6328, s0.loss_bbox: 0.0479, s0.loss_mask: 0.5091, s1.loss_cls: 0.0260, s1.acc: 97.8200, s1.loss_bbox: 0.0243, s1.loss_mask: 0.2595, s2.loss_cls: 0.0145, s2.acc: 97.7046, s2.loss_bbox: 0.0109, s2.loss_mask: 0.1273, loss: 1.1494
2022-08-18 15:58:40,525 - mmdet - INFO - Epoch [12][10900/18729]	lr: 1.000e-05, eta: 1:13:25, time: 0.563, data_time: 0.037, memory: 12528, loss_rpn_cls: 0.0228, loss_rpn_bbox: 0.0845, s0.loss_cls: 0.0743, s0.acc: 96.9609, s0.loss_bbox: 0.0521, s0.loss_mask: 0.4773, s1.loss_cls: 0.0347, s1.acc: 97.3739, s1.loss_bbox: 0.0248, s1.loss_mask: 0.2448, s2.loss_cls: 0.0182, s2.acc: 97.2422, s2.loss_bbox: 0.0108, s2.loss_mask: 0.1194, loss: 1.1638
2022-08-18 15:59:08,474 - mmdet - INFO - Epoch [12][10950/18729]	lr: 1.000e-05, eta: 1:12:57, time: 0.559, data_time: 0.017, memory: 12528, loss_rpn_cls: 0.0272, loss_rpn_bbox: 0.1123, s0.loss_cls: 0.0846, s0.acc: 96.6094, s0.loss_bbox: 0.0646, s0.loss_mask: 0.3963, s1.loss_cls: 0.0377, s1.acc: 96.9168, s1.loss_bbox: 0.0310, s1.loss_mask: 0.2002, s2.loss_cls: 0.0205, s2.acc: 96.8577, s2.loss_bbox: 0.0137, s2.loss_mask: 0.0963, loss: 1.0844
2022-08-18 15:59:36,539 - mmdet - INFO - Epoch [12][11000/18729]	lr: 1.000e-05, eta: 1:12:28, time: 0.561, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0178, loss_rpn_bbox: 0.0656, s0.loss_cls: 0.0700, s0.acc: 97.4766, s0.loss_bbox: 0.0511, s0.loss_mask: 0.4844, s1.loss_cls: 0.0310, s1.acc: 97.7994, s1.loss_bbox: 0.0251, s1.loss_mask: 0.2517, s2.loss_cls: 0.0158, s2.acc: 97.7090, s2.loss_bbox: 0.0112, s2.loss_mask: 0.1214, loss: 1.1450
2022-08-18 16:00:03,452 - mmdet - INFO - Epoch [12][11050/18729]	lr: 1.000e-05, eta: 1:11:59, time: 0.538, data_time: 0.022, memory: 12528, loss_rpn_cls: 0.0202, loss_rpn_bbox: 0.0942, s0.loss_cls: 0.0663, s0.acc: 97.4805, s0.loss_bbox: 0.0541, s0.loss_mask: 0.4659, s1.loss_cls: 0.0311, s1.acc: 97.6267, s1.loss_bbox: 0.0261, s1.loss_mask: 0.2323, s2.loss_cls: 0.0176, s2.acc: 97.1027, s2.loss_bbox: 0.0111, s2.loss_mask: 0.1132, loss: 1.1320
2022-08-18 16:00:30,111 - mmdet - INFO - Epoch [12][11100/18729]	lr: 1.000e-05, eta: 1:11:30, time: 0.533, data_time: 0.018, memory: 12528, loss_rpn_cls: 0.0211, loss_rpn_bbox: 0.0872, s0.loss_cls: 0.0741, s0.acc: 97.1250, s0.loss_bbox: 0.0565, s0.loss_mask: 0.4571, s1.loss_cls: 0.0334, s1.acc: 97.4670, s1.loss_bbox: 0.0266, s1.loss_mask: 0.2252, s2.loss_cls: 0.0163, s2.acc: 97.4844, s2.loss_bbox: 0.0113, s2.loss_mask: 0.1092, loss: 1.1179
2022-08-18 16:00:58,984 - mmdet - INFO - Epoch [12][11150/18729]	lr: 1.000e-05, eta: 1:11:03, time: 0.577, data_time: 0.032, memory: 12528, loss_rpn_cls: 0.0168, loss_rpn_bbox: 0.1076, s0.loss_cls: 0.0629, s0.acc: 97.6172, s0.loss_bbox: 0.0582, s0.loss_mask: 0.4418, s1.loss_cls: 0.0258, s1.acc: 97.9390, s1.loss_bbox: 0.0270, s1.loss_mask: 0.2293, s2.loss_cls: 0.0145, s2.acc: 97.8547, s2.loss_bbox: 0.0118, s2.loss_mask: 0.1109, loss: 1.1066
2022-08-18 16:01:28,808 - mmdet - INFO - Epoch [12][11200/18729]	lr: 1.000e-05, eta: 1:10:36, time: 0.596, data_time: 0.045, memory: 12528, loss_rpn_cls: 0.0239, loss_rpn_bbox: 0.1023, s0.loss_cls: 0.0704, s0.acc: 97.3203, s0.loss_bbox: 0.0537, s0.loss_mask: 0.4652, s1.loss_cls: 0.0299, s1.acc: 97.7690, s1.loss_bbox: 0.0255, s1.loss_mask: 0.2360, s2.loss_cls: 0.0176, s2.acc: 97.3513, s2.loss_bbox: 0.0111, s2.loss_mask: 0.1122, loss: 1.1478
2022-08-18 16:01:57,411 - mmdet - INFO - Epoch [12][11250/18729]	lr: 1.000e-05, eta: 1:10:08, time: 0.572, data_time: 0.029, memory: 12528, loss_rpn_cls: 0.0218, loss_rpn_bbox: 0.0836, s0.loss_cls: 0.0831, s0.acc: 96.7148, s0.loss_bbox: 0.0524, s0.loss_mask: 0.4895, s1.loss_cls: 0.0388, s1.acc: 97.0473, s1.loss_bbox: 0.0250, s1.loss_mask: 0.2371, s2.loss_cls: 0.0199, s2.acc: 96.8852, s2.loss_bbox: 0.0110, s2.loss_mask: 0.1174, loss: 1.1796
2022-08-18 16:02:26,435 - mmdet - INFO - Epoch [12][11300/18729]	lr: 1.000e-05, eta: 1:09:40, time: 0.580, data_time: 0.041, memory: 12528, loss_rpn_cls: 0.0330, loss_rpn_bbox: 0.1195, s0.loss_cls: 0.0869, s0.acc: 96.8320, s0.loss_bbox: 0.0607, s0.loss_mask: 0.4742, s1.loss_cls: 0.0393, s1.acc: 97.2839, s1.loss_bbox: 0.0274, s1.loss_mask: 0.2420, s2.loss_cls: 0.0218, s2.acc: 96.7591, s2.loss_bbox: 0.0115, s2.loss_mask: 0.1172, loss: 1.2335
2022-08-18 16:02:57,250 - mmdet - INFO - Epoch [12][11350/18729]	lr: 1.000e-05, eta: 1:09:14, time: 0.616, data_time: 0.050, memory: 12528, loss_rpn_cls: 0.0295, loss_rpn_bbox: 0.1131, s0.loss_cls: 0.0845, s0.acc: 96.7578, s0.loss_bbox: 0.0669, s0.loss_mask: 0.4682, s1.loss_cls: 0.0340, s1.acc: 97.3670, s1.loss_bbox: 0.0302, s1.loss_mask: 0.2431, s2.loss_cls: 0.0186, s2.acc: 97.1508, s2.loss_bbox: 0.0128, s2.loss_mask: 0.1178, loss: 1.2186
2022-08-18 16:03:26,488 - mmdet - INFO - Epoch [12][11400/18729]	lr: 1.000e-05, eta: 1:08:46, time: 0.585, data_time: 0.045, memory: 12528, loss_rpn_cls: 0.0212, loss_rpn_bbox: 0.0662, s0.loss_cls: 0.0742, s0.acc: 97.0898, s0.loss_bbox: 0.0495, s0.loss_mask: 0.4921, s1.loss_cls: 0.0319, s1.acc: 97.5207, s1.loss_bbox: 0.0247, s1.loss_mask: 0.2547, s2.loss_cls: 0.0160, s2.acc: 97.5249, s2.loss_bbox: 0.0110, s2.loss_mask: 0.1280, loss: 1.1695
2022-08-18 16:03:54,976 - mmdet - INFO - Epoch [12][11450/18729]	lr: 1.000e-05, eta: 1:08:19, time: 0.570, data_time: 0.029, memory: 12528, loss_rpn_cls: 0.0303, loss_rpn_bbox: 0.1131, s0.loss_cls: 0.0969, s0.acc: 96.2812, s0.loss_bbox: 0.0648, s0.loss_mask: 0.4748, s1.loss_cls: 0.0416, s1.acc: 96.8274, s1.loss_bbox: 0.0291, s1.loss_mask: 0.2415, s2.loss_cls: 0.0222, s2.acc: 96.6837, s2.loss_bbox: 0.0125, s2.loss_mask: 0.1180, loss: 1.2448
2022-08-18 16:04:22,037 - mmdet - INFO - Epoch [12][11500/18729]	lr: 1.000e-05, eta: 1:07:50, time: 0.541, data_time: 0.031, memory: 12528, loss_rpn_cls: 0.0176, loss_rpn_bbox: 0.0732, s0.loss_cls: 0.0597, s0.acc: 97.6953, s0.loss_bbox: 0.0477, s0.loss_mask: 0.4825, s1.loss_cls: 0.0272, s1.acc: 97.8368, s1.loss_bbox: 0.0233, s1.loss_mask: 0.2445, s2.loss_cls: 0.0160, s2.acc: 97.5328, s2.loss_bbox: 0.0099, s2.loss_mask: 0.1190, loss: 1.1205
2022-08-18 16:04:50,041 - mmdet - INFO - Epoch [12][11550/18729]	lr: 1.000e-05, eta: 1:07:21, time: 0.560, data_time: 0.030, memory: 12528, loss_rpn_cls: 0.0277, loss_rpn_bbox: 0.1100, s0.loss_cls: 0.0750, s0.acc: 97.0391, s0.loss_bbox: 0.0595, s0.loss_mask: 0.4708, s1.loss_cls: 0.0335, s1.acc: 97.4534, s1.loss_bbox: 0.0275, s1.loss_mask: 0.2397, s2.loss_cls: 0.0195, s2.acc: 96.9225, s2.loss_bbox: 0.0119, s2.loss_mask: 0.1158, loss: 1.1909
2022-08-18 16:05:17,621 - mmdet - INFO - Epoch [12][11600/18729]	lr: 1.000e-05, eta: 1:06:53, time: 0.552, data_time: 0.024, memory: 12528, loss_rpn_cls: 0.0239, loss_rpn_bbox: 0.0866, s0.loss_cls: 0.0707, s0.acc: 97.1250, s0.loss_bbox: 0.0531, s0.loss_mask: 0.4718, s1.loss_cls: 0.0340, s1.acc: 97.2012, s1.loss_bbox: 0.0263, s1.loss_mask: 0.2394, s2.loss_cls: 0.0180, s2.acc: 97.0841, s2.loss_bbox: 0.0111, s2.loss_mask: 0.1170, loss: 1.1520
2022-08-18 16:05:45,322 - mmdet - INFO - Epoch [12][11650/18729]	lr: 1.000e-05, eta: 1:06:25, time: 0.554, data_time: 0.033, memory: 12528, loss_rpn_cls: 0.0154, loss_rpn_bbox: 0.0793, s0.loss_cls: 0.0491, s0.acc: 98.1914, s0.loss_bbox: 0.0456, s0.loss_mask: 0.4363, s1.loss_cls: 0.0227, s1.acc: 98.3520, s1.loss_bbox: 0.0211, s1.loss_mask: 0.2268, s2.loss_cls: 0.0126, s2.acc: 98.2591, s2.loss_bbox: 0.0094, s2.loss_mask: 0.1125, loss: 1.0309
2022-08-18 16:06:12,518 - mmdet - INFO - Epoch [12][11700/18729]	lr: 1.000e-05, eta: 1:05:56, time: 0.544, data_time: 0.024, memory: 12528, loss_rpn_cls: 0.0405, loss_rpn_bbox: 0.0895, s0.loss_cls: 0.0798, s0.acc: 97.0352, s0.loss_bbox: 0.0534, s0.loss_mask: 0.4548, s1.loss_cls: 0.0324, s1.acc: 97.6922, s1.loss_bbox: 0.0248, s1.loss_mask: 0.2299, s2.loss_cls: 0.0166, s2.acc: 97.4354, s2.loss_bbox: 0.0110, s2.loss_mask: 0.1114, loss: 1.1442
2022-08-18 16:06:38,600 - mmdet - INFO - Epoch [12][11750/18729]	lr: 1.000e-05, eta: 1:05:26, time: 0.522, data_time: 0.014, memory: 12528, loss_rpn_cls: 0.0147, loss_rpn_bbox: 0.0766, s0.loss_cls: 0.0751, s0.acc: 97.1055, s0.loss_bbox: 0.0553, s0.loss_mask: 0.4575, s1.loss_cls: 0.0317, s1.acc: 97.5870, s1.loss_bbox: 0.0259, s1.loss_mask: 0.2257, s2.loss_cls: 0.0174, s2.acc: 97.2780, s2.loss_bbox: 0.0114, s2.loss_mask: 0.1065, loss: 1.0979
2022-08-18 16:07:05,645 - mmdet - INFO - Epoch [12][11800/18729]	lr: 1.000e-05, eta: 1:04:58, time: 0.541, data_time: 0.025, memory: 12528, loss_rpn_cls: 0.0235, loss_rpn_bbox: 0.0764, s0.loss_cls: 0.0669, s0.acc: 97.3711, s0.loss_bbox: 0.0501, s0.loss_mask: 0.4845, s1.loss_cls: 0.0300, s1.acc: 97.6887, s1.loss_bbox: 0.0249, s1.loss_mask: 0.2463, s2.loss_cls: 0.0164, s2.acc: 97.3984, s2.loss_bbox: 0.0106, s2.loss_mask: 0.1185, loss: 1.1483
2022-08-18 16:07:34,068 - mmdet - INFO - Epoch [12][11850/18729]	lr: 1.000e-05, eta: 1:04:30, time: 0.568, data_time: 0.035, memory: 12528, loss_rpn_cls: 0.0228, loss_rpn_bbox: 0.0908, s0.loss_cls: 0.0741, s0.acc: 97.1953, s0.loss_bbox: 0.0557, s0.loss_mask: 0.4489, s1.loss_cls: 0.0314, s1.acc: 97.7239, s1.loss_bbox: 0.0256, s1.loss_mask: 0.2303, s2.loss_cls: 0.0184, s2.acc: 97.0923, s2.loss_bbox: 0.0111, s2.loss_mask: 0.1119, loss: 1.1208
2022-08-18 16:08:01,984 - mmdet - INFO - Epoch [12][11900/18729]	lr: 1.000e-05, eta: 1:04:01, time: 0.558, data_time: 0.029, memory: 12528, loss_rpn_cls: 0.0295, loss_rpn_bbox: 0.0835, s0.loss_cls: 0.0738, s0.acc: 97.0430, s0.loss_bbox: 0.0570, s0.loss_mask: 0.4392, s1.loss_cls: 0.0329, s1.acc: 97.6044, s1.loss_bbox: 0.0274, s1.loss_mask: 0.2269, s2.loss_cls: 0.0185, s2.acc: 97.1023, s2.loss_bbox: 0.0117, s2.loss_mask: 0.1103, loss: 1.1107
2022-08-18 16:08:30,496 - mmdet - INFO - Epoch [12][11950/18729]	lr: 1.000e-05, eta: 1:03:34, time: 0.570, data_time: 0.029, memory: 12528, loss_rpn_cls: 0.0204, loss_rpn_bbox: 0.1115, s0.loss_cls: 0.0800, s0.acc: 96.7852, s0.loss_bbox: 0.0613, s0.loss_mask: 0.4506, s1.loss_cls: 0.0340, s1.acc: 97.2947, s1.loss_bbox: 0.0291, s1.loss_mask: 0.2319, s2.loss_cls: 0.0174, s2.acc: 97.1892, s2.loss_bbox: 0.0129, s2.loss_mask: 0.1134, loss: 1.1625
2022-08-18 16:08:59,520 - mmdet - INFO - Epoch [12][12000/18729]	lr: 1.000e-05, eta: 1:03:06, time: 0.580, data_time: 0.041, memory: 12528, loss_rpn_cls: 0.0170, loss_rpn_bbox: 0.0766, s0.loss_cls: 0.0675, s0.acc: 97.3672, s0.loss_bbox: 0.0486, s0.loss_mask: 0.5367, s1.loss_cls: 0.0277, s1.acc: 97.8937, s1.loss_bbox: 0.0228, s1.loss_mask: 0.2749, s2.loss_cls: 0.0147, s2.acc: 97.6535, s2.loss_bbox: 0.0096, s2.loss_mask: 0.1346, loss: 1.2306
2022-08-18 16:09:25,724 - mmdet - INFO - Epoch [12][12050/18729]	lr: 1.000e-05, eta: 1:02:37, time: 0.524, data_time: 0.017, memory: 12528, loss_rpn_cls: 0.0138, loss_rpn_bbox: 0.0755, s0.loss_cls: 0.0667, s0.acc: 97.3242, s0.loss_bbox: 0.0458, s0.loss_mask: 0.4616, s1.loss_cls: 0.0282, s1.acc: 97.7947, s1.loss_bbox: 0.0218, s1.loss_mask: 0.2338, s2.loss_cls: 0.0151, s2.acc: 97.5284, s2.loss_bbox: 0.0097, s2.loss_mask: 0.1132, loss: 1.0852
2022-08-18 16:09:52,028 - mmdet - INFO - Epoch [12][12100/18729]	lr: 1.000e-05, eta: 1:02:08, time: 0.526, data_time: 0.015, memory: 12528, loss_rpn_cls: 0.0185, loss_rpn_bbox: 0.0877, s0.loss_cls: 0.0707, s0.acc: 97.2539, s0.loss_bbox: 0.0563, s0.loss_mask: 0.4718, s1.loss_cls: 0.0279, s1.acc: 97.7848, s1.loss_bbox: 0.0262, s1.loss_mask: 0.2390, s2.loss_cls: 0.0145, s2.acc: 97.7315, s2.loss_bbox: 0.0114, s2.loss_mask: 0.1161, loss: 1.1402
2022-08-18 16:10:19,772 - mmdet - INFO - Epoch [12][12150/18729]	lr: 1.000e-05, eta: 1:01:39, time: 0.555, data_time: 0.021, memory: 12528, loss_rpn_cls: 0.0156, loss_rpn_bbox: 0.0607, s0.loss_cls: 0.0648, s0.acc: 97.6172, s0.loss_bbox: 0.0503, s0.loss_mask: 0.4704, s1.loss_cls: 0.0261, s1.acc: 97.9787, s1.loss_bbox: 0.0246, s1.loss_mask: 0.2430, s2.loss_cls: 0.0145, s2.acc: 97.8165, s2.loss_bbox: 0.0114, s2.loss_mask: 0.1193, loss: 1.1006
2022-08-18 16:10:48,307 - mmdet - INFO - Epoch [12][12200/18729]	lr: 1.000e-05, eta: 1:01:11, time: 0.571, data_time: 0.042, memory: 12528, loss_rpn_cls: 0.0192, loss_rpn_bbox: 0.0655, s0.loss_cls: 0.0590, s0.acc: 97.7031, s0.loss_bbox: 0.0495, s0.loss_mask: 0.5109, s1.loss_cls: 0.0256, s1.acc: 98.1004, s1.loss_bbox: 0.0253, s1.loss_mask: 0.2681, s2.loss_cls: 0.0145, s2.acc: 97.8088, s2.loss_bbox: 0.0111, s2.loss_mask: 0.1305, loss: 1.1792
2022-08-18 16:11:16,284 - mmdet - INFO - Epoch [12][12250/18729]	lr: 1.000e-05, eta: 1:00:43, time: 0.560, data_time: 0.023, memory: 12528, loss_rpn_cls: 0.0169, loss_rpn_bbox: 0.0887, s0.loss_cls: 0.0741, s0.acc: 97.0508, s0.loss_bbox: 0.0624, s0.loss_mask: 0.4803, s1.loss_cls: 0.0321, s1.acc: 97.5828, s1.loss_bbox: 0.0302, s1.loss_mask: 0.2479, s2.loss_cls: 0.0180, s2.acc: 97.1264, s2.loss_bbox: 0.0134, s2.loss_mask: 0.1201, loss: 1.1841
2022-08-18 16:11:44,234 - mmdet - INFO - Epoch [12][12300/18729]	lr: 1.000e-05, eta: 1:00:15, time: 0.559, data_time: 0.035, memory: 12528, loss_rpn_cls: 0.0241, loss_rpn_bbox: 0.0815, s0.loss_cls: 0.0773, s0.acc: 97.2031, s0.loss_bbox: 0.0559, s0.loss_mask: 0.4621, s1.loss_cls: 0.0319, s1.acc: 97.7397, s1.loss_bbox: 0.0275, s1.loss_mask: 0.2368, s2.loss_cls: 0.0173, s2.acc: 97.2341, s2.loss_bbox: 0.0115, s2.loss_mask: 0.1140, loss: 1.1400
2022-08-18 16:12:12,151 - mmdet - INFO - Epoch [12][12350/18729]	lr: 1.000e-05, eta: 0:59:47, time: 0.558, data_time: 0.016, memory: 12528, loss_rpn_cls: 0.0129, loss_rpn_bbox: 0.0934, s0.loss_cls: 0.0886, s0.acc: 96.6211, s0.loss_bbox: 0.0641, s0.loss_mask: 0.3992, s1.loss_cls: 0.0350, s1.acc: 97.3608, s1.loss_bbox: 0.0309, s1.loss_mask: 0.2036, s2.loss_cls: 0.0199, s2.acc: 96.8499, s2.loss_bbox: 0.0144, s2.loss_mask: 0.0980, loss: 1.0602
2022-08-18 16:12:39,282 - mmdet - INFO - Epoch [12][12400/18729]	lr: 1.000e-05, eta: 0:59:18, time: 0.543, data_time: 0.015, memory: 12528, loss_rpn_cls: 0.0212, loss_rpn_bbox: 0.0795, s0.loss_cls: 0.0732, s0.acc: 97.1758, s0.loss_bbox: 0.0572, s0.loss_mask: 0.4145, s1.loss_cls: 0.0318, s1.acc: 97.6255, s1.loss_bbox: 0.0280, s1.loss_mask: 0.2071, s2.loss_cls: 0.0168, s2.acc: 97.4164, s2.loss_bbox: 0.0123, s2.loss_mask: 0.1022, loss: 1.0436
2022-08-18 16:13:09,135 - mmdet - INFO - Epoch [12][12450/18729]	lr: 1.000e-05, eta: 0:58:51, time: 0.597, data_time: 0.048, memory: 12528, loss_rpn_cls: 0.0202, loss_rpn_bbox: 0.0898, s0.loss_cls: 0.0722, s0.acc: 97.3438, s0.loss_bbox: 0.0583, s0.loss_mask: 0.4525, s1.loss_cls: 0.0312, s1.acc: 97.9737, s1.loss_bbox: 0.0279, s1.loss_mask: 0.2309, s2.loss_cls: 0.0175, s2.acc: 97.3394, s2.loss_bbox: 0.0121, s2.loss_mask: 0.1095, loss: 1.1221
2022-08-18 16:13:37,230 - mmdet - INFO - Epoch [12][12500/18729]	lr: 1.000e-05, eta: 0:58:23, time: 0.562, data_time: 0.029, memory: 12528, loss_rpn_cls: 0.0163, loss_rpn_bbox: 0.0862, s0.loss_cls: 0.0668, s0.acc: 97.3867, s0.loss_bbox: 0.0557, s0.loss_mask: 0.4357, s1.loss_cls: 0.0274, s1.acc: 98.0563, s1.loss_bbox: 0.0270, s1.loss_mask: 0.2209, s2.loss_cls: 0.0152, s2.acc: 97.5504, s2.loss_bbox: 0.0122, s2.loss_mask: 0.1090, loss: 1.0724
2022-08-18 16:14:04,072 - mmdet - INFO - Epoch [12][12550/18729]	lr: 1.000e-05, eta: 0:57:54, time: 0.537, data_time: 0.020, memory: 12528, loss_rpn_cls: 0.0211, loss_rpn_bbox: 0.1077, s0.loss_cls: 0.0663, s0.acc: 97.4492, s0.loss_bbox: 0.0544, s0.loss_mask: 0.4725, s1.loss_cls: 0.0267, s1.acc: 97.8958, s1.loss_bbox: 0.0254, s1.loss_mask: 0.2433, s2.loss_cls: 0.0161, s2.acc: 97.4066, s2.loss_bbox: 0.0107, s2.loss_mask: 0.1178, loss: 1.1620
2022-08-18 16:14:36,221 - mmdet - INFO - Epoch [12][12600/18729]	lr: 1.000e-05, eta: 0:57:28, time: 0.643, data_time: 0.090, memory: 12528, loss_rpn_cls: 0.0237, loss_rpn_bbox: 0.1035, s0.loss_cls: 0.0725, s0.acc: 97.1211, s0.loss_bbox: 0.0596, s0.loss_mask: 0.4901, s1.loss_cls: 0.0318, s1.acc: 97.6055, s1.loss_bbox: 0.0265, s1.loss_mask: 0.2419, s2.loss_cls: 0.0165, s2.acc: 97.5674, s2.loss_bbox: 0.0109, s2.loss_mask: 0.1146, loss: 1.1914
2022-08-18 16:15:04,505 - mmdet - INFO - Epoch [12][12650/18729]	lr: 1.000e-05, eta: 0:57:00, time: 0.566, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0185, loss_rpn_bbox: 0.0753, s0.loss_cls: 0.0729, s0.acc: 97.1680, s0.loss_bbox: 0.0554, s0.loss_mask: 0.4687, s1.loss_cls: 0.0324, s1.acc: 97.4712, s1.loss_bbox: 0.0272, s1.loss_mask: 0.2426, s2.loss_cls: 0.0167, s2.acc: 97.2795, s2.loss_bbox: 0.0122, s2.loss_mask: 0.1205, loss: 1.1425
2022-08-18 16:15:33,286 - mmdet - INFO - Epoch [12][12700/18729]	lr: 1.000e-05, eta: 0:56:32, time: 0.576, data_time: 0.047, memory: 12528, loss_rpn_cls: 0.0221, loss_rpn_bbox: 0.0954, s0.loss_cls: 0.0801, s0.acc: 96.9102, s0.loss_bbox: 0.0521, s0.loss_mask: 0.4770, s1.loss_cls: 0.0329, s1.acc: 97.4240, s1.loss_bbox: 0.0240, s1.loss_mask: 0.2451, s2.loss_cls: 0.0179, s2.acc: 97.1106, s2.loss_bbox: 0.0102, s2.loss_mask: 0.1215, loss: 1.1782
2022-08-18 16:16:02,711 - mmdet - INFO - Epoch [12][12750/18729]	lr: 1.000e-05, eta: 0:56:04, time: 0.588, data_time: 0.052, memory: 12528, loss_rpn_cls: 0.0218, loss_rpn_bbox: 0.0827, s0.loss_cls: 0.0774, s0.acc: 97.0469, s0.loss_bbox: 0.0519, s0.loss_mask: 0.4280, s1.loss_cls: 0.0345, s1.acc: 97.4144, s1.loss_bbox: 0.0260, s1.loss_mask: 0.2127, s2.loss_cls: 0.0197, s2.acc: 97.0675, s2.loss_bbox: 0.0114, s2.loss_mask: 0.1052, loss: 1.0712
2022-08-18 16:16:30,941 - mmdet - INFO - Epoch [12][12800/18729]	lr: 1.000e-05, eta: 0:55:36, time: 0.565, data_time: 0.025, memory: 12528, loss_rpn_cls: 0.0188, loss_rpn_bbox: 0.0945, s0.loss_cls: 0.0751, s0.acc: 97.0586, s0.loss_bbox: 0.0631, s0.loss_mask: 0.4204, s1.loss_cls: 0.0317, s1.acc: 97.4226, s1.loss_bbox: 0.0311, s1.loss_mask: 0.2191, s2.loss_cls: 0.0179, s2.acc: 97.3602, s2.loss_bbox: 0.0136, s2.loss_mask: 0.1056, loss: 1.0909
2022-08-18 16:16:59,793 - mmdet - INFO - Epoch [12][12850/18729]	lr: 1.000e-05, eta: 0:55:09, time: 0.577, data_time: 0.034, memory: 12528, loss_rpn_cls: 0.0263, loss_rpn_bbox: 0.0862, s0.loss_cls: 0.0665, s0.acc: 97.3008, s0.loss_bbox: 0.0541, s0.loss_mask: 0.4421, s1.loss_cls: 0.0295, s1.acc: 97.7587, s1.loss_bbox: 0.0267, s1.loss_mask: 0.2334, s2.loss_cls: 0.0170, s2.acc: 97.3121, s2.loss_bbox: 0.0112, s2.loss_mask: 0.1166, loss: 1.1096
2022-08-18 16:17:28,060 - mmdet - INFO - Epoch [12][12900/18729]	lr: 1.000e-05, eta: 0:54:40, time: 0.565, data_time: 0.033, memory: 12528, loss_rpn_cls: 0.0261, loss_rpn_bbox: 0.0885, s0.loss_cls: 0.0676, s0.acc: 97.2891, s0.loss_bbox: 0.0531, s0.loss_mask: 0.4325, s1.loss_cls: 0.0292, s1.acc: 97.6438, s1.loss_bbox: 0.0248, s1.loss_mask: 0.2216, s2.loss_cls: 0.0161, s2.acc: 97.5806, s2.loss_bbox: 0.0108, s2.loss_mask: 0.1094, loss: 1.0797
2022-08-18 16:17:56,959 - mmdet - INFO - Epoch [12][12950/18729]	lr: 1.000e-05, eta: 0:54:13, time: 0.578, data_time: 0.039, memory: 12528, loss_rpn_cls: 0.0228, loss_rpn_bbox: 0.0883, s0.loss_cls: 0.0774, s0.acc: 97.0664, s0.loss_bbox: 0.0607, s0.loss_mask: 0.4337, s1.loss_cls: 0.0349, s1.acc: 97.5975, s1.loss_bbox: 0.0293, s1.loss_mask: 0.2251, s2.loss_cls: 0.0188, s2.acc: 97.0159, s2.loss_bbox: 0.0132, s2.loss_mask: 0.1112, loss: 1.1155
2022-08-18 16:18:23,434 - mmdet - INFO - Epoch [12][13000/18729]	lr: 1.000e-05, eta: 0:53:44, time: 0.530, data_time: 0.013, memory: 12528, loss_rpn_cls: 0.0269, loss_rpn_bbox: 0.0752, s0.loss_cls: 0.0669, s0.acc: 97.4492, s0.loss_bbox: 0.0547, s0.loss_mask: 0.4807, s1.loss_cls: 0.0260, s1.acc: 98.0227, s1.loss_bbox: 0.0278, s1.loss_mask: 0.2462, s2.loss_cls: 0.0135, s2.acc: 98.0094, s2.loss_bbox: 0.0124, s2.loss_mask: 0.1176, loss: 1.1480
2022-08-18 16:18:51,072 - mmdet - INFO - Epoch [12][13050/18729]	lr: 1.000e-05, eta: 0:53:15, time: 0.553, data_time: 0.024, memory: 12528, loss_rpn_cls: 0.0149, loss_rpn_bbox: 0.0759, s0.loss_cls: 0.0802, s0.acc: 96.9805, s0.loss_bbox: 0.0544, s0.loss_mask: 0.4759, s1.loss_cls: 0.0338, s1.acc: 97.5319, s1.loss_bbox: 0.0263, s1.loss_mask: 0.2422, s2.loss_cls: 0.0183, s2.acc: 97.3285, s2.loss_bbox: 0.0118, s2.loss_mask: 0.1167, loss: 1.1504
2022-08-18 16:19:19,098 - mmdet - INFO - Epoch [12][13100/18729]	lr: 1.000e-05, eta: 0:52:47, time: 0.561, data_time: 0.034, memory: 12528, loss_rpn_cls: 0.0233, loss_rpn_bbox: 0.1082, s0.loss_cls: 0.0848, s0.acc: 96.9219, s0.loss_bbox: 0.0580, s0.loss_mask: 0.4900, s1.loss_cls: 0.0391, s1.acc: 97.2267, s1.loss_bbox: 0.0273, s1.loss_mask: 0.2402, s2.loss_cls: 0.0209, s2.acc: 97.1057, s2.loss_bbox: 0.0117, s2.loss_mask: 0.1166, loss: 1.2201
2022-08-18 16:19:50,713 - mmdet - INFO - Epoch [12][13150/18729]	lr: 1.000e-05, eta: 0:52:21, time: 0.632, data_time: 0.087, memory: 12528, loss_rpn_cls: 0.0216, loss_rpn_bbox: 0.0702, s0.loss_cls: 0.0639, s0.acc: 97.5234, s0.loss_bbox: 0.0470, s0.loss_mask: 0.4771, s1.loss_cls: 0.0280, s1.acc: 98.0317, s1.loss_bbox: 0.0227, s1.loss_mask: 0.2440, s2.loss_cls: 0.0143, s2.acc: 97.7652, s2.loss_bbox: 0.0100, s2.loss_mask: 0.1188, loss: 1.1176
2022-08-18 16:20:20,147 - mmdet - INFO - Epoch [12][13200/18729]	lr: 1.000e-05, eta: 0:51:53, time: 0.589, data_time: 0.040, memory: 12528, loss_rpn_cls: 0.0222, loss_rpn_bbox: 0.0984, s0.loss_cls: 0.0701, s0.acc: 97.3125, s0.loss_bbox: 0.0559, s0.loss_mask: 0.4567, s1.loss_cls: 0.0334, s1.acc: 97.5227, s1.loss_bbox: 0.0259, s1.loss_mask: 0.2338, s2.loss_cls: 0.0171, s2.acc: 97.3558, s2.loss_bbox: 0.0111, s2.loss_mask: 0.1152, loss: 1.1399
2022-08-18 16:20:47,926 - mmdet - INFO - Epoch [12][13250/18729]	lr: 1.000e-05, eta: 0:51:25, time: 0.556, data_time: 0.023, memory: 12528, loss_rpn_cls: 0.0191, loss_rpn_bbox: 0.1000, s0.loss_cls: 0.0868, s0.acc: 96.8438, s0.loss_bbox: 0.0611, s0.loss_mask: 0.4592, s1.loss_cls: 0.0372, s1.acc: 97.3940, s1.loss_bbox: 0.0288, s1.loss_mask: 0.2367, s2.loss_cls: 0.0204, s2.acc: 96.9671, s2.loss_bbox: 0.0124, s2.loss_mask: 0.1154, loss: 1.1771
2022-08-18 16:21:18,794 - mmdet - INFO - Epoch [12][13300/18729]	lr: 1.000e-05, eta: 0:50:58, time: 0.617, data_time: 0.057, memory: 12528, loss_rpn_cls: 0.0265, loss_rpn_bbox: 0.1063, s0.loss_cls: 0.0787, s0.acc: 97.1172, s0.loss_bbox: 0.0588, s0.loss_mask: 0.5015, s1.loss_cls: 0.0339, s1.acc: 97.5825, s1.loss_bbox: 0.0267, s1.loss_mask: 0.2555, s2.loss_cls: 0.0181, s2.acc: 97.2349, s2.loss_bbox: 0.0115, s2.loss_mask: 0.1233, loss: 1.2407
2022-08-18 16:21:49,039 - mmdet - INFO - Epoch [12][13350/18729]	lr: 1.000e-05, eta: 0:50:30, time: 0.605, data_time: 0.046, memory: 12528, loss_rpn_cls: 0.0288, loss_rpn_bbox: 0.1190, s0.loss_cls: 0.0835, s0.acc: 96.6094, s0.loss_bbox: 0.0643, s0.loss_mask: 0.5076, s1.loss_cls: 0.0368, s1.acc: 97.2265, s1.loss_bbox: 0.0293, s1.loss_mask: 0.2562, s2.loss_cls: 0.0200, s2.acc: 97.1020, s2.loss_bbox: 0.0125, s2.loss_mask: 0.1210, loss: 1.2790
2022-08-18 16:22:14,995 - mmdet - INFO - Epoch [12][13400/18729]	lr: 1.000e-05, eta: 0:50:01, time: 0.519, data_time: 0.012, memory: 12528, loss_rpn_cls: 0.0154, loss_rpn_bbox: 0.0734, s0.loss_cls: 0.0676, s0.acc: 97.2734, s0.loss_bbox: 0.0522, s0.loss_mask: 0.4161, s1.loss_cls: 0.0317, s1.acc: 97.5425, s1.loss_bbox: 0.0261, s1.loss_mask: 0.2143, s2.loss_cls: 0.0176, s2.acc: 97.1271, s2.loss_bbox: 0.0115, s2.loss_mask: 0.1052, loss: 1.0313
2022-08-18 16:22:43,021 - mmdet - INFO - Epoch [12][13450/18729]	lr: 1.000e-05, eta: 0:49:33, time: 0.561, data_time: 0.026, memory: 12528, loss_rpn_cls: 0.0215, loss_rpn_bbox: 0.1102, s0.loss_cls: 0.0804, s0.acc: 96.8867, s0.loss_bbox: 0.0583, s0.loss_mask: 0.4530, s1.loss_cls: 0.0359, s1.acc: 97.2209, s1.loss_bbox: 0.0267, s1.loss_mask: 0.2244, s2.loss_cls: 0.0189, s2.acc: 96.9956, s2.loss_bbox: 0.0113, s2.loss_mask: 0.1076, loss: 1.1482
2022-08-18 16:23:10,111 - mmdet - INFO - Epoch [12][13500/18729]	lr: 1.000e-05, eta: 0:49:04, time: 0.542, data_time: 0.024, memory: 12528, loss_rpn_cls: 0.0211, loss_rpn_bbox: 0.0704, s0.loss_cls: 0.0720, s0.acc: 97.2266, s0.loss_bbox: 0.0522, s0.loss_mask: 0.4624, s1.loss_cls: 0.0321, s1.acc: 98.0114, s1.loss_bbox: 0.0252, s1.loss_mask: 0.2352, s2.loss_cls: 0.0182, s2.acc: 97.3481, s2.loss_bbox: 0.0114, s2.loss_mask: 0.1138, loss: 1.1141
2022-08-18 16:23:36,262 - mmdet - INFO - Epoch [12][13550/18729]	lr: 1.000e-05, eta: 0:48:35, time: 0.523, data_time: 0.014, memory: 12528, loss_rpn_cls: 0.0239, loss_rpn_bbox: 0.0854, s0.loss_cls: 0.0744, s0.acc: 97.1328, s0.loss_bbox: 0.0531, s0.loss_mask: 0.4295, s1.loss_cls: 0.0333, s1.acc: 97.4370, s1.loss_bbox: 0.0249, s1.loss_mask: 0.2178, s2.loss_cls: 0.0182, s2.acc: 97.0354, s2.loss_bbox: 0.0110, s2.loss_mask: 0.1067, loss: 1.0783
2022-08-18 16:24:04,851 - mmdet - INFO - Epoch [12][13600/18729]	lr: 1.000e-05, eta: 0:48:07, time: 0.572, data_time: 0.030, memory: 12528, loss_rpn_cls: 0.0219, loss_rpn_bbox: 0.0889, s0.loss_cls: 0.0731, s0.acc: 97.3125, s0.loss_bbox: 0.0549, s0.loss_mask: 0.4700, s1.loss_cls: 0.0298, s1.acc: 97.9215, s1.loss_bbox: 0.0266, s1.loss_mask: 0.2471, s2.loss_cls: 0.0173, s2.acc: 97.4407, s2.loss_bbox: 0.0114, s2.loss_mask: 0.1185, loss: 1.1595
2022-08-18 16:24:32,154 - mmdet - INFO - Epoch [12][13650/18729]	lr: 1.000e-05, eta: 0:47:39, time: 0.546, data_time: 0.014, memory: 12528, loss_rpn_cls: 0.0212, loss_rpn_bbox: 0.0890, s0.loss_cls: 0.0825, s0.acc: 96.8398, s0.loss_bbox: 0.0614, s0.loss_mask: 0.3918, s1.loss_cls: 0.0330, s1.acc: 97.3404, s1.loss_bbox: 0.0300, s1.loss_mask: 0.2041, s2.loss_cls: 0.0193, s2.acc: 96.7302, s2.loss_bbox: 0.0129, s2.loss_mask: 0.0991, loss: 1.0443
2022-08-18 16:24:59,509 - mmdet - INFO - Epoch [12][13700/18729]	lr: 1.000e-05, eta: 0:47:11, time: 0.547, data_time: 0.019, memory: 12528, loss_rpn_cls: 0.0230, loss_rpn_bbox: 0.0837, s0.loss_cls: 0.0684, s0.acc: 97.3320, s0.loss_bbox: 0.0525, s0.loss_mask: 0.4411, s1.loss_cls: 0.0270, s1.acc: 97.9314, s1.loss_bbox: 0.0249, s1.loss_mask: 0.2200, s2.loss_cls: 0.0133, s2.acc: 98.0419, s2.loss_bbox: 0.0107, s2.loss_mask: 0.1070, loss: 1.0717
2022-08-18 16:25:25,833 - mmdet - INFO - Epoch [12][13750/18729]	lr: 1.000e-05, eta: 0:46:42, time: 0.526, data_time: 0.013, memory: 12528, loss_rpn_cls: 0.0275, loss_rpn_bbox: 0.1008, s0.loss_cls: 0.0721, s0.acc: 97.2383, s0.loss_bbox: 0.0581, s0.loss_mask: 0.5003, s1.loss_cls: 0.0327, s1.acc: 97.4705, s1.loss_bbox: 0.0278, s1.loss_mask: 0.2484, s2.loss_cls: 0.0181, s2.acc: 97.1857, s2.loss_bbox: 0.0120, s2.loss_mask: 0.1190, loss: 1.2169
2022-08-18 16:25:54,349 - mmdet - INFO - Epoch [12][13800/18729]	lr: 1.000e-05, eta: 0:46:14, time: 0.570, data_time: 0.033, memory: 12528, loss_rpn_cls: 0.0217, loss_rpn_bbox: 0.0841, s0.loss_cls: 0.0727, s0.acc: 97.0703, s0.loss_bbox: 0.0524, s0.loss_mask: 0.4598, s1.loss_cls: 0.0309, s1.acc: 97.5926, s1.loss_bbox: 0.0239, s1.loss_mask: 0.2341, s2.loss_cls: 0.0165, s2.acc: 97.5206, s2.loss_bbox: 0.0104, s2.loss_mask: 0.1148, loss: 1.1212
2022-08-18 16:26:22,491 - mmdet - INFO - Epoch [12][13850/18729]	lr: 1.000e-05, eta: 0:45:46, time: 0.563, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0208, loss_rpn_bbox: 0.0888, s0.loss_cls: 0.0818, s0.acc: 96.9766, s0.loss_bbox: 0.0559, s0.loss_mask: 0.4449, s1.loss_cls: 0.0354, s1.acc: 97.3511, s1.loss_bbox: 0.0273, s1.loss_mask: 0.2240, s2.loss_cls: 0.0193, s2.acc: 97.0131, s2.loss_bbox: 0.0120, s2.loss_mask: 0.1089, loss: 1.1190
2022-08-18 16:26:51,468 - mmdet - INFO - Epoch [12][13900/18729]	lr: 1.000e-05, eta: 0:45:18, time: 0.580, data_time: 0.041, memory: 12528, loss_rpn_cls: 0.0167, loss_rpn_bbox: 0.0823, s0.loss_cls: 0.0754, s0.acc: 97.0586, s0.loss_bbox: 0.0476, s0.loss_mask: 0.4406, s1.loss_cls: 0.0320, s1.acc: 97.5744, s1.loss_bbox: 0.0224, s1.loss_mask: 0.2235, s2.loss_cls: 0.0188, s2.acc: 97.1749, s2.loss_bbox: 0.0097, s2.loss_mask: 0.1087, loss: 1.0777
2022-08-18 16:27:19,120 - mmdet - INFO - Epoch [12][13950/18729]	lr: 1.000e-05, eta: 0:44:49, time: 0.553, data_time: 0.035, memory: 12528, loss_rpn_cls: 0.0211, loss_rpn_bbox: 0.0814, s0.loss_cls: 0.0647, s0.acc: 97.4492, s0.loss_bbox: 0.0453, s0.loss_mask: 0.4883, s1.loss_cls: 0.0290, s1.acc: 97.7582, s1.loss_bbox: 0.0219, s1.loss_mask: 0.2443, s2.loss_cls: 0.0150, s2.acc: 97.8025, s2.loss_bbox: 0.0094, s2.loss_mask: 0.1168, loss: 1.1372
2022-08-18 16:27:46,242 - mmdet - INFO - Epoch [12][14000/18729]	lr: 1.000e-05, eta: 0:44:21, time: 0.542, data_time: 0.016, memory: 12528, loss_rpn_cls: 0.0274, loss_rpn_bbox: 0.0829, s0.loss_cls: 0.0804, s0.acc: 96.8867, s0.loss_bbox: 0.0552, s0.loss_mask: 0.4546, s1.loss_cls: 0.0340, s1.acc: 97.4963, s1.loss_bbox: 0.0272, s1.loss_mask: 0.2357, s2.loss_cls: 0.0191, s2.acc: 97.1839, s2.loss_bbox: 0.0118, s2.loss_mask: 0.1136, loss: 1.1420
2022-08-18 16:28:15,473 - mmdet - INFO - Epoch [12][14050/18729]	lr: 1.000e-05, eta: 0:43:53, time: 0.585, data_time: 0.046, memory: 12528, loss_rpn_cls: 0.0248, loss_rpn_bbox: 0.0693, s0.loss_cls: 0.0687, s0.acc: 97.3164, s0.loss_bbox: 0.0434, s0.loss_mask: 0.4953, s1.loss_cls: 0.0310, s1.acc: 97.6828, s1.loss_bbox: 0.0220, s1.loss_mask: 0.2502, s2.loss_cls: 0.0179, s2.acc: 97.1836, s2.loss_bbox: 0.0094, s2.loss_mask: 0.1232, loss: 1.1552
2022-08-18 16:28:41,851 - mmdet - INFO - Epoch [12][14100/18729]	lr: 1.000e-05, eta: 0:43:24, time: 0.528, data_time: 0.019, memory: 12528, loss_rpn_cls: 0.0230, loss_rpn_bbox: 0.1015, s0.loss_cls: 0.0581, s0.acc: 97.7734, s0.loss_bbox: 0.0504, s0.loss_mask: 0.4133, s1.loss_cls: 0.0242, s1.acc: 98.2447, s1.loss_bbox: 0.0236, s1.loss_mask: 0.2131, s2.loss_cls: 0.0142, s2.acc: 97.8160, s2.loss_bbox: 0.0099, s2.loss_mask: 0.1023, loss: 1.0336
2022-08-18 16:29:09,570 - mmdet - INFO - Epoch [12][14150/18729]	lr: 1.000e-05, eta: 0:42:56, time: 0.554, data_time: 0.026, memory: 12528, loss_rpn_cls: 0.0236, loss_rpn_bbox: 0.1176, s0.loss_cls: 0.0742, s0.acc: 97.2188, s0.loss_bbox: 0.0589, s0.loss_mask: 0.4714, s1.loss_cls: 0.0341, s1.acc: 97.5099, s1.loss_bbox: 0.0271, s1.loss_mask: 0.2372, s2.loss_cls: 0.0187, s2.acc: 97.0378, s2.loss_bbox: 0.0117, s2.loss_mask: 0.1168, loss: 1.1911
2022-08-18 16:29:38,954 - mmdet - INFO - Epoch [12][14200/18729]	lr: 1.000e-05, eta: 0:42:28, time: 0.588, data_time: 0.046, memory: 12528, loss_rpn_cls: 0.0221, loss_rpn_bbox: 0.1027, s0.loss_cls: 0.0853, s0.acc: 96.6641, s0.loss_bbox: 0.0559, s0.loss_mask: 0.4886, s1.loss_cls: 0.0370, s1.acc: 97.0402, s1.loss_bbox: 0.0261, s1.loss_mask: 0.2482, s2.loss_cls: 0.0195, s2.acc: 97.1316, s2.loss_bbox: 0.0110, s2.loss_mask: 0.1219, loss: 1.2185
2022-08-18 16:30:05,786 - mmdet - INFO - Epoch [12][14250/18729]	lr: 1.000e-05, eta: 0:42:00, time: 0.537, data_time: 0.015, memory: 12528, loss_rpn_cls: 0.0171, loss_rpn_bbox: 0.0888, s0.loss_cls: 0.0754, s0.acc: 96.9141, s0.loss_bbox: 0.0578, s0.loss_mask: 0.4442, s1.loss_cls: 0.0326, s1.acc: 97.4352, s1.loss_bbox: 0.0286, s1.loss_mask: 0.2275, s2.loss_cls: 0.0195, s2.acc: 96.7548, s2.loss_bbox: 0.0121, s2.loss_mask: 0.1099, loss: 1.1134
2022-08-18 16:30:31,674 - mmdet - INFO - Epoch [12][14300/18729]	lr: 1.000e-05, eta: 0:41:31, time: 0.518, data_time: 0.016, memory: 12528, loss_rpn_cls: 0.0109, loss_rpn_bbox: 0.0481, s0.loss_cls: 0.0490, s0.acc: 98.2344, s0.loss_bbox: 0.0380, s0.loss_mask: 0.4406, s1.loss_cls: 0.0197, s1.acc: 98.6185, s1.loss_bbox: 0.0182, s1.loss_mask: 0.2270, s2.loss_cls: 0.0104, s2.acc: 98.5995, s2.loss_bbox: 0.0086, s2.loss_mask: 0.1105, loss: 0.9809
2022-08-18 16:30:58,306 - mmdet - INFO - Epoch [12][14350/18729]	lr: 1.000e-05, eta: 0:41:02, time: 0.533, data_time: 0.026, memory: 12528, loss_rpn_cls: 0.0276, loss_rpn_bbox: 0.0560, s0.loss_cls: 0.0666, s0.acc: 97.4375, s0.loss_bbox: 0.0419, s0.loss_mask: 0.4888, s1.loss_cls: 0.0287, s1.acc: 97.6707, s1.loss_bbox: 0.0205, s1.loss_mask: 0.2563, s2.loss_cls: 0.0138, s2.acc: 97.8402, s2.loss_bbox: 0.0090, s2.loss_mask: 0.1242, loss: 1.1334
2022-08-18 16:31:29,725 - mmdet - INFO - Epoch [12][14400/18729]	lr: 1.000e-05, eta: 0:40:35, time: 0.628, data_time: 0.067, memory: 12528, loss_rpn_cls: 0.0280, loss_rpn_bbox: 0.1061, s0.loss_cls: 0.0820, s0.acc: 96.8281, s0.loss_bbox: 0.0574, s0.loss_mask: 0.5065, s1.loss_cls: 0.0376, s1.acc: 97.2527, s1.loss_bbox: 0.0265, s1.loss_mask: 0.2606, s2.loss_cls: 0.0187, s2.acc: 97.2624, s2.loss_bbox: 0.0110, s2.loss_mask: 0.1244, loss: 1.2589
2022-08-18 16:31:58,159 - mmdet - INFO - Epoch [12][14450/18729]	lr: 1.000e-05, eta: 0:40:07, time: 0.569, data_time: 0.031, memory: 12528, loss_rpn_cls: 0.0186, loss_rpn_bbox: 0.0934, s0.loss_cls: 0.0697, s0.acc: 97.3047, s0.loss_bbox: 0.0547, s0.loss_mask: 0.4524, s1.loss_cls: 0.0299, s1.acc: 97.7372, s1.loss_bbox: 0.0262, s1.loss_mask: 0.2351, s2.loss_cls: 0.0158, s2.acc: 97.5844, s2.loss_bbox: 0.0116, s2.loss_mask: 0.1150, loss: 1.1225
2022-08-18 16:32:27,544 - mmdet - INFO - Epoch [12][14500/18729]	lr: 1.000e-05, eta: 0:39:40, time: 0.588, data_time: 0.040, memory: 12528, loss_rpn_cls: 0.0211, loss_rpn_bbox: 0.0694, s0.loss_cls: 0.0777, s0.acc: 97.0703, s0.loss_bbox: 0.0590, s0.loss_mask: 0.4353, s1.loss_cls: 0.0350, s1.acc: 97.3884, s1.loss_bbox: 0.0299, s1.loss_mask: 0.2243, s2.loss_cls: 0.0188, s2.acc: 97.0904, s2.loss_bbox: 0.0125, s2.loss_mask: 0.1090, loss: 1.0920
2022-08-18 16:32:55,890 - mmdet - INFO - Epoch [12][14550/18729]	lr: 1.000e-05, eta: 0:39:11, time: 0.567, data_time: 0.023, memory: 12528, loss_rpn_cls: 0.0269, loss_rpn_bbox: 0.1002, s0.loss_cls: 0.0747, s0.acc: 97.0664, s0.loss_bbox: 0.0570, s0.loss_mask: 0.4508, s1.loss_cls: 0.0338, s1.acc: 97.3173, s1.loss_bbox: 0.0272, s1.loss_mask: 0.2308, s2.loss_cls: 0.0189, s2.acc: 97.0064, s2.loss_bbox: 0.0122, s2.loss_mask: 0.1132, loss: 1.1458
2022-08-18 16:33:23,710 - mmdet - INFO - Epoch [12][14600/18729]	lr: 1.000e-05, eta: 0:38:43, time: 0.556, data_time: 0.034, memory: 12528, loss_rpn_cls: 0.0188, loss_rpn_bbox: 0.0898, s0.loss_cls: 0.0772, s0.acc: 96.8750, s0.loss_bbox: 0.0506, s0.loss_mask: 0.4911, s1.loss_cls: 0.0317, s1.acc: 97.5346, s1.loss_bbox: 0.0240, s1.loss_mask: 0.2494, s2.loss_cls: 0.0182, s2.acc: 97.2163, s2.loss_bbox: 0.0099, s2.loss_mask: 0.1230, loss: 1.1839
2022-08-18 16:33:53,104 - mmdet - INFO - Epoch [12][14650/18729]	lr: 1.000e-05, eta: 0:38:15, time: 0.588, data_time: 0.032, memory: 12528, loss_rpn_cls: 0.0259, loss_rpn_bbox: 0.1075, s0.loss_cls: 0.0773, s0.acc: 97.1992, s0.loss_bbox: 0.0630, s0.loss_mask: 0.4723, s1.loss_cls: 0.0336, s1.acc: 97.6218, s1.loss_bbox: 0.0284, s1.loss_mask: 0.2398, s2.loss_cls: 0.0183, s2.acc: 97.0968, s2.loss_bbox: 0.0123, s2.loss_mask: 0.1193, loss: 1.1978
2022-08-18 16:34:20,798 - mmdet - INFO - Epoch [12][14700/18729]	lr: 1.000e-05, eta: 0:37:47, time: 0.554, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0106, loss_rpn_bbox: 0.0661, s0.loss_cls: 0.0627, s0.acc: 97.3789, s0.loss_bbox: 0.0504, s0.loss_mask: 0.4626, s1.loss_cls: 0.0273, s1.acc: 97.6800, s1.loss_bbox: 0.0247, s1.loss_mask: 0.2368, s2.loss_cls: 0.0138, s2.acc: 97.6617, s2.loss_bbox: 0.0112, s2.loss_mask: 0.1147, loss: 1.0810
2022-08-18 16:34:49,995 - mmdet - INFO - Epoch [12][14750/18729]	lr: 1.000e-05, eta: 0:37:19, time: 0.584, data_time: 0.067, memory: 12528, loss_rpn_cls: 0.0203, loss_rpn_bbox: 0.0681, s0.loss_cls: 0.0660, s0.acc: 97.6055, s0.loss_bbox: 0.0433, s0.loss_mask: 0.5097, s1.loss_cls: 0.0319, s1.acc: 97.7340, s1.loss_bbox: 0.0214, s1.loss_mask: 0.2635, s2.loss_cls: 0.0163, s2.acc: 97.6096, s2.loss_bbox: 0.0094, s2.loss_mask: 0.1269, loss: 1.1769
2022-08-18 16:35:18,416 - mmdet - INFO - Epoch [12][14800/18729]	lr: 1.000e-05, eta: 0:36:51, time: 0.568, data_time: 0.034, memory: 12528, loss_rpn_cls: 0.0245, loss_rpn_bbox: 0.1170, s0.loss_cls: 0.0805, s0.acc: 96.9102, s0.loss_bbox: 0.0580, s0.loss_mask: 0.4256, s1.loss_cls: 0.0338, s1.acc: 97.4381, s1.loss_bbox: 0.0269, s1.loss_mask: 0.2171, s2.loss_cls: 0.0185, s2.acc: 97.3112, s2.loss_bbox: 0.0118, s2.loss_mask: 0.1061, loss: 1.1198
2022-08-18 16:35:47,685 - mmdet - INFO - Epoch [12][14850/18729]	lr: 1.000e-05, eta: 0:36:23, time: 0.585, data_time: 0.047, memory: 12528, loss_rpn_cls: 0.0220, loss_rpn_bbox: 0.0897, s0.loss_cls: 0.0632, s0.acc: 97.5117, s0.loss_bbox: 0.0484, s0.loss_mask: 0.4600, s1.loss_cls: 0.0285, s1.acc: 97.8220, s1.loss_bbox: 0.0226, s1.loss_mask: 0.2362, s2.loss_cls: 0.0143, s2.acc: 97.8391, s2.loss_bbox: 0.0097, s2.loss_mask: 0.1150, loss: 1.1097
2022-08-18 16:36:16,339 - mmdet - INFO - Epoch [12][14900/18729]	lr: 1.000e-05, eta: 0:35:55, time: 0.573, data_time: 0.037, memory: 12528, loss_rpn_cls: 0.0244, loss_rpn_bbox: 0.0944, s0.loss_cls: 0.0715, s0.acc: 97.1875, s0.loss_bbox: 0.0525, s0.loss_mask: 0.5128, s1.loss_cls: 0.0323, s1.acc: 97.5877, s1.loss_bbox: 0.0239, s1.loss_mask: 0.2632, s2.loss_cls: 0.0174, s2.acc: 97.4076, s2.loss_bbox: 0.0103, s2.loss_mask: 0.1296, loss: 1.2324
2022-08-18 16:36:43,588 - mmdet - INFO - Epoch [12][14950/18729]	lr: 1.000e-05, eta: 0:35:27, time: 0.545, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0131, loss_rpn_bbox: 0.0654, s0.loss_cls: 0.0548, s0.acc: 97.9375, s0.loss_bbox: 0.0446, s0.loss_mask: 0.4432, s1.loss_cls: 0.0238, s1.acc: 98.1002, s1.loss_bbox: 0.0222, s1.loss_mask: 0.2249, s2.loss_cls: 0.0135, s2.acc: 97.8966, s2.loss_bbox: 0.0099, s2.loss_mask: 0.1094, loss: 1.0247
2022-08-18 16:37:11,388 - mmdet - INFO - Epoch [12][15000/18729]	lr: 1.000e-05, eta: 0:34:59, time: 0.556, data_time: 0.020, memory: 12528, loss_rpn_cls: 0.0165, loss_rpn_bbox: 0.0771, s0.loss_cls: 0.0704, s0.acc: 97.3008, s0.loss_bbox: 0.0633, s0.loss_mask: 0.4669, s1.loss_cls: 0.0291, s1.acc: 97.8895, s1.loss_bbox: 0.0305, s1.loss_mask: 0.2391, s2.loss_cls: 0.0173, s2.acc: 97.3098, s2.loss_bbox: 0.0133, s2.loss_mask: 0.1167, loss: 1.1401
2022-08-18 16:37:40,656 - mmdet - INFO - Epoch [12][15050/18729]	lr: 1.000e-05, eta: 0:34:31, time: 0.585, data_time: 0.041, memory: 12528, loss_rpn_cls: 0.0208, loss_rpn_bbox: 0.0910, s0.loss_cls: 0.0710, s0.acc: 97.2383, s0.loss_bbox: 0.0520, s0.loss_mask: 0.4434, s1.loss_cls: 0.0312, s1.acc: 97.5928, s1.loss_bbox: 0.0247, s1.loss_mask: 0.2217, s2.loss_cls: 0.0162, s2.acc: 97.4652, s2.loss_bbox: 0.0112, s2.loss_mask: 0.1075, loss: 1.0907
2022-08-18 16:38:07,732 - mmdet - INFO - Epoch [12][15100/18729]	lr: 1.000e-05, eta: 0:34:02, time: 0.542, data_time: 0.021, memory: 12528, loss_rpn_cls: 0.0343, loss_rpn_bbox: 0.0926, s0.loss_cls: 0.0723, s0.acc: 97.1484, s0.loss_bbox: 0.0541, s0.loss_mask: 0.4324, s1.loss_cls: 0.0310, s1.acc: 97.6377, s1.loss_bbox: 0.0266, s1.loss_mask: 0.2240, s2.loss_cls: 0.0173, s2.acc: 97.3133, s2.loss_bbox: 0.0117, s2.loss_mask: 0.1075, loss: 1.1038
2022-08-18 16:38:33,783 - mmdet - INFO - Epoch [12][15150/18729]	lr: 1.000e-05, eta: 0:33:34, time: 0.521, data_time: 0.011, memory: 12528, loss_rpn_cls: 0.0140, loss_rpn_bbox: 0.0730, s0.loss_cls: 0.0641, s0.acc: 97.5039, s0.loss_bbox: 0.0546, s0.loss_mask: 0.4144, s1.loss_cls: 0.0269, s1.acc: 98.0588, s1.loss_bbox: 0.0277, s1.loss_mask: 0.2172, s2.loss_cls: 0.0161, s2.acc: 97.3068, s2.loss_bbox: 0.0128, s2.loss_mask: 0.1036, loss: 1.0244
2022-08-18 16:39:00,352 - mmdet - INFO - Epoch [12][15200/18729]	lr: 1.000e-05, eta: 0:33:05, time: 0.531, data_time: 0.021, memory: 12528, loss_rpn_cls: 0.0151, loss_rpn_bbox: 0.0705, s0.loss_cls: 0.0682, s0.acc: 97.2461, s0.loss_bbox: 0.0520, s0.loss_mask: 0.4409, s1.loss_cls: 0.0283, s1.acc: 97.7092, s1.loss_bbox: 0.0249, s1.loss_mask: 0.2286, s2.loss_cls: 0.0165, s2.acc: 97.2571, s2.loss_bbox: 0.0108, s2.loss_mask: 0.1098, loss: 1.0657
2022-08-18 16:39:28,756 - mmdet - INFO - Epoch [12][15250/18729]	lr: 1.000e-05, eta: 0:32:37, time: 0.568, data_time: 0.036, memory: 12528, loss_rpn_cls: 0.0238, loss_rpn_bbox: 0.0998, s0.loss_cls: 0.0830, s0.acc: 96.7383, s0.loss_bbox: 0.0585, s0.loss_mask: 0.4690, s1.loss_cls: 0.0356, s1.acc: 97.4462, s1.loss_bbox: 0.0272, s1.loss_mask: 0.2402, s2.loss_cls: 0.0200, s2.acc: 96.8534, s2.loss_bbox: 0.0118, s2.loss_mask: 0.1176, loss: 1.1864
2022-08-18 16:39:59,287 - mmdet - INFO - Epoch [12][15300/18729]	lr: 1.000e-05, eta: 0:32:10, time: 0.611, data_time: 0.055, memory: 12528, loss_rpn_cls: 0.0229, loss_rpn_bbox: 0.1190, s0.loss_cls: 0.0724, s0.acc: 97.1562, s0.loss_bbox: 0.0579, s0.loss_mask: 0.4814, s1.loss_cls: 0.0325, s1.acc: 97.6879, s1.loss_bbox: 0.0260, s1.loss_mask: 0.2453, s2.loss_cls: 0.0186, s2.acc: 97.1305, s2.loss_bbox: 0.0106, s2.loss_mask: 0.1165, loss: 1.2031
2022-08-18 16:40:28,742 - mmdet - INFO - Epoch [12][15350/18729]	lr: 1.000e-05, eta: 0:31:42, time: 0.589, data_time: 0.040, memory: 12528, loss_rpn_cls: 0.0236, loss_rpn_bbox: 0.0915, s0.loss_cls: 0.0797, s0.acc: 96.9531, s0.loss_bbox: 0.0550, s0.loss_mask: 0.4408, s1.loss_cls: 0.0324, s1.acc: 97.6835, s1.loss_bbox: 0.0256, s1.loss_mask: 0.2226, s2.loss_cls: 0.0169, s2.acc: 97.4078, s2.loss_bbox: 0.0111, s2.loss_mask: 0.1083, loss: 1.1074
2022-08-18 16:40:57,262 - mmdet - INFO - Epoch [12][15400/18729]	lr: 1.000e-05, eta: 0:31:14, time: 0.570, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0190, loss_rpn_bbox: 0.1198, s0.loss_cls: 0.1017, s0.acc: 96.3125, s0.loss_bbox: 0.0651, s0.loss_mask: 0.4651, s1.loss_cls: 0.0466, s1.acc: 96.7621, s1.loss_bbox: 0.0301, s1.loss_mask: 0.2437, s2.loss_cls: 0.0235, s2.acc: 96.6050, s2.loss_bbox: 0.0129, s2.loss_mask: 0.1193, loss: 1.2469
2022-08-18 16:41:23,749 - mmdet - INFO - Epoch [12][15450/18729]	lr: 1.000e-05, eta: 0:30:45, time: 0.530, data_time: 0.016, memory: 12528, loss_rpn_cls: 0.0201, loss_rpn_bbox: 0.0880, s0.loss_cls: 0.0712, s0.acc: 97.1484, s0.loss_bbox: 0.0546, s0.loss_mask: 0.4583, s1.loss_cls: 0.0295, s1.acc: 97.6454, s1.loss_bbox: 0.0265, s1.loss_mask: 0.2329, s2.loss_cls: 0.0161, s2.acc: 97.3004, s2.loss_bbox: 0.0110, s2.loss_mask: 0.1094, loss: 1.1175
2022-08-18 16:41:50,980 - mmdet - INFO - Epoch [12][15500/18729]	lr: 1.000e-05, eta: 0:30:17, time: 0.545, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0132, loss_rpn_bbox: 0.0778, s0.loss_cls: 0.0493, s0.acc: 98.1562, s0.loss_bbox: 0.0454, s0.loss_mask: 0.4219, s1.loss_cls: 0.0207, s1.acc: 98.5256, s1.loss_bbox: 0.0214, s1.loss_mask: 0.2137, s2.loss_cls: 0.0128, s2.acc: 98.2143, s2.loss_bbox: 0.0098, s2.loss_mask: 0.1047, loss: 0.9907
2022-08-18 16:42:26,385 - mmdet - INFO - Epoch [12][15550/18729]	lr: 1.000e-05, eta: 0:29:50, time: 0.708, data_time: 0.155, memory: 12528, loss_rpn_cls: 0.0180, loss_rpn_bbox: 0.0944, s0.loss_cls: 0.0693, s0.acc: 97.2734, s0.loss_bbox: 0.0530, s0.loss_mask: 0.4904, s1.loss_cls: 0.0293, s1.acc: 97.7492, s1.loss_bbox: 0.0259, s1.loss_mask: 0.2501, s2.loss_cls: 0.0163, s2.acc: 97.5375, s2.loss_bbox: 0.0114, s2.loss_mask: 0.1226, loss: 1.1806
2022-08-18 16:42:55,870 - mmdet - INFO - Epoch [12][15600/18729]	lr: 1.000e-05, eta: 0:29:22, time: 0.590, data_time: 0.033, memory: 12528, loss_rpn_cls: 0.0260, loss_rpn_bbox: 0.1147, s0.loss_cls: 0.0853, s0.acc: 96.7461, s0.loss_bbox: 0.0609, s0.loss_mask: 0.4559, s1.loss_cls: 0.0364, s1.acc: 97.2740, s1.loss_bbox: 0.0285, s1.loss_mask: 0.2326, s2.loss_cls: 0.0193, s2.acc: 97.2091, s2.loss_bbox: 0.0120, s2.loss_mask: 0.1125, loss: 1.1842
2022-08-18 16:43:22,781 - mmdet - INFO - Epoch [12][15650/18729]	lr: 1.000e-05, eta: 0:28:54, time: 0.538, data_time: 0.018, memory: 12528, loss_rpn_cls: 0.0255, loss_rpn_bbox: 0.1061, s0.loss_cls: 0.0734, s0.acc: 97.1016, s0.loss_bbox: 0.0571, s0.loss_mask: 0.4587, s1.loss_cls: 0.0301, s1.acc: 97.7531, s1.loss_bbox: 0.0275, s1.loss_mask: 0.2329, s2.loss_cls: 0.0174, s2.acc: 97.3979, s2.loss_bbox: 0.0116, s2.loss_mask: 0.1110, loss: 1.1512
2022-08-18 16:43:49,968 - mmdet - INFO - Epoch [12][15700/18729]	lr: 1.000e-05, eta: 0:28:26, time: 0.544, data_time: 0.023, memory: 12528, loss_rpn_cls: 0.0196, loss_rpn_bbox: 0.0698, s0.loss_cls: 0.0733, s0.acc: 97.3203, s0.loss_bbox: 0.0527, s0.loss_mask: 0.4266, s1.loss_cls: 0.0323, s1.acc: 97.5102, s1.loss_bbox: 0.0262, s1.loss_mask: 0.2136, s2.loss_cls: 0.0162, s2.acc: 97.5347, s2.loss_bbox: 0.0115, s2.loss_mask: 0.1056, loss: 1.0475
2022-08-18 16:44:19,567 - mmdet - INFO - Epoch [12][15750/18729]	lr: 1.000e-05, eta: 0:27:58, time: 0.592, data_time: 0.034, memory: 12528, loss_rpn_cls: 0.0217, loss_rpn_bbox: 0.1124, s0.loss_cls: 0.0887, s0.acc: 96.5859, s0.loss_bbox: 0.0662, s0.loss_mask: 0.4669, s1.loss_cls: 0.0382, s1.acc: 97.1392, s1.loss_bbox: 0.0299, s1.loss_mask: 0.2345, s2.loss_cls: 0.0209, s2.acc: 96.6240, s2.loss_bbox: 0.0130, s2.loss_mask: 0.1122, loss: 1.2046
2022-08-18 16:44:47,935 - mmdet - INFO - Epoch [12][15800/18729]	lr: 1.000e-05, eta: 0:27:30, time: 0.567, data_time: 0.020, memory: 12528, loss_rpn_cls: 0.0184, loss_rpn_bbox: 0.0980, s0.loss_cls: 0.0788, s0.acc: 96.9531, s0.loss_bbox: 0.0620, s0.loss_mask: 0.4428, s1.loss_cls: 0.0325, s1.acc: 97.4988, s1.loss_bbox: 0.0304, s1.loss_mask: 0.2269, s2.loss_cls: 0.0192, s2.acc: 97.0424, s2.loss_bbox: 0.0133, s2.loss_mask: 0.1108, loss: 1.1332
2022-08-18 16:45:14,916 - mmdet - INFO - Epoch [12][15850/18729]	lr: 1.000e-05, eta: 0:27:01, time: 0.540, data_time: 0.024, memory: 12528, loss_rpn_cls: 0.0180, loss_rpn_bbox: 0.0637, s0.loss_cls: 0.0724, s0.acc: 97.1836, s0.loss_bbox: 0.0521, s0.loss_mask: 0.4118, s1.loss_cls: 0.0310, s1.acc: 97.7398, s1.loss_bbox: 0.0254, s1.loss_mask: 0.2163, s2.loss_cls: 0.0166, s2.acc: 97.3080, s2.loss_bbox: 0.0111, s2.loss_mask: 0.1084, loss: 1.0267
2022-08-18 16:45:43,409 - mmdet - INFO - Epoch [12][15900/18729]	lr: 1.000e-05, eta: 0:26:33, time: 0.570, data_time: 0.044, memory: 12528, loss_rpn_cls: 0.0280, loss_rpn_bbox: 0.0870, s0.loss_cls: 0.0753, s0.acc: 97.1172, s0.loss_bbox: 0.0522, s0.loss_mask: 0.4965, s1.loss_cls: 0.0356, s1.acc: 97.3628, s1.loss_bbox: 0.0230, s1.loss_mask: 0.2492, s2.loss_cls: 0.0191, s2.acc: 97.0793, s2.loss_bbox: 0.0093, s2.loss_mask: 0.1202, loss: 1.1954
2022-08-18 16:46:12,650 - mmdet - INFO - Epoch [12][15950/18729]	lr: 1.000e-05, eta: 0:26:05, time: 0.585, data_time: 0.037, memory: 12528, loss_rpn_cls: 0.0260, loss_rpn_bbox: 0.0875, s0.loss_cls: 0.0879, s0.acc: 96.6328, s0.loss_bbox: 0.0617, s0.loss_mask: 0.4427, s1.loss_cls: 0.0400, s1.acc: 96.9986, s1.loss_bbox: 0.0285, s1.loss_mask: 0.2227, s2.loss_cls: 0.0211, s2.acc: 96.7029, s2.loss_bbox: 0.0123, s2.loss_mask: 0.1077, loss: 1.1382
2022-08-18 16:46:39,559 - mmdet - INFO - Epoch [12][16000/18729]	lr: 1.000e-05, eta: 0:25:37, time: 0.538, data_time: 0.015, memory: 12528, loss_rpn_cls: 0.0163, loss_rpn_bbox: 0.0861, s0.loss_cls: 0.0751, s0.acc: 97.0781, s0.loss_bbox: 0.0590, s0.loss_mask: 0.4294, s1.loss_cls: 0.0328, s1.acc: 97.4222, s1.loss_bbox: 0.0284, s1.loss_mask: 0.2162, s2.loss_cls: 0.0167, s2.acc: 97.3024, s2.loss_bbox: 0.0125, s2.loss_mask: 0.1039, loss: 1.0764
2022-08-18 16:47:07,203 - mmdet - INFO - Epoch [12][16050/18729]	lr: 1.000e-05, eta: 0:25:08, time: 0.553, data_time: 0.027, memory: 12528, loss_rpn_cls: 0.0183, loss_rpn_bbox: 0.0927, s0.loss_cls: 0.0687, s0.acc: 97.4492, s0.loss_bbox: 0.0533, s0.loss_mask: 0.4204, s1.loss_cls: 0.0292, s1.acc: 97.7913, s1.loss_bbox: 0.0262, s1.loss_mask: 0.2176, s2.loss_cls: 0.0162, s2.acc: 97.6701, s2.loss_bbox: 0.0112, s2.loss_mask: 0.1052, loss: 1.0591
2022-08-18 16:47:31,984 - mmdet - INFO - Epoch [12][16100/18729]	lr: 1.000e-05, eta: 0:24:40, time: 0.496, data_time: 0.013, memory: 12528, loss_rpn_cls: 0.0142, loss_rpn_bbox: 0.0482, s0.loss_cls: 0.0529, s0.acc: 97.8828, s0.loss_bbox: 0.0396, s0.loss_mask: 0.4196, s1.loss_cls: 0.0250, s1.acc: 98.0099, s1.loss_bbox: 0.0192, s1.loss_mask: 0.2129, s2.loss_cls: 0.0138, s2.acc: 97.8705, s2.loss_bbox: 0.0088, s2.loss_mask: 0.1020, loss: 0.9561
2022-08-18 16:48:01,505 - mmdet - INFO - Epoch [12][16150/18729]	lr: 1.000e-05, eta: 0:24:12, time: 0.590, data_time: 0.049, memory: 12528, loss_rpn_cls: 0.0206, loss_rpn_bbox: 0.0932, s0.loss_cls: 0.0732, s0.acc: 97.3438, s0.loss_bbox: 0.0560, s0.loss_mask: 0.4700, s1.loss_cls: 0.0320, s1.acc: 97.6994, s1.loss_bbox: 0.0278, s1.loss_mask: 0.2404, s2.loss_cls: 0.0177, s2.acc: 97.3085, s2.loss_bbox: 0.0123, s2.loss_mask: 0.1185, loss: 1.1617
2022-08-18 16:48:29,801 - mmdet - INFO - Epoch [12][16200/18729]	lr: 1.000e-05, eta: 0:23:44, time: 0.566, data_time: 0.042, memory: 12528, loss_rpn_cls: 0.0233, loss_rpn_bbox: 0.1030, s0.loss_cls: 0.0837, s0.acc: 96.7461, s0.loss_bbox: 0.0497, s0.loss_mask: 0.5156, s1.loss_cls: 0.0359, s1.acc: 97.2838, s1.loss_bbox: 0.0234, s1.loss_mask: 0.2620, s2.loss_cls: 0.0194, s2.acc: 97.0488, s2.loss_bbox: 0.0099, s2.loss_mask: 0.1264, loss: 1.2522
2022-08-18 16:48:57,778 - mmdet - INFO - Epoch [12][16250/18729]	lr: 1.000e-05, eta: 0:23:15, time: 0.560, data_time: 0.026, memory: 12528, loss_rpn_cls: 0.0151, loss_rpn_bbox: 0.0883, s0.loss_cls: 0.0684, s0.acc: 97.2617, s0.loss_bbox: 0.0567, s0.loss_mask: 0.4293, s1.loss_cls: 0.0282, s1.acc: 97.9696, s1.loss_bbox: 0.0274, s1.loss_mask: 0.2234, s2.loss_cls: 0.0159, s2.acc: 97.5133, s2.loss_bbox: 0.0124, s2.loss_mask: 0.1089, loss: 1.0740
2022-08-18 16:49:25,007 - mmdet - INFO - Epoch [12][16300/18729]	lr: 1.000e-05, eta: 0:22:47, time: 0.545, data_time: 0.017, memory: 12528, loss_rpn_cls: 0.0215, loss_rpn_bbox: 0.0797, s0.loss_cls: 0.0708, s0.acc: 97.4141, s0.loss_bbox: 0.0516, s0.loss_mask: 0.4663, s1.loss_cls: 0.0309, s1.acc: 97.6405, s1.loss_bbox: 0.0242, s1.loss_mask: 0.2372, s2.loss_cls: 0.0171, s2.acc: 97.3164, s2.loss_bbox: 0.0106, s2.loss_mask: 0.1121, loss: 1.1220
2022-08-18 16:49:53,599 - mmdet - INFO - Epoch [12][16350/18729]	lr: 1.000e-05, eta: 0:22:19, time: 0.572, data_time: 0.032, memory: 12528, loss_rpn_cls: 0.0172, loss_rpn_bbox: 0.1052, s0.loss_cls: 0.0886, s0.acc: 96.6016, s0.loss_bbox: 0.0645, s0.loss_mask: 0.4495, s1.loss_cls: 0.0386, s1.acc: 97.1871, s1.loss_bbox: 0.0307, s1.loss_mask: 0.2352, s2.loss_cls: 0.0200, s2.acc: 96.9924, s2.loss_bbox: 0.0134, s2.loss_mask: 0.1156, loss: 1.1785
2022-08-18 16:50:20,856 - mmdet - INFO - Epoch [12][16400/18729]	lr: 1.000e-05, eta: 0:21:51, time: 0.545, data_time: 0.023, memory: 12528, loss_rpn_cls: 0.0188, loss_rpn_bbox: 0.0921, s0.loss_cls: 0.0600, s0.acc: 97.7188, s0.loss_bbox: 0.0527, s0.loss_mask: 0.4121, s1.loss_cls: 0.0266, s1.acc: 98.0009, s1.loss_bbox: 0.0241, s1.loss_mask: 0.2048, s2.loss_cls: 0.0148, s2.acc: 97.8220, s2.loss_bbox: 0.0105, s2.loss_mask: 0.0994, loss: 1.0157
2022-08-18 16:50:48,942 - mmdet - INFO - Epoch [12][16450/18729]	lr: 1.000e-05, eta: 0:21:23, time: 0.562, data_time: 0.026, memory: 12528, loss_rpn_cls: 0.0269, loss_rpn_bbox: 0.0898, s0.loss_cls: 0.0785, s0.acc: 96.9414, s0.loss_bbox: 0.0580, s0.loss_mask: 0.4464, s1.loss_cls: 0.0353, s1.acc: 97.1873, s1.loss_bbox: 0.0284, s1.loss_mask: 0.2289, s2.loss_cls: 0.0202, s2.acc: 96.9193, s2.loss_bbox: 0.0121, s2.loss_mask: 0.1113, loss: 1.1361
2022-08-18 16:51:16,497 - mmdet - INFO - Epoch [12][16500/18729]	lr: 1.000e-05, eta: 0:20:54, time: 0.551, data_time: 0.024, memory: 12528, loss_rpn_cls: 0.0163, loss_rpn_bbox: 0.0864, s0.loss_cls: 0.0665, s0.acc: 97.5352, s0.loss_bbox: 0.0534, s0.loss_mask: 0.4094, s1.loss_cls: 0.0289, s1.acc: 97.9410, s1.loss_bbox: 0.0254, s1.loss_mask: 0.2106, s2.loss_cls: 0.0147, s2.acc: 97.8665, s2.loss_bbox: 0.0114, s2.loss_mask: 0.1030, loss: 1.0259
2022-08-18 16:51:45,859 - mmdet - INFO - Epoch [12][16550/18729]	lr: 1.000e-05, eta: 0:20:26, time: 0.587, data_time: 0.040, memory: 12528, loss_rpn_cls: 0.0258, loss_rpn_bbox: 0.1151, s0.loss_cls: 0.0877, s0.acc: 96.5820, s0.loss_bbox: 0.0589, s0.loss_mask: 0.4548, s1.loss_cls: 0.0369, s1.acc: 97.2191, s1.loss_bbox: 0.0275, s1.loss_mask: 0.2350, s2.loss_cls: 0.0197, s2.acc: 97.2556, s2.loss_bbox: 0.0118, s2.loss_mask: 0.1136, loss: 1.1869
2022-08-18 16:52:12,813 - mmdet - INFO - Epoch [12][16600/18729]	lr: 1.000e-05, eta: 0:19:58, time: 0.539, data_time: 0.028, memory: 12528, loss_rpn_cls: 0.0225, loss_rpn_bbox: 0.0694, s0.loss_cls: 0.0793, s0.acc: 96.9688, s0.loss_bbox: 0.0481, s0.loss_mask: 0.4597, s1.loss_cls: 0.0322, s1.acc: 97.6092, s1.loss_bbox: 0.0230, s1.loss_mask: 0.2356, s2.loss_cls: 0.0177, s2.acc: 97.4108, s2.loss_bbox: 0.0099, s2.loss_mask: 0.1156, loss: 1.1130
2022-08-18 16:52:40,630 - mmdet - INFO - Epoch [12][16650/18729]	lr: 1.000e-05, eta: 0:19:30, time: 0.556, data_time: 0.030, memory: 12528, loss_rpn_cls: 0.0207, loss_rpn_bbox: 0.1035, s0.loss_cls: 0.0661, s0.acc: 97.4844, s0.loss_bbox: 0.0541, s0.loss_mask: 0.5059, s1.loss_cls: 0.0312, s1.acc: 97.6907, s1.loss_bbox: 0.0253, s1.loss_mask: 0.2526, s2.loss_cls: 0.0177, s2.acc: 97.3016, s2.loss_bbox: 0.0109, s2.loss_mask: 0.1232, loss: 1.2112
2022-08-18 16:53:08,461 - mmdet - INFO - Epoch [12][16700/18729]	lr: 1.000e-05, eta: 0:19:02, time: 0.557, data_time: 0.025, memory: 12528, loss_rpn_cls: 0.0229, loss_rpn_bbox: 0.0981, s0.loss_cls: 0.0768, s0.acc: 97.0312, s0.loss_bbox: 0.0643, s0.loss_mask: 0.4348, s1.loss_cls: 0.0332, s1.acc: 97.4793, s1.loss_bbox: 0.0301, s1.loss_mask: 0.2263, s2.loss_cls: 0.0186, s2.acc: 97.2254, s2.loss_bbox: 0.0131, s2.loss_mask: 0.1097, loss: 1.1279
2022-08-18 16:53:36,318 - mmdet - INFO - Epoch [12][16750/18729]	lr: 1.000e-05, eta: 0:18:34, time: 0.557, data_time: 0.031, memory: 12528, loss_rpn_cls: 0.0172, loss_rpn_bbox: 0.0827, s0.loss_cls: 0.0691, s0.acc: 97.2109, s0.loss_bbox: 0.0511, s0.loss_mask: 0.4145, s1.loss_cls: 0.0292, s1.acc: 97.6563, s1.loss_bbox: 0.0242, s1.loss_mask: 0.2163, s2.loss_cls: 0.0168, s2.acc: 97.1231, s2.loss_bbox: 0.0107, s2.loss_mask: 0.1051, loss: 1.0370
2022-08-18 16:54:16,002 - mmdet - INFO - Epoch [12][16800/18729]	lr: 1.000e-05, eta: 0:18:07, time: 0.794, data_time: 0.262, memory: 18111, loss_rpn_cls: 0.0135, loss_rpn_bbox: 0.0473, s0.loss_cls: 0.0536, s0.acc: 97.9453, s0.loss_bbox: 0.0414, s0.loss_mask: 0.4565, s1.loss_cls: 0.0268, s1.acc: 97.9838, s1.loss_bbox: 0.0211, s1.loss_mask: 0.2370, s2.loss_cls: 0.0137, s2.acc: 97.6134, s2.loss_bbox: 0.0091, s2.loss_mask: 0.1161, loss: 1.0362
2022-08-18 16:54:45,187 - mmdet - INFO - Epoch [12][16850/18729]	lr: 1.000e-05, eta: 0:17:39, time: 0.584, data_time: 0.043, memory: 18111, loss_rpn_cls: 0.0189, loss_rpn_bbox: 0.0908, s0.loss_cls: 0.0623, s0.acc: 97.5703, s0.loss_bbox: 0.0558, s0.loss_mask: 0.5203, s1.loss_cls: 0.0257, s1.acc: 97.9580, s1.loss_bbox: 0.0268, s1.loss_mask: 0.2609, s2.loss_cls: 0.0144, s2.acc: 97.6749, s2.loss_bbox: 0.0118, s2.loss_mask: 0.1289, loss: 1.2166
2022-08-18 16:55:12,360 - mmdet - INFO - Epoch [12][16900/18729]	lr: 1.000e-05, eta: 0:17:10, time: 0.543, data_time: 0.015, memory: 18111, loss_rpn_cls: 0.0164, loss_rpn_bbox: 0.1046, s0.loss_cls: 0.0771, s0.acc: 96.9258, s0.loss_bbox: 0.0610, s0.loss_mask: 0.4174, s1.loss_cls: 0.0332, s1.acc: 97.4073, s1.loss_bbox: 0.0299, s1.loss_mask: 0.2226, s2.loss_cls: 0.0185, s2.acc: 97.1908, s2.loss_bbox: 0.0133, s2.loss_mask: 0.1111, loss: 1.1050
2022-08-18 16:55:39,435 - mmdet - INFO - Epoch [12][16950/18729]	lr: 1.000e-05, eta: 0:16:42, time: 0.541, data_time: 0.022, memory: 18111, loss_rpn_cls: 0.0193, loss_rpn_bbox: 0.1066, s0.loss_cls: 0.0730, s0.acc: 97.2305, s0.loss_bbox: 0.0612, s0.loss_mask: 0.4926, s1.loss_cls: 0.0339, s1.acc: 97.2349, s1.loss_bbox: 0.0282, s1.loss_mask: 0.2468, s2.loss_cls: 0.0186, s2.acc: 97.0425, s2.loss_bbox: 0.0122, s2.loss_mask: 0.1199, loss: 1.2123
2022-08-18 16:56:10,291 - mmdet - INFO - Epoch [12][17000/18729]	lr: 1.000e-05, eta: 0:16:14, time: 0.617, data_time: 0.072, memory: 18111, loss_rpn_cls: 0.0200, loss_rpn_bbox: 0.0831, s0.loss_cls: 0.0772, s0.acc: 97.0859, s0.loss_bbox: 0.0573, s0.loss_mask: 0.5039, s1.loss_cls: 0.0323, s1.acc: 97.6542, s1.loss_bbox: 0.0267, s1.loss_mask: 0.2532, s2.loss_cls: 0.0176, s2.acc: 97.4976, s2.loss_bbox: 0.0115, s2.loss_mask: 0.1243, loss: 1.2070
2022-08-18 16:56:37,852 - mmdet - INFO - Epoch [12][17050/18729]	lr: 1.000e-05, eta: 0:15:46, time: 0.551, data_time: 0.031, memory: 18111, loss_rpn_cls: 0.0166, loss_rpn_bbox: 0.0607, s0.loss_cls: 0.0626, s0.acc: 97.5156, s0.loss_bbox: 0.0418, s0.loss_mask: 0.5055, s1.loss_cls: 0.0275, s1.acc: 98.1457, s1.loss_bbox: 0.0205, s1.loss_mask: 0.2674, s2.loss_cls: 0.0156, s2.acc: 97.7508, s2.loss_bbox: 0.0095, s2.loss_mask: 0.1318, loss: 1.1596
2022-08-18 16:57:06,848 - mmdet - INFO - Epoch [12][17100/18729]	lr: 1.000e-05, eta: 0:15:18, time: 0.580, data_time: 0.043, memory: 18111, loss_rpn_cls: 0.0210, loss_rpn_bbox: 0.0940, s0.loss_cls: 0.0659, s0.acc: 97.4727, s0.loss_bbox: 0.0530, s0.loss_mask: 0.4111, s1.loss_cls: 0.0278, s1.acc: 97.8078, s1.loss_bbox: 0.0255, s1.loss_mask: 0.2105, s2.loss_cls: 0.0153, s2.acc: 97.8553, s2.loss_bbox: 0.0112, s2.loss_mask: 0.1043, loss: 1.0397
2022-08-18 16:57:36,242 - mmdet - INFO - Epoch [12][17150/18729]	lr: 1.000e-05, eta: 0:14:50, time: 0.588, data_time: 0.034, memory: 18111, loss_rpn_cls: 0.0247, loss_rpn_bbox: 0.1056, s0.loss_cls: 0.0791, s0.acc: 96.8984, s0.loss_bbox: 0.0642, s0.loss_mask: 0.4880, s1.loss_cls: 0.0348, s1.acc: 97.3064, s1.loss_bbox: 0.0290, s1.loss_mask: 0.2424, s2.loss_cls: 0.0180, s2.acc: 97.0744, s2.loss_bbox: 0.0123, s2.loss_mask: 0.1156, loss: 1.2139
2022-08-18 16:58:03,730 - mmdet - INFO - Epoch [12][17200/18729]	lr: 1.000e-05, eta: 0:14:21, time: 0.550, data_time: 0.020, memory: 18111, loss_rpn_cls: 0.0234, loss_rpn_bbox: 0.1002, s0.loss_cls: 0.0645, s0.acc: 97.4258, s0.loss_bbox: 0.0598, s0.loss_mask: 0.4351, s1.loss_cls: 0.0284, s1.acc: 97.8900, s1.loss_bbox: 0.0289, s1.loss_mask: 0.2175, s2.loss_cls: 0.0159, s2.acc: 97.3751, s2.loss_bbox: 0.0122, s2.loss_mask: 0.1017, loss: 1.0876
2022-08-18 16:58:34,633 - mmdet - INFO - Epoch [12][17250/18729]	lr: 1.000e-05, eta: 0:13:54, time: 0.618, data_time: 0.058, memory: 18111, loss_rpn_cls: 0.0277, loss_rpn_bbox: 0.0942, s0.loss_cls: 0.0742, s0.acc: 97.2383, s0.loss_bbox: 0.0554, s0.loss_mask: 0.5368, s1.loss_cls: 0.0352, s1.acc: 97.4876, s1.loss_bbox: 0.0260, s1.loss_mask: 0.2736, s2.loss_cls: 0.0197, s2.acc: 97.0681, s2.loss_bbox: 0.0112, s2.loss_mask: 0.1333, loss: 1.2872
2022-08-18 16:59:03,008 - mmdet - INFO - Epoch [12][17300/18729]	lr: 1.000e-05, eta: 0:13:25, time: 0.567, data_time: 0.028, memory: 18111, loss_rpn_cls: 0.0229, loss_rpn_bbox: 0.0843, s0.loss_cls: 0.0787, s0.acc: 96.7852, s0.loss_bbox: 0.0548, s0.loss_mask: 0.4050, s1.loss_cls: 0.0345, s1.acc: 97.3286, s1.loss_bbox: 0.0282, s1.loss_mask: 0.2129, s2.loss_cls: 0.0178, s2.acc: 96.9341, s2.loss_bbox: 0.0128, s2.loss_mask: 0.1061, loss: 1.0581
2022-08-18 16:59:31,568 - mmdet - INFO - Epoch [12][17350/18729]	lr: 1.000e-05, eta: 0:12:57, time: 0.571, data_time: 0.028, memory: 18111, loss_rpn_cls: 0.0173, loss_rpn_bbox: 0.0891, s0.loss_cls: 0.0827, s0.acc: 96.8633, s0.loss_bbox: 0.0611, s0.loss_mask: 0.4384, s1.loss_cls: 0.0329, s1.acc: 97.6177, s1.loss_bbox: 0.0283, s1.loss_mask: 0.2199, s2.loss_cls: 0.0174, s2.acc: 97.5163, s2.loss_bbox: 0.0129, s2.loss_mask: 0.1088, loss: 1.1087
2022-08-18 17:00:00,035 - mmdet - INFO - Epoch [12][17400/18729]	lr: 1.000e-05, eta: 0:12:29, time: 0.569, data_time: 0.030, memory: 18111, loss_rpn_cls: 0.0211, loss_rpn_bbox: 0.1117, s0.loss_cls: 0.0897, s0.acc: 96.6875, s0.loss_bbox: 0.0697, s0.loss_mask: 0.4935, s1.loss_cls: 0.0381, s1.acc: 97.2323, s1.loss_bbox: 0.0325, s1.loss_mask: 0.2462, s2.loss_cls: 0.0218, s2.acc: 96.6120, s2.loss_bbox: 0.0136, s2.loss_mask: 0.1191, loss: 1.2570
2022-08-18 17:00:26,855 - mmdet - INFO - Epoch [12][17450/18729]	lr: 1.000e-05, eta: 0:12:01, time: 0.536, data_time: 0.023, memory: 18111, loss_rpn_cls: 0.0196, loss_rpn_bbox: 0.0949, s0.loss_cls: 0.0686, s0.acc: 97.3359, s0.loss_bbox: 0.0513, s0.loss_mask: 0.5171, s1.loss_cls: 0.0344, s1.acc: 97.4614, s1.loss_bbox: 0.0243, s1.loss_mask: 0.2628, s2.loss_cls: 0.0189, s2.acc: 96.8282, s2.loss_bbox: 0.0102, s2.loss_mask: 0.1277, loss: 1.2299
2022-08-18 17:00:55,190 - mmdet - INFO - Epoch [12][17500/18729]	lr: 1.000e-05, eta: 0:11:33, time: 0.567, data_time: 0.020, memory: 18111, loss_rpn_cls: 0.0203, loss_rpn_bbox: 0.1077, s0.loss_cls: 0.0721, s0.acc: 97.2148, s0.loss_bbox: 0.0635, s0.loss_mask: 0.4319, s1.loss_cls: 0.0314, s1.acc: 97.6801, s1.loss_bbox: 0.0301, s1.loss_mask: 0.2204, s2.loss_cls: 0.0160, s2.acc: 97.5803, s2.loss_bbox: 0.0131, s2.loss_mask: 0.1044, loss: 1.1108
2022-08-18 17:01:24,393 - mmdet - INFO - Epoch [12][17550/18729]	lr: 1.000e-05, eta: 0:11:04, time: 0.584, data_time: 0.041, memory: 18111, loss_rpn_cls: 0.0178, loss_rpn_bbox: 0.0913, s0.loss_cls: 0.0758, s0.acc: 97.1953, s0.loss_bbox: 0.0526, s0.loss_mask: 0.5183, s1.loss_cls: 0.0334, s1.acc: 97.5378, s1.loss_bbox: 0.0237, s1.loss_mask: 0.2619, s2.loss_cls: 0.0170, s2.acc: 97.6590, s2.loss_bbox: 0.0103, s2.loss_mask: 0.1260, loss: 1.2281
2022-08-18 17:01:52,515 - mmdet - INFO - Epoch [12][17600/18729]	lr: 1.000e-05, eta: 0:10:36, time: 0.562, data_time: 0.039, memory: 18111, loss_rpn_cls: 0.0267, loss_rpn_bbox: 0.0979, s0.loss_cls: 0.0689, s0.acc: 97.3359, s0.loss_bbox: 0.0515, s0.loss_mask: 0.4755, s1.loss_cls: 0.0334, s1.acc: 97.4876, s1.loss_bbox: 0.0241, s1.loss_mask: 0.2452, s2.loss_cls: 0.0201, s2.acc: 96.7432, s2.loss_bbox: 0.0100, s2.loss_mask: 0.1189, loss: 1.1724
2022-08-18 17:02:24,822 - mmdet - INFO - Epoch [12][17650/18729]	lr: 1.000e-05, eta: 0:10:08, time: 0.646, data_time: 0.101, memory: 18111, loss_rpn_cls: 0.0302, loss_rpn_bbox: 0.0926, s0.loss_cls: 0.0701, s0.acc: 97.3047, s0.loss_bbox: 0.0536, s0.loss_mask: 0.5452, s1.loss_cls: 0.0298, s1.acc: 97.7136, s1.loss_bbox: 0.0250, s1.loss_mask: 0.2687, s2.loss_cls: 0.0166, s2.acc: 97.4460, s2.loss_bbox: 0.0106, s2.loss_mask: 0.1325, loss: 1.2748
2022-08-18 17:02:53,581 - mmdet - INFO - Epoch [12][17700/18729]	lr: 1.000e-05, eta: 0:09:40, time: 0.575, data_time: 0.034, memory: 18111, loss_rpn_cls: 0.0202, loss_rpn_bbox: 0.0932, s0.loss_cls: 0.0673, s0.acc: 97.4688, s0.loss_bbox: 0.0559, s0.loss_mask: 0.4396, s1.loss_cls: 0.0311, s1.acc: 97.7062, s1.loss_bbox: 0.0269, s1.loss_mask: 0.2260, s2.loss_cls: 0.0171, s2.acc: 97.3540, s2.loss_bbox: 0.0116, s2.loss_mask: 0.1071, loss: 1.0960
2022-08-18 17:03:20,503 - mmdet - INFO - Epoch [12][17750/18729]	lr: 1.000e-05, eta: 0:09:12, time: 0.538, data_time: 0.027, memory: 18111, loss_rpn_cls: 0.0175, loss_rpn_bbox: 0.0715, s0.loss_cls: 0.0682, s0.acc: 97.3281, s0.loss_bbox: 0.0534, s0.loss_mask: 0.4896, s1.loss_cls: 0.0311, s1.acc: 97.7490, s1.loss_bbox: 0.0258, s1.loss_mask: 0.2529, s2.loss_cls: 0.0170, s2.acc: 97.3646, s2.loss_bbox: 0.0106, s2.loss_mask: 0.1224, loss: 1.1600
2022-08-18 17:03:49,585 - mmdet - INFO - Epoch [12][17800/18729]	lr: 1.000e-05, eta: 0:08:44, time: 0.582, data_time: 0.042, memory: 18111, loss_rpn_cls: 0.0181, loss_rpn_bbox: 0.0887, s0.loss_cls: 0.0673, s0.acc: 97.4648, s0.loss_bbox: 0.0524, s0.loss_mask: 0.4666, s1.loss_cls: 0.0292, s1.acc: 97.9998, s1.loss_bbox: 0.0249, s1.loss_mask: 0.2385, s2.loss_cls: 0.0162, s2.acc: 97.5542, s2.loss_bbox: 0.0108, s2.loss_mask: 0.1158, loss: 1.1285
2022-08-18 17:04:19,945 - mmdet - INFO - Epoch [12][17850/18729]	lr: 1.000e-05, eta: 0:08:16, time: 0.607, data_time: 0.068, memory: 18111, loss_rpn_cls: 0.0189, loss_rpn_bbox: 0.1024, s0.loss_cls: 0.0860, s0.acc: 96.7734, s0.loss_bbox: 0.0615, s0.loss_mask: 0.4733, s1.loss_cls: 0.0362, s1.acc: 97.2546, s1.loss_bbox: 0.0290, s1.loss_mask: 0.2328, s2.loss_cls: 0.0190, s2.acc: 97.2262, s2.loss_bbox: 0.0125, s2.loss_mask: 0.1108, loss: 1.1822
2022-08-18 17:04:47,611 - mmdet - INFO - Epoch [12][17900/18729]	lr: 1.000e-05, eta: 0:07:47, time: 0.553, data_time: 0.028, memory: 18111, loss_rpn_cls: 0.0173, loss_rpn_bbox: 0.1013, s0.loss_cls: 0.0700, s0.acc: 97.1562, s0.loss_bbox: 0.0517, s0.loss_mask: 0.4194, s1.loss_cls: 0.0318, s1.acc: 97.4893, s1.loss_bbox: 0.0243, s1.loss_mask: 0.2156, s2.loss_cls: 0.0168, s2.acc: 97.0926, s2.loss_bbox: 0.0109, s2.loss_mask: 0.1062, loss: 1.0653
2022-08-18 17:05:17,304 - mmdet - INFO - Epoch [12][17950/18729]	lr: 1.000e-05, eta: 0:07:19, time: 0.594, data_time: 0.046, memory: 18111, loss_rpn_cls: 0.0133, loss_rpn_bbox: 0.0914, s0.loss_cls: 0.0761, s0.acc: 97.0781, s0.loss_bbox: 0.0567, s0.loss_mask: 0.4565, s1.loss_cls: 0.0307, s1.acc: 97.7799, s1.loss_bbox: 0.0266, s1.loss_mask: 0.2342, s2.loss_cls: 0.0161, s2.acc: 97.5616, s2.loss_bbox: 0.0116, s2.loss_mask: 0.1095, loss: 1.1227
2022-08-18 17:05:45,526 - mmdet - INFO - Epoch [12][18000/18729]	lr: 1.000e-05, eta: 0:06:51, time: 0.564, data_time: 0.034, memory: 18111, loss_rpn_cls: 0.0173, loss_rpn_bbox: 0.0996, s0.loss_cls: 0.0745, s0.acc: 97.0273, s0.loss_bbox: 0.0515, s0.loss_mask: 0.4262, s1.loss_cls: 0.0362, s1.acc: 97.2103, s1.loss_bbox: 0.0248, s1.loss_mask: 0.2163, s2.loss_cls: 0.0185, s2.acc: 97.1201, s2.loss_bbox: 0.0108, s2.loss_mask: 0.1081, loss: 1.0840
2022-08-18 17:06:14,303 - mmdet - INFO - Epoch [12][18050/18729]	lr: 1.000e-05, eta: 0:06:23, time: 0.576, data_time: 0.034, memory: 18111, loss_rpn_cls: 0.0177, loss_rpn_bbox: 0.0890, s0.loss_cls: 0.0884, s0.acc: 96.6133, s0.loss_bbox: 0.0623, s0.loss_mask: 0.4431, s1.loss_cls: 0.0378, s1.acc: 97.2108, s1.loss_bbox: 0.0308, s1.loss_mask: 0.2295, s2.loss_cls: 0.0194, s2.acc: 97.1147, s2.loss_bbox: 0.0135, s2.loss_mask: 0.1127, loss: 1.1444
2022-08-18 17:06:41,285 - mmdet - INFO - Epoch [12][18100/18729]	lr: 1.000e-05, eta: 0:05:54, time: 0.540, data_time: 0.023, memory: 18111, loss_rpn_cls: 0.0240, loss_rpn_bbox: 0.0785, s0.loss_cls: 0.0755, s0.acc: 97.3750, s0.loss_bbox: 0.0528, s0.loss_mask: 0.4792, s1.loss_cls: 0.0343, s1.acc: 97.5793, s1.loss_bbox: 0.0260, s1.loss_mask: 0.2419, s2.loss_cls: 0.0182, s2.acc: 97.3683, s2.loss_bbox: 0.0116, s2.loss_mask: 0.1190, loss: 1.1610
2022-08-18 17:07:10,361 - mmdet - INFO - Epoch [12][18150/18729]	lr: 1.000e-05, eta: 0:05:26, time: 0.582, data_time: 0.031, memory: 18111, loss_rpn_cls: 0.0224, loss_rpn_bbox: 0.1130, s0.loss_cls: 0.0852, s0.acc: 96.6875, s0.loss_bbox: 0.0621, s0.loss_mask: 0.4727, s1.loss_cls: 0.0356, s1.acc: 97.4820, s1.loss_bbox: 0.0294, s1.loss_mask: 0.2358, s2.loss_cls: 0.0197, s2.acc: 97.0469, s2.loss_bbox: 0.0126, s2.loss_mask: 0.1163, loss: 1.2047
2022-08-18 17:07:40,828 - mmdet - INFO - Epoch [12][18200/18729]	lr: 1.000e-05, eta: 0:04:58, time: 0.609, data_time: 0.046, memory: 18111, loss_rpn_cls: 0.0274, loss_rpn_bbox: 0.1174, s0.loss_cls: 0.0826, s0.acc: 96.6602, s0.loss_bbox: 0.0625, s0.loss_mask: 0.5350, s1.loss_cls: 0.0353, s1.acc: 97.2422, s1.loss_bbox: 0.0285, s1.loss_mask: 0.2750, s2.loss_cls: 0.0184, s2.acc: 97.0494, s2.loss_bbox: 0.0121, s2.loss_mask: 0.1339, loss: 1.3280
2022-08-18 17:08:08,427 - mmdet - INFO - Epoch [12][18250/18729]	lr: 1.000e-05, eta: 0:04:30, time: 0.552, data_time: 0.018, memory: 18111, loss_rpn_cls: 0.0255, loss_rpn_bbox: 0.0855, s0.loss_cls: 0.0841, s0.acc: 96.7227, s0.loss_bbox: 0.0636, s0.loss_mask: 0.4116, s1.loss_cls: 0.0351, s1.acc: 97.4391, s1.loss_bbox: 0.0325, s1.loss_mask: 0.2140, s2.loss_cls: 0.0208, s2.acc: 96.7782, s2.loss_bbox: 0.0143, s2.loss_mask: 0.1048, loss: 1.0918
2022-08-18 17:08:36,941 - mmdet - INFO - Epoch [12][18300/18729]	lr: 1.000e-05, eta: 0:04:02, time: 0.570, data_time: 0.027, memory: 18111, loss_rpn_cls: 0.0213, loss_rpn_bbox: 0.0932, s0.loss_cls: 0.0702, s0.acc: 97.1875, s0.loss_bbox: 0.0529, s0.loss_mask: 0.4392, s1.loss_cls: 0.0275, s1.acc: 97.9397, s1.loss_bbox: 0.0257, s1.loss_mask: 0.2294, s2.loss_cls: 0.0165, s2.acc: 97.5626, s2.loss_bbox: 0.0112, s2.loss_mask: 0.1148, loss: 1.1019
2022-08-18 17:09:08,181 - mmdet - INFO - Epoch [12][18350/18729]	lr: 1.000e-05, eta: 0:03:33, time: 0.625, data_time: 0.084, memory: 18111, loss_rpn_cls: 0.0226, loss_rpn_bbox: 0.0889, s0.loss_cls: 0.0669, s0.acc: 97.4805, s0.loss_bbox: 0.0468, s0.loss_mask: 0.4768, s1.loss_cls: 0.0272, s1.acc: 97.9112, s1.loss_bbox: 0.0223, s1.loss_mask: 0.2426, s2.loss_cls: 0.0138, s2.acc: 98.0149, s2.loss_bbox: 0.0095, s2.loss_mask: 0.1189, loss: 1.1363
2022-08-18 17:09:35,071 - mmdet - INFO - Epoch [12][18400/18729]	lr: 1.000e-05, eta: 0:03:05, time: 0.538, data_time: 0.022, memory: 18111, loss_rpn_cls: 0.0170, loss_rpn_bbox: 0.0685, s0.loss_cls: 0.0609, s0.acc: 97.7578, s0.loss_bbox: 0.0468, s0.loss_mask: 0.5298, s1.loss_cls: 0.0292, s1.acc: 97.9606, s1.loss_bbox: 0.0225, s1.loss_mask: 0.2695, s2.loss_cls: 0.0165, s2.acc: 97.6989, s2.loss_bbox: 0.0102, s2.loss_mask: 0.1317, loss: 1.2026
2022-08-18 17:10:02,979 - mmdet - INFO - Epoch [12][18450/18729]	lr: 1.000e-05, eta: 0:02:37, time: 0.558, data_time: 0.027, memory: 18111, loss_rpn_cls: 0.0113, loss_rpn_bbox: 0.0630, s0.loss_cls: 0.0689, s0.acc: 97.3398, s0.loss_bbox: 0.0517, s0.loss_mask: 0.5434, s1.loss_cls: 0.0287, s1.acc: 97.7559, s1.loss_bbox: 0.0248, s1.loss_mask: 0.2743, s2.loss_cls: 0.0154, s2.acc: 97.6124, s2.loss_bbox: 0.0110, s2.loss_mask: 0.1376, loss: 1.2300
2022-08-18 17:10:31,740 - mmdet - INFO - Epoch [12][18500/18729]	lr: 1.000e-05, eta: 0:02:09, time: 0.575, data_time: 0.030, memory: 18111, loss_rpn_cls: 0.0209, loss_rpn_bbox: 0.0957, s0.loss_cls: 0.0736, s0.acc: 97.2109, s0.loss_bbox: 0.0615, s0.loss_mask: 0.4664, s1.loss_cls: 0.0347, s1.acc: 97.6223, s1.loss_bbox: 0.0290, s1.loss_mask: 0.2412, s2.loss_cls: 0.0186, s2.acc: 97.1921, s2.loss_bbox: 0.0127, s2.loss_mask: 0.1183, loss: 1.1726
2022-08-18 17:11:00,955 - mmdet - INFO - Epoch [12][18550/18729]	lr: 1.000e-05, eta: 0:01:41, time: 0.584, data_time: 0.031, memory: 18111, loss_rpn_cls: 0.0236, loss_rpn_bbox: 0.0994, s0.loss_cls: 0.0811, s0.acc: 96.8984, s0.loss_bbox: 0.0590, s0.loss_mask: 0.4868, s1.loss_cls: 0.0381, s1.acc: 97.2335, s1.loss_bbox: 0.0272, s1.loss_mask: 0.2424, s2.loss_cls: 0.0201, s2.acc: 96.8442, s2.loss_bbox: 0.0121, s2.loss_mask: 0.1185, loss: 1.2083
2022-08-18 17:11:27,796 - mmdet - INFO - Epoch [12][18600/18729]	lr: 1.000e-05, eta: 0:01:12, time: 0.537, data_time: 0.024, memory: 18111, loss_rpn_cls: 0.0188, loss_rpn_bbox: 0.0981, s0.loss_cls: 0.0765, s0.acc: 96.8984, s0.loss_bbox: 0.0574, s0.loss_mask: 0.4025, s1.loss_cls: 0.0343, s1.acc: 97.2759, s1.loss_bbox: 0.0273, s1.loss_mask: 0.2124, s2.loss_cls: 0.0202, s2.acc: 96.8526, s2.loss_bbox: 0.0118, s2.loss_mask: 0.1020, loss: 1.0614
2022-08-18 17:11:55,839 - mmdet - INFO - Epoch [12][18650/18729]	lr: 1.000e-05, eta: 0:00:44, time: 0.561, data_time: 0.022, memory: 18111, loss_rpn_cls: 0.0231, loss_rpn_bbox: 0.0929, s0.loss_cls: 0.0864, s0.acc: 96.5391, s0.loss_bbox: 0.0627, s0.loss_mask: 0.4647, s1.loss_cls: 0.0396, s1.acc: 96.8693, s1.loss_bbox: 0.0297, s1.loss_mask: 0.2364, s2.loss_cls: 0.0211, s2.acc: 96.7393, s2.loss_bbox: 0.0121, s2.loss_mask: 0.1118, loss: 1.1805
2022-08-18 17:12:25,014 - mmdet - INFO - Epoch [12][18700/18729]	lr: 1.000e-05, eta: 0:00:16, time: 0.583, data_time: 0.047, memory: 18111, loss_rpn_cls: 0.0281, loss_rpn_bbox: 0.1090, s0.loss_cls: 0.0741, s0.acc: 97.2148, s0.loss_bbox: 0.0578, s0.loss_mask: 0.5242, s1.loss_cls: 0.0316, s1.acc: 97.6712, s1.loss_bbox: 0.0264, s1.loss_mask: 0.2649, s2.loss_cls: 0.0178, s2.acc: 97.1531, s2.loss_bbox: 0.0110, s2.loss_mask: 0.1283, loss: 1.2731
2022-08-18 17:12:41,523 - mmdet - INFO - Saving checkpoint at 12 epochs
2022-08-18 19:10:30,102 - mmdet - INFO - Evaluating bbox...
2022-08-18 19:15:15,616 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.466
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.683
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.533
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.323
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.548
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.580
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.429
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.694
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.782

2022-08-18 19:15:15,616 - mmdet - INFO - Evaluating segm...
2022-08-18 19:20:11,724 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.651
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.443
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.253
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.499
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.573
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.505
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.513
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.514
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.372
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.603
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.666

2022-08-18 19:20:12,464 - mmdet - INFO - Exp name: cascade_mask_rcnn_swin-t-p4-w7_fpn_1x_coco.py
2022-08-18 19:20:12,465 - mmdet - INFO - Epoch(val) [12][9512]	bbox_mAP: 0.4660, bbox_mAP_50: 0.6830, bbox_mAP_75: 0.5330, bbox_mAP_s: 0.3230, bbox_mAP_m: 0.5480, bbox_mAP_l: 0.6160, bbox_mAP_copypaste: 0.466 0.683 0.533 0.323 0.548 0.616, segm_mAP: 0.4020, segm_mAP_50: 0.6510, segm_mAP_75: 0.4430, segm_mAP_s: 0.2530, segm_mAP_m: 0.4990, segm_mAP_l: 0.5730, segm_mAP_copypaste: 0.402 0.651 0.443 0.253 0.499 0.573
